{
  "batch_mode": "truncate_episodes",
  "clip_param": 0.3,
  "entropy_coeff": 0.01,
  "env": "overcooked_asymmetric_advantages",
  "evaluation_interval": 50,
  "framework": "torch",
  "kl_coeff": 0.2,
  "lambda": 1.0,
  "lr": 0.0005,
  "model": {
    "custom_model": "Centralized_Critic_Model",
    "custom_model_config": {
      "agent_level_batch_update": true,
      "agent_name_ls": [
        "agent_0",
        "agent_1"
      ],
      "algorithm": "mappo",
      "checkpoint_end": true,
      "checkpoint_freq": 20,
      "env": "overcooked",
      "env_args": {
        "horizon": 200,
        "map_name": "asymmetric_advantages"
      },
      "episode_limit": 200,
      "evaluation_interval": 50,
      "force_coop": false,
      "framework": "torch",
      "global_state_flag": false,
      "local_dir": "",
      "local_mode": false,
      "mask_flag": false,
      "model_arch_args": {
        "core_arch": "mlp",
        "encode_layer": "128-256",
        "fc_layer": 2,
        "hidden_state_size": 256,
        "out_dim_fc_0": 128,
        "out_dim_fc_1": 64
      },
      "num_agents": 2,
      "num_cpus_per_worker": 1,
      "num_gpus": 0,
      "num_gpus_per_worker": 0,
      "num_workers": 1,
      "opp_action_in_cc": true,
      "policy_mapping_info": {
        "all_scenario": {
          "all_agents_one_policy": true,
          "description": "overcook all scenarios",
          "one_agent_one_policy": true,
          "team_prefix": [
            "agent_"
          ]
        }
      },
      "restore_path": {
        "model_path": "",
        "params_path": ""
      },
      "seed": 321,
      "share_policy": "group",
      "space_act": "Discrete(6)",
      "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))",
      "stop_iters": 9999999,
      "stop_reward": 999999,
      "stop_timesteps": 2000000
    }
  },
  "multiagent": {
    "policies": "{'default_policy'}",
    "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b183a9700>"
  },
  "num_gpus": 0,
  "num_gpus_per_worker": 0,
  "num_sgd_iter": 2,
  "num_workers": 1,
  "seed": 321,
  "sgd_minibatch_size": 400,
  "simple_optimizer": false,
  "train_batch_size": 400,
  "use_gae": true,
  "vf_clip_param": 10.0,
  "vf_loss_coeff": 1.0
}