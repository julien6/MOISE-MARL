{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0], "episode_lengths": [200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1413644249759503, "mean_inference_ms": 0.7244093501152683, "mean_action_processing_ms": 0.039450564787755556, "mean_env_wait_ms": 0.5586538741837687, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 400, "timesteps_this_iter": 0, "agent_timesteps_total": 400, "timers": {"sample_time_ms": 328.478, "sample_throughput": 1217.739, "load_time_ms": 0.566, "load_throughput": 706409.095, "learn_time_ms": 23.422, "learn_throughput": 17078.133, "update_time_ms": 1.157}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 0.0005, "total_loss": -0.0196500513702631, "policy_loss": -0.002904384834693019, "vf_loss": 0.0011390088748157723, "vf_explained_var": -1.0, "kl": 0.00015669973596681153, "entropy": 1.7916009426116943, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 400, "num_agent_steps_sampled": 400, "num_steps_trained": 400, "num_agent_steps_trained": 400}, "done": false, "episodes_total": 1, "training_iteration": 1, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-06", "timestamp": 1742376306, "time_this_iter_s": 0.32671523094177246, "time_total_s": 0.32671523094177246, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.32671523094177246, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 14.5, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0], "episode_lengths": [200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13745992695805606, "mean_inference_ms": 0.7207808669859554, "mean_action_processing_ms": 0.03920247499434682, "mean_env_wait_ms": 0.5547574737187619, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 800, "timesteps_this_iter": 0, "agent_timesteps_total": 800, "timers": {"sample_time_ms": 327.798, "sample_throughput": 1220.264, "load_time_ms": 0.408, "load_throughput": 979691.445, "learn_time_ms": 20.281, "learn_throughput": 19722.703, "update_time_ms": 1.125}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 0.0005, "total_loss": -0.0192256523296237, "policy_loss": -0.0016352075897145824, "vf_loss": 0.00029634576640091836, "vf_explained_var": -1.0, "kl": 0.00012411284251895305, "entropy": 1.7899197936058044, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 800, "num_agent_steps_sampled": 800, "num_steps_trained": 800, "num_agent_steps_trained": 800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2, "training_iteration": 2, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-06", "timestamp": 1742376306, "time_this_iter_s": 0.30670642852783203, "time_total_s": 0.6334216594696045, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f069d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.6334216594696045, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13510274585839432, "mean_inference_ms": 0.7172826570697893, "mean_action_processing_ms": 0.038974412257154846, "mean_env_wait_ms": 0.5508551426008279, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1200, "timesteps_this_iter": 0, "agent_timesteps_total": 1200, "timers": {"sample_time_ms": 322.918, "sample_throughput": 1238.705, "load_time_ms": 0.325, "load_throughput": 1229700.66, "learn_time_ms": 19.038, "learn_throughput": 21010.302, "update_time_ms": 1.121}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 0.0005, "total_loss": -0.01967670489102602, "policy_loss": -0.0018433356611058382, "vf_loss": 2.934798067144584e-05, "vf_explained_var": -1.0, "kl": 0.00012772348580558646, "entropy": 1.786910355091095, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1200, "num_agent_steps_sampled": 1200, "num_steps_trained": 1200, "num_agent_steps_trained": 1200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3, "training_iteration": 3, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-06", "timestamp": 1742376306, "time_this_iter_s": 0.29970788955688477, "time_total_s": 0.9331295490264893, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fa5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.9331295490264893, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 11.3, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336530171409325, "mean_inference_ms": 0.7145214428304365, "mean_action_processing_ms": 0.03879605245549165, "mean_env_wait_ms": 0.5463238802041772, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1600, "timesteps_this_iter": 0, "agent_timesteps_total": 1600, "timers": {"sample_time_ms": 319.302, "sample_throughput": 1252.732, "load_time_ms": 0.28, "load_throughput": 1427240.834, "learn_time_ms": 18.366, "learn_throughput": 21779.046, "update_time_ms": 1.082}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.025, "cur_lr": 0.0005, "total_loss": -0.016924763564020395, "policy_loss": -0.0007752251485300121, "vf_loss": 0.0016629943856969476, "vf_explained_var": -1.0, "kl": 9.647676538748762e-05, "entropy": 1.781495451927185, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1600, "num_agent_steps_sampled": 1600, "num_steps_trained": 1600, "num_agent_steps_trained": 1600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4, "training_iteration": 4, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-06", "timestamp": 1742376306, "time_this_iter_s": 0.29399871826171875, "time_total_s": 1.227128267288208, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.227128267288208, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1325975937877979, "mean_inference_ms": 0.7123866287778728, "mean_action_processing_ms": 0.038654327475708176, "mean_env_wait_ms": 0.5425404853462459, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2000, "timesteps_this_iter": 0, "agent_timesteps_total": 2000, "timers": {"sample_time_ms": 317.044, "sample_throughput": 1261.655, "load_time_ms": 0.254, "load_throughput": 1576509.679, "learn_time_ms": 18.539, "learn_throughput": 21576.47, "update_time_ms": 1.052}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0125, "cur_lr": 0.0005, "total_loss": -0.018121001310646534, "policy_loss": -0.0003573216404766377, "vf_loss": 1.8860942873288877e-05, "vf_explained_var": -1.0, "kl": 5.89772963375812e-05, "entropy": 1.7783275246620178, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2000, "num_agent_steps_sampled": 2000, "num_steps_trained": 2000, "num_agent_steps_trained": 2000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5, "training_iteration": 5, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-07", "timestamp": 1742376307, "time_this_iter_s": 0.29776430130004883, "time_total_s": 1.5248925685882568, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.5248925685882568, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 11.0, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13178388380843165, "mean_inference_ms": 0.7106163800907649, "mean_action_processing_ms": 0.038515871050017685, "mean_env_wait_ms": 0.5391958342086018, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2400, "timesteps_this_iter": 0, "agent_timesteps_total": 2400, "timers": {"sample_time_ms": 315.538, "sample_throughput": 1267.674, "load_time_ms": 0.236, "load_throughput": 1696381.8, "learn_time_ms": 18.157, "learn_throughput": 22029.824, "update_time_ms": 1.024}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00625, "cur_lr": 0.0005, "total_loss": -0.01845217775553465, "policy_loss": -0.0009824600303538489, "vf_loss": 0.00029078208171995357, "vf_explained_var": -1.0, "kl": 6.824359101442745e-05, "entropy": 1.776092529296875, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2400, "num_agent_steps_sampled": 2400, "num_steps_trained": 2400, "num_agent_steps_trained": 2400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6, "training_iteration": 6, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-07", "timestamp": 1742376307, "time_this_iter_s": 0.29204773902893066, "time_total_s": 1.8169403076171875, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.8169403076171875, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13111642164713785, "mean_inference_ms": 0.7090088812497212, "mean_action_processing_ms": 0.038389046853285834, "mean_env_wait_ms": 0.5364216918664962, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2800, "timesteps_this_iter": 0, "agent_timesteps_total": 2800, "timers": {"sample_time_ms": 313.952, "sample_throughput": 1274.08, "load_time_ms": 0.239, "load_throughput": 1675089.317, "learn_time_ms": 17.866, "learn_throughput": 22388.428, "update_time_ms": 1.004}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003125, "cur_lr": 0.0005, "total_loss": -0.017585220746695995, "policy_loss": -0.0005007958365581544, "vf_loss": 0.0006423509330488741, "vf_explained_var": -1.0, "kl": 7.526001382929248e-05, "entropy": 1.7727013230323792, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2800, "num_agent_steps_sampled": 2800, "num_steps_trained": 2800, "num_agent_steps_trained": 2800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7, "training_iteration": 7, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-07", "timestamp": 1742376307, "time_this_iter_s": 0.29183125495910645, "time_total_s": 2.108771562576294, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.108771562576294, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 10.4, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13053501848988283, "mean_inference_ms": 0.7075402865126983, "mean_action_processing_ms": 0.03828518459132285, "mean_env_wait_ms": 0.5340179800208809, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3200, "timesteps_this_iter": 0, "agent_timesteps_total": 3200, "timers": {"sample_time_ms": 312.674, "sample_throughput": 1279.288, "load_time_ms": 0.236, "load_throughput": 1692531.248, "learn_time_ms": 17.695, "learn_throughput": 22604.786, "update_time_ms": 0.986}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015625, "cur_lr": 0.0005, "total_loss": -0.018151908181607723, "policy_loss": -0.0008203055220654676, "vf_loss": 0.0003333157001179643, "vf_explained_var": -1.0, "kl": 9.546315190722687e-05, "entropy": 1.766506016254425, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3200, "num_agent_steps_sampled": 3200, "num_steps_trained": 3200, "num_agent_steps_trained": 3200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8, "training_iteration": 8, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-08", "timestamp": 1742376308, "time_this_iter_s": 0.29076266288757324, "time_total_s": 2.399534225463867, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.399534225463867, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1329829694630527, "mean_inference_ms": 0.7062269333594979, "mean_action_processing_ms": 0.038193134855589506, "mean_env_wait_ms": 0.5320563759277452, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3600, "timesteps_this_iter": 0, "agent_timesteps_total": 3600, "timers": {"sample_time_ms": 317.332, "sample_throughput": 1260.511, "load_time_ms": 0.238, "load_throughput": 1682769.91, "learn_time_ms": 17.855, "learn_throughput": 22402.777, "update_time_ms": 0.982}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00078125, "cur_lr": 0.0005, "total_loss": -0.017786892130970955, "policy_loss": -0.00048028170480396426, "vf_loss": 0.0002779157293844037, "vf_explained_var": -1.0, "kl": 0.0001060645463062393, "entropy": 1.7584606409072876, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3600, "num_agent_steps_sampled": 3600, "num_steps_trained": 3600, "num_agent_steps_trained": 3600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9, "training_iteration": 9, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-08", "timestamp": 1742376308, "time_this_iter_s": 0.34374141693115234, "time_total_s": 2.7432756423950195, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.7432756423950195, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 11.0, "ram_util_percent": 20.9}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13464173875672925, "mean_inference_ms": 0.7050285727904837, "mean_action_processing_ms": 0.03810880747652565, "mean_env_wait_ms": 0.5304317102582193, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4000, "timesteps_this_iter": 0, "agent_timesteps_total": 4000, "timers": {"sample_time_ms": 316.506, "sample_throughput": 1263.798, "load_time_ms": 0.228, "load_throughput": 1752738.822, "learn_time_ms": 17.727, "learn_throughput": 22564.822, "update_time_ms": 0.979}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.000390625, "cur_lr": 0.0005, "total_loss": -0.017896292731165886, "policy_loss": -0.0006580257159658487, "vf_loss": 0.0002553768135840073, "vf_explained_var": -1.0, "kl": 0.00010091007238061112, "entropy": 1.749367892742157, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4000, "num_agent_steps_sampled": 4000, "num_steps_trained": 4000, "num_agent_steps_trained": 4000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10, "training_iteration": 10, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-08", "timestamp": 1742376308, "time_this_iter_s": 0.2926790714263916, "time_total_s": 3.035954713821411, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.035954713821411, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13579465647974953, "mean_inference_ms": 0.7039710142800139, "mean_action_processing_ms": 0.03803500346059749, "mean_env_wait_ms": 0.5292526569832068, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4400, "timesteps_this_iter": 0, "agent_timesteps_total": 4400, "timers": {"sample_time_ms": 314.853, "sample_throughput": 1270.434, "load_time_ms": 0.196, "load_throughput": 2037306.132, "learn_time_ms": 17.034, "learn_throughput": 23482.57, "update_time_ms": 0.952}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0001953125, "cur_lr": 0.0005, "total_loss": -0.01788442488759756, "policy_loss": -0.000517962896264379, "vf_loss": 6.489199040515814e-05, "vf_explained_var": -1.0, "kl": 6.601786834459222e-05, "entropy": 1.7431364059448242, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4400, "num_agent_steps_sampled": 4400, "num_steps_trained": 4400, "num_agent_steps_trained": 4400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11, "training_iteration": 11, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-09", "timestamp": 1742376309, "time_this_iter_s": 0.29868626594543457, "time_total_s": 3.3346409797668457, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fedca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.3346409797668457, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13659423144730107, "mean_inference_ms": 0.702997555102257, "mean_action_processing_ms": 0.037967856908143825, "mean_env_wait_ms": 0.5281809357348096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4800, "timesteps_this_iter": 0, "agent_timesteps_total": 4800, "timers": {"sample_time_ms": 312.561, "sample_throughput": 1279.751, "load_time_ms": 0.185, "load_throughput": 2157009.0, "learn_time_ms": 16.973, "learn_throughput": 23566.915, "update_time_ms": 0.924}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005, "total_loss": -0.017241019755601883, "policy_loss": -0.0008243226958484229, "vf_loss": 0.0009072427346836776, "vf_explained_var": -1.0, "kl": 7.682583997392634e-05, "entropy": 1.7323948740959167, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4800, "num_agent_steps_sampled": 4800, "num_steps_trained": 4800, "num_agent_steps_trained": 4800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12, "training_iteration": 12, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-09", "timestamp": 1742376309, "time_this_iter_s": 0.29108619689941406, "time_total_s": 3.6257271766662598, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.6257271766662598, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 10.8, "ram_util_percent": 20.9}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13718457695162412, "mean_inference_ms": 0.7021854471525284, "mean_action_processing_ms": 0.03790936839909737, "mean_env_wait_ms": 0.5272588219570639, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5200, "timesteps_this_iter": 0, "agent_timesteps_total": 5200, "timers": {"sample_time_ms": 312.442, "sample_throughput": 1280.236, "load_time_ms": 0.184, "load_throughput": 2177445.295, "learn_time_ms": 16.981, "learn_throughput": 23555.268, "update_time_ms": 0.895}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 0.0005, "total_loss": -0.017275536432862282, "policy_loss": -0.00014775216230233923, "vf_loss": 0.00014561218267772347, "vf_explained_var": -1.0, "kl": 6.094616976676931e-05, "entropy": 1.7273398637771606, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5200, "num_agent_steps_sampled": 5200, "num_steps_trained": 5200, "num_agent_steps_trained": 5200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13, "training_iteration": 13, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-09", "timestamp": 1742376309, "time_this_iter_s": 0.2980775833129883, "time_total_s": 3.923804759979248, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.923804759979248, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13758281824395543, "mean_inference_ms": 0.7014303069035827, "mean_action_processing_ms": 0.03785544808726895, "mean_env_wait_ms": 0.5264280590969846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5600, "timesteps_this_iter": 0, "agent_timesteps_total": 5600, "timers": {"sample_time_ms": 312.342, "sample_throughput": 1280.648, "load_time_ms": 0.183, "load_throughput": 2180558.357, "learn_time_ms": 16.95, "learn_throughput": 23598.605, "update_time_ms": 0.886}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 0.0005, "total_loss": -0.018621359951794147, "policy_loss": -0.001394793400541161, "vf_loss": 3.1886131182545796e-05, "vf_explained_var": -1.0, "kl": 7.538696526276922e-05, "entropy": 1.7258458137512207, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5600, "num_agent_steps_sampled": 5600, "num_steps_trained": 5600, "num_agent_steps_trained": 5600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 14, "training_iteration": 14, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-10", "timestamp": 1742376310, "time_this_iter_s": 0.29152750968933105, "time_total_s": 4.215332269668579, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f619d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.215332269668579, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 11.1, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13785189486851834, "mean_inference_ms": 0.7007307135543643, "mean_action_processing_ms": 0.037804387639499774, "mean_env_wait_ms": 0.5256311698696101, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6000, "timesteps_this_iter": 0, "agent_timesteps_total": 6000, "timers": {"sample_time_ms": 311.8, "sample_throughput": 1282.873, "load_time_ms": 0.19, "load_throughput": 2105045.922, "learn_time_ms": 16.649, "learn_throughput": 24025.937, "update_time_ms": 0.87}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 0.0005, "total_loss": -0.01887466013431549, "policy_loss": -0.0017061272263525495, "vf_loss": 4.3278876546537504e-05, "vf_explained_var": -1.0, "kl": 0.00013409490420790426, "entropy": 1.7211817502975464, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6000, "num_agent_steps_sampled": 6000, "num_steps_trained": 6000, "num_agent_steps_trained": 6000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15, "training_iteration": 15, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-10", "timestamp": 1742376310, "time_this_iter_s": 0.2902405261993408, "time_total_s": 4.50557279586792, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.50557279586792, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13801968070655152, "mean_inference_ms": 0.7000774156026403, "mean_action_processing_ms": 0.037757363723286974, "mean_env_wait_ms": 0.5248953160095029, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6400, "timesteps_this_iter": 0, "agent_timesteps_total": 6400, "timers": {"sample_time_ms": 311.364, "sample_throughput": 1284.672, "load_time_ms": 0.197, "load_throughput": 2028929.254, "learn_time_ms": 16.671, "learn_throughput": 23993.227, "update_time_ms": 0.869}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 0.0005, "total_loss": -0.012761864811182022, "policy_loss": -0.001376525741065393, "vf_loss": 0.005770948715507984, "vf_explained_var": -1.0, "kl": 0.00018389223524772902, "entropy": 1.7156286239624023, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6400, "num_agent_steps_sampled": 6400, "num_steps_trained": 6400, "num_agent_steps_trained": 6400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16, "training_iteration": 16, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-10", "timestamp": 1742376310, "time_this_iter_s": 0.29164648056030273, "time_total_s": 4.797219276428223, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f069d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.797219276428223, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 10.7, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13811672320574392, "mean_inference_ms": 0.6994910954508671, "mean_action_processing_ms": 0.037717379341105126, "mean_env_wait_ms": 0.5242226481532943, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6800, "timesteps_this_iter": 0, "agent_timesteps_total": 6800, "timers": {"sample_time_ms": 311.563, "sample_throughput": 1283.85, "load_time_ms": 0.186, "load_throughput": 2150098.167, "learn_time_ms": 16.677, "learn_throughput": 23984.72, "update_time_ms": 0.867}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005, "total_loss": -0.018525052815675735, "policy_loss": -0.0014627875573935967, "vf_loss": 3.479487077129306e-05, "vf_explained_var": -1.0, "kl": 0.00022100947166736606, "entropy": 1.7097062468528748, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6800, "num_agent_steps_sampled": 6800, "num_steps_trained": 6800, "num_agent_steps_trained": 6800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17, "training_iteration": 17, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-10", "timestamp": 1742376310, "time_this_iter_s": 0.29351115226745605, "time_total_s": 5.090730428695679, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.090730428695679, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13815441086412808, "mean_inference_ms": 0.6989687331484704, "mean_action_processing_ms": 0.037679869901087654, "mean_env_wait_ms": 0.5236436406289338, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7200, "timesteps_this_iter": 0, "agent_timesteps_total": 7200, "timers": {"sample_time_ms": 312.177, "sample_throughput": 1281.324, "load_time_ms": 0.178, "load_throughput": 2243243.214, "learn_time_ms": 16.662, "learn_throughput": 24006.72, "update_time_ms": 0.856}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 0.0005, "total_loss": -0.016992642544209957, "policy_loss": -1.674115628702566e-05, "vf_loss": 9.514862176729366e-05, "vf_explained_var": -1.0, "kl": 0.0001309153759003756, "entropy": 1.707105278968811, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7200, "num_agent_steps_sampled": 7200, "num_steps_trained": 7200, "num_agent_steps_trained": 7200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18, "training_iteration": 18, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-11", "timestamp": 1742376311, "time_this_iter_s": 0.2959904670715332, "time_total_s": 5.386720895767212, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.386720895767212, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 10.8, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13816024254580497, "mean_inference_ms": 0.698520754116557, "mean_action_processing_ms": 0.03764567411841922, "mean_env_wait_ms": 0.5231417078901416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7600, "timesteps_this_iter": 0, "agent_timesteps_total": 7600, "timers": {"sample_time_ms": 307.781, "sample_throughput": 1299.623, "load_time_ms": 0.168, "load_throughput": 2379746.95, "learn_time_ms": 16.384, "learn_throughput": 24413.486, "update_time_ms": 0.866}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 0.0005, "total_loss": -0.017219205386936665, "policy_loss": -0.0005001669842750189, "vf_loss": 0.0002016655053012073, "vf_explained_var": -1.0, "kl": 0.0001107560530516638, "entropy": 1.6920697093009949, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7600, "num_agent_steps_sampled": 7600, "num_steps_trained": 7600, "num_agent_steps_trained": 7600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19, "training_iteration": 19, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-11", "timestamp": 1742376311, "time_this_iter_s": 0.2991654872894287, "time_total_s": 5.685886383056641, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fedca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.685886383056641, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1381275971433542, "mean_inference_ms": 0.6986767976741657, "mean_action_processing_ms": 0.037614247964833813, "mean_env_wait_ms": 0.5226414828071528, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8000, "timesteps_this_iter": 0, "agent_timesteps_total": 8000, "timers": {"sample_time_ms": 311.797, "sample_throughput": 1282.886, "load_time_ms": 0.168, "load_throughput": 2378060.383, "learn_time_ms": 16.328, "learn_throughput": 24497.114, "update_time_ms": 0.85}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 0.0005, "total_loss": -0.01719281915575266, "policy_loss": -0.0004781359306074151, "vf_loss": 8.422288010478951e-05, "vf_explained_var": -1.0, "kl": 6.659502302452935e-05, "entropy": 1.679891049861908, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8000, "num_agent_steps_sampled": 8000, "num_steps_trained": 8000, "num_agent_steps_trained": 8000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20, "training_iteration": 20, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-11", "timestamp": 1742376311, "time_this_iter_s": 0.33568787574768066, "time_total_s": 6.021574258804321, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.021574258804321, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13807641770106457, "mean_inference_ms": 0.6988593861055941, "mean_action_processing_ms": 0.037588778796916425, "mean_env_wait_ms": 0.5222985833285604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8400, "timesteps_this_iter": 0, "agent_timesteps_total": 8400, "timers": {"sample_time_ms": 313.479, "sample_throughput": 1276.003, "load_time_ms": 0.159, "load_throughput": 2517589.436, "learn_time_ms": 16.292, "learn_throughput": 24551.281, "update_time_ms": 0.84}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 0.0005, "total_loss": -0.016929197125136852, "policy_loss": -0.0002731001318903026, "vf_loss": 0.00011719122630893253, "vf_explained_var": -1.0, "kl": 5.814509352686237e-05, "entropy": 1.677327811717987, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8400, "num_agent_steps_sampled": 8400, "num_steps_trained": 8400, "num_agent_steps_trained": 8400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 21, "training_iteration": 21, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-12", "timestamp": 1742376312, "time_this_iter_s": 0.3116421699523926, "time_total_s": 6.333216428756714, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f615e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.333216428756714, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 11.0, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13800476357018115, "mean_inference_ms": 0.698978586553816, "mean_action_processing_ms": 0.037564828527716476, "mean_env_wait_ms": 0.5219744115714375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8800, "timesteps_this_iter": 0, "agent_timesteps_total": 8800, "timers": {"sample_time_ms": 313.941, "sample_throughput": 1274.125, "load_time_ms": 0.16, "load_throughput": 2501448.636, "learn_time_ms": 16.236, "learn_throughput": 24636.69, "update_time_ms": 0.843}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005, "total_loss": -0.014832358341664076, "policy_loss": -0.001266844319175675, "vf_loss": 0.003316783462651074, "vf_explained_var": -1.0, "kl": 7.96580910891187e-05, "entropy": 1.6882303953170776, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8800, "num_agent_steps_sampled": 8800, "num_steps_trained": 8800, "num_agent_steps_trained": 8800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 22, "training_iteration": 22, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-12", "timestamp": 1742376312, "time_this_iter_s": 0.29251575469970703, "time_total_s": 6.625732183456421, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fed550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.625732183456421, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13792338560771947, "mean_inference_ms": 0.6990948215228314, "mean_action_processing_ms": 0.037543887429136835, "mean_env_wait_ms": 0.5216930906114187, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9200, "timesteps_this_iter": 0, "agent_timesteps_total": 9200, "timers": {"sample_time_ms": 314.04, "sample_throughput": 1273.724, "load_time_ms": 0.16, "load_throughput": 2493640.904, "learn_time_ms": 16.214, "learn_throughput": 24670.671, "update_time_ms": 0.843}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 0.0005, "total_loss": -0.01756589114665985, "policy_loss": -0.0012664932943877716, "vf_loss": 0.00047000061022117734, "vf_explained_var": -1.0, "kl": 0.00013591526555289946, "entropy": 1.6769395470619202, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9200, "num_agent_steps_sampled": 9200, "num_steps_trained": 9200, "num_agent_steps_trained": 9200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 23, "training_iteration": 23, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-12", "timestamp": 1742376312, "time_this_iter_s": 0.3011739253997803, "time_total_s": 6.926906108856201, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6a790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.926906108856201, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 11.4, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13784005371504826, "mean_inference_ms": 0.6991999997258619, "mean_action_processing_ms": 0.037524299047049826, "mean_env_wait_ms": 0.5214643695509901, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9600, "timesteps_this_iter": 0, "agent_timesteps_total": 9600, "timers": {"sample_time_ms": 314.826, "sample_throughput": 1270.544, "load_time_ms": 0.16, "load_throughput": 2492899.851, "learn_time_ms": 16.207, "learn_throughput": 24680.942, "update_time_ms": 0.839}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005, "total_loss": -0.016643100418150425, "policy_loss": -2.9242634845993987e-05, "vf_loss": 0.0001801244870875962, "vf_explained_var": -1.0, "kl": 0.00013021552011971416, "entropy": 1.6793984174728394, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9600, "num_agent_steps_sampled": 9600, "num_steps_trained": 9600, "num_agent_steps_trained": 9600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 24, "training_iteration": 24, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-13", "timestamp": 1742376313, "time_this_iter_s": 0.3023526668548584, "time_total_s": 7.22925877571106, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6a3a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.22925877571106, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1377492294681414, "mean_inference_ms": 0.6993139859549403, "mean_action_processing_ms": 0.037508236707247324, "mean_env_wait_ms": 0.5212653820287446, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10000, "timesteps_this_iter": 0, "agent_timesteps_total": 10000, "timers": {"sample_time_ms": 316.18, "sample_throughput": 1265.103, "load_time_ms": 0.153, "load_throughput": 2607587.193, "learn_time_ms": 16.37, "learn_throughput": 24434.784, "update_time_ms": 0.851}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 0.0005, "total_loss": -0.017704947851598263, "policy_loss": -0.0011352876387533684, "vf_loss": 0.00012366783630568534, "vf_explained_var": -1.0, "kl": 0.00016543287680856333, "entropy": 1.6693331599235535, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10000, "num_agent_steps_sampled": 10000, "num_steps_trained": 10000, "num_agent_steps_trained": 10000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 25, "training_iteration": 25, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-13", "timestamp": 1742376313, "time_this_iter_s": 0.30439281463623047, "time_total_s": 7.53365159034729, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6aee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.53365159034729, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 10.8, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13765064345488345, "mean_inference_ms": 0.6994131337315641, "mean_action_processing_ms": 0.03749352310296235, "mean_env_wait_ms": 0.5211485426695522, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10400, "timesteps_this_iter": 0, "agent_timesteps_total": 10400, "timers": {"sample_time_ms": 318.379, "sample_throughput": 1256.364, "load_time_ms": 0.158, "load_throughput": 2537388.99, "learn_time_ms": 16.355, "learn_throughput": 24457.367, "update_time_ms": 0.843}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 0.0005, "total_loss": -0.017035769298672676, "policy_loss": -0.00041884244303203033, "vf_loss": 0.00032783513597678393, "vf_explained_var": -1.0, "kl": 0.00013083449133111102, "entropy": 1.6944762468338013, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10400, "num_agent_steps_sampled": 10400, "num_steps_trained": 10400, "num_agent_steps_trained": 10400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 26, "training_iteration": 26, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-13", "timestamp": 1742376313, "time_this_iter_s": 0.3072636127471924, "time_total_s": 7.840915203094482, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fed700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.840915203094482, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13754827156105698, "mean_inference_ms": 0.699515120393904, "mean_action_processing_ms": 0.03748050877037111, "mean_env_wait_ms": 0.5210445733086633, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10800, "timesteps_this_iter": 0, "agent_timesteps_total": 10800, "timers": {"sample_time_ms": 319.175, "sample_throughput": 1253.23, "load_time_ms": 0.157, "load_throughput": 2542002.424, "learn_time_ms": 16.351, "learn_throughput": 24463.787, "update_time_ms": 0.849}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 0.0005, "total_loss": -0.016488916240632534, "policy_loss": -9.48831404095074e-05, "vf_loss": 0.00034066149964928627, "vf_explained_var": -1.0, "kl": 8.631791840874037e-05, "entropy": 1.6734697222709656, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10800, "num_agent_steps_sampled": 10800, "num_steps_trained": 10800, "num_agent_steps_trained": 10800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 27, "training_iteration": 27, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-14", "timestamp": 1742376314, "time_this_iter_s": 0.30113816261291504, "time_total_s": 8.142053365707397, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fed4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.142053365707397, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 10.4, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1374438105609554, "mean_inference_ms": 0.6996006624813518, "mean_action_processing_ms": 0.03746934822341923, "mean_env_wait_ms": 0.5209342533887056, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11200, "timesteps_this_iter": 0, "agent_timesteps_total": 11200, "timers": {"sample_time_ms": 319.119, "sample_throughput": 1253.451, "load_time_ms": 0.157, "load_throughput": 2541617.331, "learn_time_ms": 16.342, "learn_throughput": 24477.421, "update_time_ms": 0.87}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 0.0005, "total_loss": -0.01806933991611004, "policy_loss": -0.0016335881967100008, "vf_loss": 0.00032031849696068093, "vf_explained_var": -1.0, "kl": 0.00013132940476712207, "entropy": 1.675606906414032, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11200, "num_agent_steps_sampled": 11200, "num_steps_trained": 11200, "num_agent_steps_trained": 11200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 28, "training_iteration": 28, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-14", "timestamp": 1742376314, "time_this_iter_s": 0.2955605983734131, "time_total_s": 8.43761396408081, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.43761396408081, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13734137910223596, "mean_inference_ms": 0.699677204173801, "mean_action_processing_ms": 0.03745980375184152, "mean_env_wait_ms": 0.5208249606187019, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11600, "timesteps_this_iter": 0, "agent_timesteps_total": 11600, "timers": {"sample_time_ms": 319.369, "sample_throughput": 1252.469, "load_time_ms": 0.164, "load_throughput": 2438903.329, "learn_time_ms": 16.333, "learn_throughput": 24489.748, "update_time_ms": 0.849}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 0.0005, "total_loss": -0.01866497378796339, "policy_loss": -0.0018182580638672619, "vf_loss": 1.58290804392891e-05, "vf_explained_var": -1.0, "kl": 0.00023802053946986312, "entropy": 1.6862547397613525, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11600, "num_agent_steps_sampled": 11600, "num_steps_trained": 11600, "num_agent_steps_trained": 11600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 29, "training_iteration": 29, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-14", "timestamp": 1742376314, "time_this_iter_s": 0.298983097076416, "time_total_s": 8.736597061157227, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6a040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.736597061157227, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 10.5, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13748468845915038, "mean_inference_ms": 0.6997647699478305, "mean_action_processing_ms": 0.03745166318552189, "mean_env_wait_ms": 0.5207299324902805, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12000, "timesteps_this_iter": 0, "agent_timesteps_total": 12000, "timers": {"sample_time_ms": 320.525, "sample_throughput": 1247.952, "load_time_ms": 0.164, "load_throughput": 2439612.622, "learn_time_ms": 16.391, "learn_throughput": 24403.614, "update_time_ms": 0.848}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 0.0005, "total_loss": -0.017078996635973454, "policy_loss": -0.00028326569707104454, "vf_loss": 5.3897671023150906e-05, "vf_explained_var": -1.0, "kl": 0.0002383070699205625, "entropy": 1.6849632263183594, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12000, "num_agent_steps_sampled": 12000, "num_steps_trained": 12000, "num_agent_steps_trained": 12000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 30, "training_iteration": 30, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-15", "timestamp": 1742376315, "time_this_iter_s": 0.348203182220459, "time_total_s": 9.084800243377686, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6aee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.084800243377686, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13760258908794018, "mean_inference_ms": 0.6998474472928249, "mean_action_processing_ms": 0.03744489653849792, "mean_env_wait_ms": 0.5206853771602308, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12400, "timesteps_this_iter": 0, "agent_timesteps_total": 12400, "timers": {"sample_time_ms": 319.847, "sample_throughput": 1250.599, "load_time_ms": 0.169, "load_throughput": 2361325.264, "learn_time_ms": 17.964, "learn_throughput": 22266.247, "update_time_ms": 0.905}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 0.0005, "total_loss": -0.017381928861141205, "policy_loss": -0.0008779948879968913, "vf_loss": 0.00043914420530200005, "vf_explained_var": -1.0, "kl": 0.00016418809776164167, "entropy": 1.6943077445030212, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12400, "num_agent_steps_sampled": 12400, "num_steps_trained": 12400, "num_agent_steps_trained": 12400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 31, "training_iteration": 31, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-15", "timestamp": 1742376315, "time_this_iter_s": 0.324892520904541, "time_total_s": 9.409692764282227, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fed700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.409692764282227, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 11.6, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13772271032349273, "mean_inference_ms": 0.7001255244273645, "mean_action_processing_ms": 0.03744824546681147, "mean_env_wait_ms": 0.5207568745916784, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12800, "timesteps_this_iter": 0, "agent_timesteps_total": 12800, "timers": {"sample_time_ms": 330.175, "sample_throughput": 1211.48, "load_time_ms": 0.169, "load_throughput": 2359996.624, "learn_time_ms": 18.359, "learn_throughput": 21787.489, "update_time_ms": 0.914}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 0.0005, "total_loss": -0.016612032428383827, "policy_loss": 0.00018723785935392812, "vf_loss": 0.00010920854037976824, "vf_explained_var": -1.0, "kl": 0.0001420100957034709, "entropy": 1.6908484101295471, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12800, "num_agent_steps_sampled": 12800, "num_steps_trained": 12800, "num_agent_steps_trained": 12800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 32, "training_iteration": 32, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-15", "timestamp": 1742376315, "time_this_iter_s": 0.37607812881469727, "time_total_s": 9.785770893096924, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fed3a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.785770893096924, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13782415892825914, "mean_inference_ms": 0.7003993940929423, "mean_action_processing_ms": 0.03745180958087279, "mean_env_wait_ms": 0.5208240368790872, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13200, "timesteps_this_iter": 0, "agent_timesteps_total": 13200, "timers": {"sample_time_ms": 331.349, "sample_throughput": 1207.186, "load_time_ms": 0.169, "load_throughput": 2365320.175, "learn_time_ms": 18.353, "learn_throughput": 21794.848, "update_time_ms": 0.913}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 0.0005, "total_loss": -0.016873584128916264, "policy_loss": 5.365967619586076e-05, "vf_loss": 6.183767254697159e-05, "vf_explained_var": -1.0, "kl": 4.909581381173922e-05, "entropy": 1.6989083290100098, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13200, "num_agent_steps_sampled": 13200, "num_steps_trained": 13200, "num_agent_steps_trained": 13200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 33, "training_iteration": 33, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-16", "timestamp": 1742376316, "time_this_iter_s": 0.30475640296936035, "time_total_s": 10.090527296066284, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6af70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.090527296066284, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 18.9, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13792073339318434, "mean_inference_ms": 0.700763200184447, "mean_action_processing_ms": 0.03745980846939578, "mean_env_wait_ms": 0.5209476230485364, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13600, "timesteps_this_iter": 0, "agent_timesteps_total": 13600, "timers": {"sample_time_ms": 335.668, "sample_throughput": 1191.653, "load_time_ms": 0.187, "load_throughput": 2138042.054, "learn_time_ms": 18.722, "learn_throughput": 21365.663, "update_time_ms": 0.925}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 0.0005, "total_loss": -0.01722566969692707, "policy_loss": -0.0002690720453393247, "vf_loss": 3.5230190405854955e-05, "vf_explained_var": -1.0, "kl": 2.211447919986398e-05, "entropy": 1.6991822719573975, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13600, "num_agent_steps_sampled": 13600, "num_steps_trained": 13600, "num_agent_steps_trained": 13600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 34, "training_iteration": 34, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-16", "timestamp": 1742376316, "time_this_iter_s": 0.3489079475402832, "time_total_s": 10.439435243606567, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f615e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.439435243606567, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1380118236540305, "mean_inference_ms": 0.7011877829986175, "mean_action_processing_ms": 0.03747213840845522, "mean_env_wait_ms": 0.5211304300144232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14000, "timesteps_this_iter": 0, "agent_timesteps_total": 14000, "timers": {"sample_time_ms": 340.214, "sample_throughput": 1175.73, "load_time_ms": 0.187, "load_throughput": 2138587.126, "learn_time_ms": 18.801, "learn_throughput": 21275.467, "update_time_ms": 0.936}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1641532182693482e-11, "cur_lr": 0.0005, "total_loss": -0.01751019712537527, "policy_loss": -0.000551651741844239, "vf_loss": 5.100781527289655e-05, "vf_explained_var": -1.0, "kl": 3.418080669215229e-05, "entropy": 1.7009552717208862, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14000, "num_agent_steps_sampled": 14000, "num_steps_trained": 14000, "num_agent_steps_trained": 14000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 35, "training_iteration": 35, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-16", "timestamp": 1742376316, "time_this_iter_s": 0.34705543518066406, "time_total_s": 10.786490678787231, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.786490678787231, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 14.6, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13810279605558884, "mean_inference_ms": 0.7016589833335484, "mean_action_processing_ms": 0.03748704774791786, "mean_env_wait_ms": 0.5213362970219183, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14400, "timesteps_this_iter": 0, "agent_timesteps_total": 14400, "timers": {"sample_time_ms": 343.239, "sample_throughput": 1165.37, "load_time_ms": 0.191, "load_throughput": 2090097.92, "learn_time_ms": 18.922, "learn_throughput": 21139.313, "update_time_ms": 0.939}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.820766091346741e-12, "cur_lr": 0.0005, "total_loss": -0.01759716309607029, "policy_loss": -0.0006697547272778159, "vf_loss": 1.2286438050068682e-05, "vf_explained_var": -1.0, "kl": 4.6712937867954274e-05, "entropy": 1.6939696669578552, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14400, "num_agent_steps_sampled": 14400, "num_steps_trained": 14400, "num_agent_steps_trained": 14400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 36, "training_iteration": 36, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-17", "timestamp": 1742376317, "time_this_iter_s": 0.3377971649169922, "time_total_s": 11.124287843704224, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11.124287843704224, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1381798301492748, "mean_inference_ms": 0.7020928195562941, "mean_action_processing_ms": 0.037500533745154815, "mean_env_wait_ms": 0.5215210758646486, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14800, "timesteps_this_iter": 0, "agent_timesteps_total": 14800, "timers": {"sample_time_ms": 343.224, "sample_throughput": 1165.42, "load_time_ms": 0.202, "load_throughput": 1984060.549, "learn_time_ms": 19.051, "learn_throughput": 20996.322, "update_time_ms": 0.942}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9103830456733705e-12, "cur_lr": 0.0005, "total_loss": -0.01697556860744953, "policy_loss": -7.895469665442079e-05, "vf_loss": 1.533736394776497e-05, "vf_explained_var": -1.0, "kl": 3.939557486976053e-05, "entropy": 1.6911953687667847, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14800, "num_agent_steps_sampled": 14800, "num_steps_trained": 14800, "num_agent_steps_trained": 14800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 37, "training_iteration": 37, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-17", "timestamp": 1742376317, "time_this_iter_s": 0.3005976676940918, "time_total_s": 11.424885511398315, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f06dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11.424885511398315, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 13.2, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.138246521615816, "mean_inference_ms": 0.7025089362610341, "mean_action_processing_ms": 0.03751332729456323, "mean_env_wait_ms": 0.5216955585305133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15200, "timesteps_this_iter": 0, "agent_timesteps_total": 15200, "timers": {"sample_time_ms": 344.717, "sample_throughput": 1160.372, "load_time_ms": 0.21, "load_throughput": 1902825.905, "learn_time_ms": 19.096, "learn_throughput": 20946.41, "update_time_ms": 0.928}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4551915228366853e-12, "cur_lr": 0.0005, "total_loss": -0.017369789071381092, "policy_loss": -0.000518174921162462, "vf_loss": 8.557802175346296e-06, "vf_explained_var": -1.0, "kl": 2.7560948389959705e-05, "entropy": 1.686017632484436, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15200, "num_agent_steps_sampled": 15200, "num_steps_trained": 15200, "num_agent_steps_trained": 15200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 38, "training_iteration": 38, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-17", "timestamp": 1742376317, "time_this_iter_s": 0.3075551986694336, "time_total_s": 11.732440710067749, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11.732440710067749, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1383024136775511, "mean_inference_ms": 0.7028936009050728, "mean_action_processing_ms": 0.03752486954364238, "mean_env_wait_ms": 0.5218552265141992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15600, "timesteps_this_iter": 0, "agent_timesteps_total": 15600, "timers": {"sample_time_ms": 344.801, "sample_throughput": 1160.089, "load_time_ms": 0.203, "load_throughput": 1965926.412, "learn_time_ms": 19.086, "learn_throughput": 20957.374, "update_time_ms": 0.932}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.275957614183426e-13, "cur_lr": 0.0005, "total_loss": -0.017875511199235916, "policy_loss": -0.0009412378235715835, "vf_loss": 1.1447348697402049e-05, "vf_explained_var": -1.0, "kl": 5.1201021011748615e-05, "entropy": 1.6945722103118896, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15600, "num_agent_steps_sampled": 15600, "num_steps_trained": 15600, "num_agent_steps_trained": 15600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 39, "training_iteration": 39, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-18", "timestamp": 1742376318, "time_this_iter_s": 0.30045223236083984, "time_total_s": 12.032892942428589, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fed820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.032892942428589, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1384930077293876, "mean_inference_ms": 0.7032593357174177, "mean_action_processing_ms": 0.03753612143886429, "mean_env_wait_ms": 0.522034414770031, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16000, "timesteps_this_iter": 0, "agent_timesteps_total": 16000, "timers": {"sample_time_ms": 346.098, "sample_throughput": 1155.742, "load_time_ms": 0.203, "load_throughput": 1968925.713, "learn_time_ms": 19.179, "learn_throughput": 20855.615, "update_time_ms": 0.957}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.637978807091713e-13, "cur_lr": 0.0005, "total_loss": -0.01773823704570532, "policy_loss": -0.0009952354151749887, "vf_loss": 3.561174526112154e-05, "vf_explained_var": -1.0, "kl": 7.309277286238203e-05, "entropy": 1.6778613924980164, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16000, "num_agent_steps_sampled": 16000, "num_steps_trained": 16000, "num_agent_steps_trained": 16000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 40, "training_iteration": 40, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-18", "timestamp": 1742376318, "time_this_iter_s": 0.36164426803588867, "time_total_s": 12.394537210464478, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.394537210464478, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 11.5, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13866410187306855, "mean_inference_ms": 0.7036155798838093, "mean_action_processing_ms": 0.037547377044737325, "mean_env_wait_ms": 0.5222325013828478, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16400, "timesteps_this_iter": 0, "agent_timesteps_total": 16400, "timers": {"sample_time_ms": 347.549, "sample_throughput": 1150.917, "load_time_ms": 0.203, "load_throughput": 1972165.981, "learn_time_ms": 17.649, "learn_throughput": 22664.012, "update_time_ms": 0.93}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8189894035458566e-13, "cur_lr": 0.0005, "total_loss": -0.01727319974452257, "policy_loss": -0.00039630666957235494, "vf_loss": 3.073509560636012e-05, "vf_explained_var": -1.0, "kl": 7.985283921807529e-05, "entropy": 1.6907623410224915, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16400, "num_agent_steps_sampled": 16400, "num_steps_trained": 16400, "num_agent_steps_trained": 16400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 41, "training_iteration": 41, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-18", "timestamp": 1742376318, "time_this_iter_s": 0.3178868293762207, "time_total_s": 12.712424039840698, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b183a93a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.712424039840698, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13881914906442874, "mean_inference_ms": 0.7039443033709101, "mean_action_processing_ms": 0.03755720696430991, "mean_env_wait_ms": 0.5224168084236782, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16800, "timesteps_this_iter": 0, "agent_timesteps_total": 16800, "timers": {"sample_time_ms": 337.662, "sample_throughput": 1184.616, "load_time_ms": 0.212, "load_throughput": 1884022.01, "learn_time_ms": 17.273, "learn_throughput": 23157.373, "update_time_ms": 0.92}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 0.0005, "total_loss": -0.017110807821154594, "policy_loss": -0.0002321623230834291, "vf_loss": 8.946168009060784e-06, "vf_explained_var": -1.0, "kl": 4.480451280830522e-05, "entropy": 1.6887596249580383, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16800, "num_agent_steps_sampled": 16800, "num_steps_trained": 16800, "num_agent_steps_trained": 16800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 42, "training_iteration": 42, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-19", "timestamp": 1742376319, "time_this_iter_s": 0.2999863624572754, "time_total_s": 13.012410402297974, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fa5af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.012410402297974, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 13.3, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13895699366359013, "mean_inference_ms": 0.7042424417224245, "mean_action_processing_ms": 0.03756584519725571, "mean_env_wait_ms": 0.5225969086601814, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17200, "timesteps_this_iter": 0, "agent_timesteps_total": 17200, "timers": {"sample_time_ms": 336.55, "sample_throughput": 1188.53, "load_time_ms": 0.213, "load_throughput": 1880221.45, "learn_time_ms": 17.301, "learn_throughput": 23120.673, "update_time_ms": 0.929}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 0.0005, "total_loss": -0.017948889173567295, "policy_loss": -0.0009712394885719178, "vf_loss": 1.3699684586754302e-05, "vf_explained_var": -1.0, "kl": 4.290633363712715e-05, "entropy": 1.6991353631019592, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17200, "num_agent_steps_sampled": 17200, "num_steps_trained": 17200, "num_agent_steps_trained": 17200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 43, "training_iteration": 43, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-19", "timestamp": 1742376319, "time_this_iter_s": 0.30065369606018066, "time_total_s": 13.313064098358154, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f063a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.313064098358154, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13907899252626688, "mean_inference_ms": 0.7045140950787686, "mean_action_processing_ms": 0.03757352567566729, "mean_env_wait_ms": 0.5227627916978087, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17600, "timesteps_this_iter": 0, "agent_timesteps_total": 17600, "timers": {"sample_time_ms": 331.616, "sample_throughput": 1206.215, "load_time_ms": 0.2, "load_throughput": 1998715.273, "learn_time_ms": 16.959, "learn_throughput": 23586.628, "update_time_ms": 0.913}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2737367544323207e-14, "cur_lr": 0.0005, "total_loss": -0.0174991674721241, "policy_loss": -0.0006592154433011643, "vf_loss": 7.55249720896245e-06, "vf_explained_var": -1.0, "kl": 6.124410287355886e-05, "entropy": 1.6847513318061829, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17600, "num_agent_steps_sampled": 17600, "num_steps_trained": 17600, "num_agent_steps_trained": 17600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 44, "training_iteration": 44, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-19", "timestamp": 1742376319, "time_this_iter_s": 0.2969794273376465, "time_total_s": 13.6100435256958, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f61e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.6100435256958, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 10.8, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13919650304461031, "mean_inference_ms": 0.7047792785973741, "mean_action_processing_ms": 0.03758107081707177, "mean_env_wait_ms": 0.5229216266146308, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18000, "timesteps_this_iter": 0, "agent_timesteps_total": 18000, "timers": {"sample_time_ms": 327.783, "sample_throughput": 1220.318, "load_time_ms": 0.208, "load_throughput": 1925317.42, "learn_time_ms": 16.981, "learn_throughput": 23555.202, "update_time_ms": 0.892}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 0.0005, "total_loss": -0.01742649357765913, "policy_loss": -0.0005451920581975855, "vf_loss": 3.2397618269897066e-05, "vf_explained_var": -1.0, "kl": 6.113293521570196e-05, "entropy": 1.691369116306305, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 18000, "num_agent_steps_sampled": 18000, "num_steps_trained": 18000, "num_agent_steps_trained": 18000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 45, "training_iteration": 45, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-20", "timestamp": 1742376320, "time_this_iter_s": 0.3140084743499756, "time_total_s": 13.924052000045776, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.924052000045776, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13930001268545816, "mean_inference_ms": 0.7050181919347362, "mean_action_processing_ms": 0.03758775626990549, "mean_env_wait_ms": 0.5230611814237693, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18400, "timesteps_this_iter": 0, "agent_timesteps_total": 18400, "timers": {"sample_time_ms": 323.271, "sample_throughput": 1237.354, "load_time_ms": 0.198, "load_throughput": 2018675.972, "learn_time_ms": 16.852, "learn_throughput": 23736.562, "update_time_ms": 0.906}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 0.0005, "total_loss": -0.017637132667005062, "policy_loss": -0.0007748371432532153, "vf_loss": 5.1171728046028875e-06, "vf_explained_var": -1.0, "kl": 7.310908538382677e-05, "entropy": 1.6867406368255615, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 18400, "num_agent_steps_sampled": 18400, "num_steps_trained": 18400, "num_agent_steps_trained": 18400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 46, "training_iteration": 46, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-20", "timestamp": 1742376320, "time_this_iter_s": 0.29236650466918945, "time_total_s": 14.216418504714966, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b183a9e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.216418504714966, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 11.9, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1393983365003445, "mean_inference_ms": 0.7052522614228486, "mean_action_processing_ms": 0.03759461682886262, "mean_env_wait_ms": 0.5231929137123791, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18800, "timesteps_this_iter": 0, "agent_timesteps_total": 18800, "timers": {"sample_time_ms": 324.022, "sample_throughput": 1234.485, "load_time_ms": 0.188, "load_throughput": 2131522.805, "learn_time_ms": 16.775, "learn_throughput": 23845.058, "update_time_ms": 0.895}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 0.0005, "total_loss": -0.017548575066030025, "policy_loss": -0.0006588953966275568, "vf_loss": 3.437340183154447e-06, "vf_explained_var": -1.0, "kl": 9.028840410785222e-05, "entropy": 1.6893121004104614, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 18800, "num_agent_steps_sampled": 18800, "num_steps_trained": 18800, "num_agent_steps_trained": 18800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 47, "training_iteration": 47, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-20", "timestamp": 1742376320, "time_this_iter_s": 0.3095741271972656, "time_total_s": 14.525992631912231, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17f6a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.525992631912231, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13949238868832728, "mean_inference_ms": 0.7054709716986881, "mean_action_processing_ms": 0.0376008788552254, "mean_env_wait_ms": 0.5233121071269223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19200, "timesteps_this_iter": 0, "agent_timesteps_total": 19200, "timers": {"sample_time_ms": 323.154, "sample_throughput": 1237.801, "load_time_ms": 0.189, "load_throughput": 2111138.291, "learn_time_ms": 17.133, "learn_throughput": 23347.216, "update_time_ms": 0.907}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 0.0005, "total_loss": -0.018581527285277843, "policy_loss": -0.0018199920235204559, "vf_loss": 3.892500899382867e-06, "vf_explained_var": -1.0, "kl": 0.00010591398707934796, "entropy": 1.67654287815094, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 19200, "num_agent_steps_sampled": 19200, "num_steps_trained": 19200, "num_agent_steps_trained": 19200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 48, "training_iteration": 48, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-21", "timestamp": 1742376321, "time_this_iter_s": 0.3061249256134033, "time_total_s": 14.832117557525635, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fed280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.832117557525635, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 13.0, "ram_util_percent": 20.8}}
{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 200.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13957769172465212, "mean_inference_ms": 0.7056847276422574, "mean_action_processing_ms": 0.03760714850887812, "mean_env_wait_ms": 0.5234257025550293, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19600, "timesteps_this_iter": 0, "agent_timesteps_total": 19600, "timers": {"sample_time_ms": 324.523, "sample_throughput": 1232.578, "load_time_ms": 0.192, "load_throughput": 2081282.223, "learn_time_ms": 17.206, "learn_throughput": 23247.864, "update_time_ms": 0.911}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.105427357601002e-16, "cur_lr": 0.0005, "total_loss": -0.016841528937220573, "policy_loss": 7.221460517037315e-05, "vf_loss": 4.069024271302624e-06, "vf_explained_var": -1.0, "kl": 0.00010117041802870652, "entropy": 1.6917819380760193, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 19600, "num_agent_steps_sampled": 19600, "num_steps_trained": 19600, "num_agent_steps_trained": 19600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 49, "training_iteration": 49, "trial_id": "08cc3_00000", "experiment_id": "685762e59d62465c8c7d2e2446f0f68f", "date": "2025-03-19_10-25-21", "timestamp": 1742376321, "time_this_iter_s": 0.3075542449951172, "time_total_s": 15.139671802520752, "pid": 13785, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 400, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "overcooked", "env_args": {"map_name": "asymmetric_advantages", "horizon": 200}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32))", "space_act": "Discrete(6)", "num_agents": 2, "episode_limit": 200, "policy_mapping_info": {"all_scenario": {"description": "overcook all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "overcooked_asymmetric_advantages", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x762b17fed430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 400, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.139671802520752, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {}}
