{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 60, "timesteps_this_iter": 0, "agent_timesteps_total": 180, "timers": {"sample_time_ms": 105.674, "sample_throughput": 567.782, "load_time_ms": 0.349, "load_throughput": 171780.369, "learn_time_ms": 16.737, "learn_throughput": 3584.773, "update_time_ms": 1.055}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 0.0005, "total_loss": 4515679.5, "policy_loss": -0.006179622953965236, "vf_loss": 4515679.5, "vf_explained_var": -1.7881393432617188e-07, "kl": 0.0006680873339064419, "entropy": 1.9452070593833923, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 60, "num_agent_steps_sampled": 180, "num_steps_trained": 60, "num_agent_steps_trained": 180}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-31", "timestamp": 1742303371, "time_this_iter_s": 0.10900998115539551, "time_total_s": 0.10900998115539551, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.10900998115539551, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 16.1, "ram_util_percent": 21.0}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0], "episode_lengths": [100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23793188993595846, "mean_inference_ms": 0.7665866662648098, "mean_action_processing_ms": 0.04966002850493123, "mean_env_wait_ms": 0.28840766465368345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 120, "timesteps_this_iter": 0, "agent_timesteps_total": 360, "timers": {"sample_time_ms": 109.497, "sample_throughput": 547.961, "load_time_ms": 0.285, "load_throughput": 210592.669, "learn_time_ms": 15.2, "learn_throughput": 3947.487, "update_time_ms": 1.17}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 0.0005, "total_loss": 8042640.0, "policy_loss": -0.004313628654927015, "vf_loss": 8042639.5, "vf_explained_var": 0.0, "kl": 0.0005110576549078871, "entropy": 1.9374894499778748, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 120, "num_agent_steps_sampled": 360, "num_steps_trained": 120, "num_agent_steps_trained": 360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1, "training_iteration": 2, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-31", "timestamp": 1742303371, "time_this_iter_s": 0.098724365234375, "time_total_s": 0.2077343463897705, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.2077343463897705, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0], "episode_lengths": [100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23793188993595846, "mean_inference_ms": 0.7665866662648098, "mean_action_processing_ms": 0.04966002850493123, "mean_env_wait_ms": 0.28840766465368345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 180, "timesteps_this_iter": 0, "agent_timesteps_total": 540, "timers": {"sample_time_ms": 108.862, "sample_throughput": 551.156, "load_time_ms": 0.237, "load_throughput": 252668.916, "learn_time_ms": 14.496, "learn_throughput": 4138.98, "update_time_ms": 1.128}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 0.0005, "total_loss": 10552789.0, "policy_loss": -0.004267210471958549, "vf_loss": 10552789.0, "vf_explained_var": 0.0, "kl": 0.0005096766180057166, "entropy": 1.923602283000946, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 180, "num_agent_steps_sampled": 540, "num_steps_trained": 180, "num_agent_steps_trained": 540, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1, "training_iteration": 3, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-31", "timestamp": 1742303371, "time_this_iter_s": 0.0915372371673584, "time_total_s": 0.2992715835571289, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.2992715835571289, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0], "episode_lengths": [100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22274134135459667, "mean_inference_ms": 0.7672258939383627, "mean_action_processing_ms": 0.04922933635068714, "mean_env_wait_ms": 0.28934683076500023, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 240, "timesteps_this_iter": 0, "agent_timesteps_total": 720, "timers": {"sample_time_ms": 110.5, "sample_throughput": 542.986, "load_time_ms": 0.214, "load_throughput": 280009.168, "learn_time_ms": 14.091, "learn_throughput": 4258.051, "update_time_ms": 1.131}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.025, "cur_lr": 0.0005, "total_loss": 2133026.25, "policy_loss": -0.00329151392086402, "vf_loss": 2133026.125, "vf_explained_var": 1.7881393432617188e-07, "kl": 0.0006840189365355798, "entropy": 1.9019273519515991, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 240, "num_agent_steps_sampled": 720, "num_steps_trained": 240, "num_agent_steps_trained": 720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2, "training_iteration": 4, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-31", "timestamp": 1742303371, "time_this_iter_s": 0.09982848167419434, "time_total_s": 0.39910006523132324, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.39910006523132324, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21472785935010838, "mean_inference_ms": 0.7654533140105527, "mean_action_processing_ms": 0.04897419849993661, "mean_env_wait_ms": 0.2890019609387684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 300, "timesteps_this_iter": 0, "agent_timesteps_total": 900, "timers": {"sample_time_ms": 109.757, "sample_throughput": 546.664, "load_time_ms": 0.224, "load_throughput": 268292.367, "learn_time_ms": 13.662, "learn_throughput": 4391.865, "update_time_ms": 1.064}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0125, "cur_lr": 0.0005, "total_loss": 19168377.0, "policy_loss": -0.0015160140633199148, "vf_loss": 19168377.0, "vf_explained_var": 2.9802322387695312e-08, "kl": 0.0007482186192646623, "entropy": 1.86761474609375, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 300, "num_agent_steps_sampled": 900, "num_steps_trained": 300, "num_agent_steps_trained": 900, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3, "training_iteration": 5, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-31", "timestamp": 1742303371, "time_this_iter_s": 0.09308433532714844, "time_total_s": 0.4921844005584717, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.4921844005584717, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21472785935010838, "mean_inference_ms": 0.7654533140105527, "mean_action_processing_ms": 0.04897419849993661, "mean_env_wait_ms": 0.2890019609387684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 360, "timesteps_this_iter": 0, "agent_timesteps_total": 1080, "timers": {"sample_time_ms": 109.71, "sample_throughput": 546.895, "load_time_ms": 0.211, "load_throughput": 284896.121, "learn_time_ms": 13.606, "learn_throughput": 4409.912, "update_time_ms": 1.036}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00625, "cur_lr": 0.0005, "total_loss": 4514446.75, "policy_loss": -0.0005434996357891464, "vf_loss": 4514446.75, "vf_explained_var": 0.0, "kl": 0.000378735492170712, "entropy": 1.830850899219513, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 360, "num_agent_steps_sampled": 1080, "num_steps_trained": 360, "num_agent_steps_trained": 1080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3, "training_iteration": 6, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-31", "timestamp": 1742303371, "time_this_iter_s": 0.09469985961914062, "time_total_s": 0.5868842601776123, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.5868842601776123, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20910663448737565, "mean_inference_ms": 0.763448845125098, "mean_action_processing_ms": 0.04884214279883741, "mean_env_wait_ms": 0.28891075082412854, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 420, "timesteps_this_iter": 0, "agent_timesteps_total": 1260, "timers": {"sample_time_ms": 109.542, "sample_throughput": 547.736, "load_time_ms": 0.202, "load_throughput": 297418.146, "learn_time_ms": 13.313, "learn_throughput": 4506.889, "update_time_ms": 1.021}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003125, "cur_lr": 0.0005, "total_loss": 8038119.75, "policy_loss": 0.00015743242402077584, "vf_loss": 8038119.75, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.0001100806362255291, "entropy": 1.817181944847107, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 420, "num_agent_steps_sampled": 1260, "num_steps_trained": 420, "num_agent_steps_trained": 1260, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4, "training_iteration": 7, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09476113319396973, "time_total_s": 0.681645393371582, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.681645393371582, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 13.8, "ram_util_percent": 21.0}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20910663448737565, "mean_inference_ms": 0.763448845125098, "mean_action_processing_ms": 0.04884214279883741, "mean_env_wait_ms": 0.28891075082412854, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 480, "timesteps_this_iter": 0, "agent_timesteps_total": 1440, "timers": {"sample_time_ms": 109.358, "sample_throughput": 548.656, "load_time_ms": 0.194, "load_throughput": 308783.117, "learn_time_ms": 13.241, "learn_throughput": 4531.362, "update_time_ms": 1.003}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015625, "cur_lr": 0.0005, "total_loss": 10550570.5, "policy_loss": -0.0006287233852262375, "vf_loss": 10550570.5, "vf_explained_var": -5.960464477539063e-08, "kl": 0.00011353280569892377, "entropy": 1.8078081011772156, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 480, "num_agent_steps_sampled": 1440, "num_steps_trained": 480, "num_agent_steps_trained": 1440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4, "training_iteration": 8, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09236669540405273, "time_total_s": 0.7740120887756348, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.7740120887756348, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20511092196910644, "mean_inference_ms": 0.7616528286441501, "mean_action_processing_ms": 0.0487002720175888, "mean_env_wait_ms": 0.2886356907783315, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 540, "timesteps_this_iter": 0, "agent_timesteps_total": 1620, "timers": {"sample_time_ms": 109.325, "sample_throughput": 548.825, "load_time_ms": 0.189, "load_throughput": 317038.656, "learn_time_ms": 13.023, "learn_throughput": 4607.147, "update_time_ms": 0.993}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00078125, "cur_lr": 0.0005, "total_loss": 2131146.25, "policy_loss": -0.00041964914481695814, "vf_loss": 2131146.375, "vf_explained_var": 1.1920928955078125e-07, "kl": 9.247038960680243e-05, "entropy": 1.8001827001571655, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 540, "num_agent_steps_sampled": 1620, "num_steps_trained": 540, "num_agent_steps_trained": 1620, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5, "training_iteration": 9, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.0938720703125, "time_total_s": 0.8678841590881348, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.8678841590881348, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2020047474739507, "mean_inference_ms": 0.7605157646224018, "mean_action_processing_ms": 0.04858949193026213, "mean_env_wait_ms": 0.28839045384725126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 600, "timesteps_this_iter": 0, "agent_timesteps_total": 1800, "timers": {"sample_time_ms": 109.132, "sample_throughput": 549.795, "load_time_ms": 0.185, "load_throughput": 325097.843, "learn_time_ms": 12.998, "learn_throughput": 4615.948, "update_time_ms": 1.023}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.000390625, "cur_lr": 0.0005, "total_loss": 19157992.0, "policy_loss": -0.0019646654526397356, "vf_loss": 19157994.0, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.00012868067056892585, "entropy": 1.7877967953681946, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 600, "num_agent_steps_sampled": 1800, "num_steps_trained": 600, "num_agent_steps_trained": 1800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6, "training_iteration": 10, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09428215026855469, "time_total_s": 0.9621663093566895, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.9621663093566895, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2020047474739507, "mean_inference_ms": 0.7605157646224018, "mean_action_processing_ms": 0.04858949193026213, "mean_env_wait_ms": 0.28839045384725126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 660, "timesteps_this_iter": 0, "agent_timesteps_total": 1980, "timers": {"sample_time_ms": 109.239, "sample_throughput": 549.255, "load_time_ms": 0.164, "load_throughput": 365198.433, "learn_time_ms": 12.519, "learn_throughput": 4792.897, "update_time_ms": 1.02}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0001953125, "cur_lr": 0.0005, "total_loss": 4512822.5, "policy_loss": -0.0011532826349132108, "vf_loss": 4512822.75, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.00015547701533691338, "entropy": 1.7713152766227722, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 660, "num_agent_steps_sampled": 1980, "num_steps_trained": 660, "num_agent_steps_trained": 1980, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6, "training_iteration": 11, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09014034271240234, "time_total_s": 1.0523066520690918, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ae50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.0523066520690918, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19952536526021533, "mean_inference_ms": 0.7594520436158492, "mean_action_processing_ms": 0.04847705438213924, "mean_env_wait_ms": 0.28827412117870743, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 720, "timesteps_this_iter": 0, "agent_timesteps_total": 2160, "timers": {"sample_time_ms": 109.1, "sample_throughput": 549.956, "load_time_ms": 0.156, "load_throughput": 383391.59, "learn_time_ms": 12.446, "learn_throughput": 4820.984, "update_time_ms": 1.001}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005, "total_loss": 8032333.75, "policy_loss": -0.0004023220778126557, "vf_loss": 8032333.5, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.00011308938311760386, "entropy": 1.7581024169921875, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 720, "num_agent_steps_sampled": 2160, "num_steps_trained": 720, "num_agent_steps_trained": 2160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7, "training_iteration": 12, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09733057022094727, "time_total_s": 1.149637222290039, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772af70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.149637222290039, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19952536526021533, "mean_inference_ms": 0.7594520436158492, "mean_action_processing_ms": 0.04847705438213924, "mean_env_wait_ms": 0.28827412117870743, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 780, "timesteps_this_iter": 0, "agent_timesteps_total": 2340, "timers": {"sample_time_ms": 109.347, "sample_throughput": 548.712, "load_time_ms": 0.157, "load_throughput": 383216.446, "learn_time_ms": 12.494, "learn_throughput": 4802.244, "update_time_ms": 1.013}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 0.0005, "total_loss": 10547987.0, "policy_loss": 0.000219048393120147, "vf_loss": 10547987.5, "vf_explained_var": 2.384185791015625e-07, "kl": 8.271606923027086e-05, "entropy": 1.7472496032714844, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 780, "num_agent_steps_sampled": 2340, "num_steps_trained": 780, "num_agent_steps_trained": 2340, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7, "training_iteration": 13, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09575796127319336, "time_total_s": 1.2453951835632324, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277510d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.2453951835632324, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 13.2, "ram_util_percent": 21.0}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19767302506545828, "mean_inference_ms": 0.758468337417842, "mean_action_processing_ms": 0.04841785973688513, "mean_env_wait_ms": 0.28825746869956403, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 840, "timesteps_this_iter": 0, "agent_timesteps_total": 2520, "timers": {"sample_time_ms": 108.865, "sample_throughput": 551.144, "load_time_ms": 0.164, "load_throughput": 366528.168, "learn_time_ms": 12.417, "learn_throughput": 4832.203, "update_time_ms": 1.009}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 0.0005, "total_loss": 2129015.25, "policy_loss": -0.000597087562912435, "vf_loss": 2129015.25, "vf_explained_var": 0.0, "kl": 9.535675672789345e-05, "entropy": 1.7460607886314392, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 840, "num_agent_steps_sampled": 2520, "num_steps_trained": 840, "num_agent_steps_trained": 2520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8, "training_iteration": 14, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09513401985168457, "time_total_s": 1.340529203414917, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.340529203414917, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19612100260170653, "mean_inference_ms": 0.7578530078454696, "mean_action_processing_ms": 0.04837195248168945, "mean_env_wait_ms": 0.28839855145891957, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 900, "timesteps_this_iter": 0, "agent_timesteps_total": 2700, "timers": {"sample_time_ms": 109.145, "sample_throughput": 549.729, "load_time_ms": 0.163, "load_throughput": 368298.317, "learn_time_ms": 12.543, "learn_throughput": 4783.568, "update_time_ms": 1.017}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 0.0005, "total_loss": 19146602.0, "policy_loss": -0.0008357799922418252, "vf_loss": 19146602.0, "vf_explained_var": 5.960464477539063e-08, "kl": 9.909634831650749e-05, "entropy": 1.7404439449310303, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 900, "num_agent_steps_sampled": 2700, "num_steps_trained": 900, "num_agent_steps_trained": 2700, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9, "training_iteration": 15, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09710144996643066, "time_total_s": 1.4376306533813477, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.4376306533813477, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19612100260170653, "mean_inference_ms": 0.7578530078454696, "mean_action_processing_ms": 0.04837195248168945, "mean_env_wait_ms": 0.28839855145891957, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 960, "timesteps_this_iter": 0, "agent_timesteps_total": 2880, "timers": {"sample_time_ms": 109.269, "sample_throughput": 549.101, "load_time_ms": 0.163, "load_throughput": 368029.014, "learn_time_ms": 12.364, "learn_throughput": 4852.796, "update_time_ms": 1.024}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 0.0005, "total_loss": 4511132.75, "policy_loss": -0.0023386114432142335, "vf_loss": 4511132.5, "vf_explained_var": 4.76837158203125e-07, "kl": 0.00015534678114148548, "entropy": 1.7448103427886963, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 960, "num_agent_steps_sampled": 2880, "num_steps_trained": 960, "num_agent_steps_trained": 2880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9, "training_iteration": 16, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-32", "timestamp": 1742303372, "time_this_iter_s": 0.09300708770751953, "time_total_s": 1.5306377410888672, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772adc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.5306377410888672, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19482638460517382, "mean_inference_ms": 0.7572459888617933, "mean_action_processing_ms": 0.04833785246169515, "mean_env_wait_ms": 0.2884549813971832, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1020, "timesteps_this_iter": 0, "agent_timesteps_total": 3060, "timers": {"sample_time_ms": 109.436, "sample_throughput": 548.265, "load_time_ms": 0.17, "load_throughput": 353949.705, "learn_time_ms": 12.494, "learn_throughput": 4802.345, "update_time_ms": 1.021}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005, "total_loss": 8026379.0, "policy_loss": -0.0009264919389453397, "vf_loss": 8026378.25, "vf_explained_var": 2.086162567138672e-07, "kl": 0.00020865774905942658, "entropy": 1.7582104206085205, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1020, "num_agent_steps_sampled": 3060, "num_steps_trained": 1020, "num_agent_steps_trained": 3060, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10, "training_iteration": 17, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.09427833557128906, "time_total_s": 1.6249160766601562, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.6249160766601562, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19482638460517382, "mean_inference_ms": 0.7572459888617933, "mean_action_processing_ms": 0.04833785246169515, "mean_env_wait_ms": 0.2884549813971832, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1080, "timesteps_this_iter": 0, "agent_timesteps_total": 3240, "timers": {"sample_time_ms": 109.37, "sample_throughput": 548.596, "load_time_ms": 0.17, "load_throughput": 353601.574, "learn_time_ms": 12.426, "learn_throughput": 4828.42, "update_time_ms": 1.085}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 0.0005, "total_loss": 10545402.0, "policy_loss": -0.0009988966734226778, "vf_loss": 10545402.5, "vf_explained_var": 5.960464477539063e-08, "kl": 0.0001945604050588301, "entropy": 1.7807464599609375, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1080, "num_agent_steps_sampled": 3240, "num_steps_trained": 1080, "num_agent_steps_trained": 3240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10, "training_iteration": 18, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.0926659107208252, "time_total_s": 1.7175819873809814, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772aee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.7175819873809814, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1936357392579731, "mean_inference_ms": 0.7565350113397572, "mean_action_processing_ms": 0.04828797846556964, "mean_env_wait_ms": 0.28838393160258025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1140, "timesteps_this_iter": 0, "agent_timesteps_total": 3420, "timers": {"sample_time_ms": 109.204, "sample_throughput": 549.429, "load_time_ms": 0.169, "load_throughput": 355198.645, "learn_time_ms": 12.596, "learn_throughput": 4763.602, "update_time_ms": 1.081}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 0.0005, "total_loss": 2126894.875, "policy_loss": 0.0006316966493606913, "vf_loss": 2126895.0, "vf_explained_var": 0.0, "kl": 0.00013595183970251112, "entropy": 1.7981044054031372, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1140, "num_agent_steps_sampled": 3420, "num_steps_trained": 1140, "num_agent_steps_trained": 3420, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11, "training_iteration": 19, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.09157657623291016, "time_total_s": 1.8091585636138916, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.8091585636138916, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1926523907615404, "mean_inference_ms": 0.7558906338980779, "mean_action_processing_ms": 0.04825173447521575, "mean_env_wait_ms": 0.28836758005664176, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1200, "timesteps_this_iter": 0, "agent_timesteps_total": 3600, "timers": {"sample_time_ms": 109.308, "sample_throughput": 548.908, "load_time_ms": 0.173, "load_throughput": 347738.345, "learn_time_ms": 12.435, "learn_throughput": 4824.986, "update_time_ms": 1.055}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 0.0005, "total_loss": 19135347.0, "policy_loss": -0.0006366229538503632, "vf_loss": 19135348.0, "vf_explained_var": 2.384185791015625e-07, "kl": 9.8483809850336e-05, "entropy": 1.8136407732963562, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1200, "num_agent_steps_sampled": 3600, "num_steps_trained": 1200, "num_agent_steps_trained": 3600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12, "training_iteration": 20, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.09466958045959473, "time_total_s": 1.9038281440734863, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.9038281440734863, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 14.0, "ram_util_percent": 21.0}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1926523907615404, "mean_inference_ms": 0.7558906338980779, "mean_action_processing_ms": 0.04825173447521575, "mean_env_wait_ms": 0.28836758005664176, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1260, "timesteps_this_iter": 0, "agent_timesteps_total": 3780, "timers": {"sample_time_ms": 109.84, "sample_throughput": 546.251, "load_time_ms": 0.174, "load_throughput": 344642.892, "learn_time_ms": 12.486, "learn_throughput": 4805.206, "update_time_ms": 1.035}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 0.0005, "total_loss": 4509483.5, "policy_loss": -0.0005938387475907803, "vf_loss": 4509483.5, "vf_explained_var": 5.960464477539063e-08, "kl": 0.00010400815709643574, "entropy": 1.8292718529701233, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1260, "num_agent_steps_sampled": 3780, "num_steps_trained": 1260, "num_agent_steps_trained": 3780, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12, "training_iteration": 21, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.09290075302124023, "time_total_s": 1.9967288970947266, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.9967288970947266, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1917748888044448, "mean_inference_ms": 0.7552849763006079, "mean_action_processing_ms": 0.04822160475464597, "mean_env_wait_ms": 0.28836720229047635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1320, "timesteps_this_iter": 0, "agent_timesteps_total": 3960, "timers": {"sample_time_ms": 109.514, "sample_throughput": 547.876, "load_time_ms": 0.174, "load_throughput": 344265.718, "learn_time_ms": 12.41, "learn_throughput": 4834.923, "update_time_ms": 1.018}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005, "total_loss": 8020560.5, "policy_loss": -0.0015065577424442367, "vf_loss": 8020560.0, "vf_explained_var": -5.364418029785156e-07, "kl": 7.776859467112374e-05, "entropy": 1.840212881565094, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1320, "num_agent_steps_sampled": 3960, "num_steps_trained": 1320, "num_agent_steps_trained": 3960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13, "training_iteration": 22, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.09341049194335938, "time_total_s": 2.090139389038086, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.090139389038086, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1917748888044448, "mean_inference_ms": 0.7552849763006079, "mean_action_processing_ms": 0.04822160475464597, "mean_env_wait_ms": 0.28836720229047635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1380, "timesteps_this_iter": 0, "agent_timesteps_total": 4140, "timers": {"sample_time_ms": 109.08, "sample_throughput": 550.054, "load_time_ms": 0.182, "load_throughput": 330346.863, "learn_time_ms": 12.321, "learn_throughput": 4869.906, "update_time_ms": 0.983}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 0.0005, "total_loss": 10542874.5, "policy_loss": -0.000159921913937211, "vf_loss": 10542874.5, "vf_explained_var": -2.384185791015625e-07, "kl": 8.613441283866763e-05, "entropy": 1.8362261652946472, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1380, "num_agent_steps_sampled": 4140, "num_steps_trained": 1380, "num_agent_steps_trained": 4140, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13, "training_iteration": 23, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.09181356430053711, "time_total_s": 2.181952953338623, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.181952953338623, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19096936744317514, "mean_inference_ms": 0.7546915841673524, "mean_action_processing_ms": 0.04818392865749661, "mean_env_wait_ms": 0.28839356752598455, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1440, "timesteps_this_iter": 0, "agent_timesteps_total": 4320, "timers": {"sample_time_ms": 108.711, "sample_throughput": 551.924, "load_time_ms": 0.174, "load_throughput": 343889.369, "learn_time_ms": 12.271, "learn_throughput": 4889.387, "update_time_ms": 1.011}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005, "total_loss": 2124824.0, "policy_loss": -0.00031275617786619136, "vf_loss": 2124823.875, "vf_explained_var": 0.0, "kl": 5.250488443886425e-05, "entropy": 1.832335114479065, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1440, "num_agent_steps_sampled": 4320, "num_steps_trained": 1440, "num_agent_steps_trained": 4320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 14, "training_iteration": 24, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.09425997734069824, "time_total_s": 2.2762129306793213, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277511f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.2762129306793213, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.190239494669963, "mean_inference_ms": 0.7542520076419212, "mean_action_processing_ms": 0.0481544462374548, "mean_env_wait_ms": 0.2884579394721151, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1500, "timesteps_this_iter": 0, "agent_timesteps_total": 4500, "timers": {"sample_time_ms": 108.595, "sample_throughput": 552.514, "load_time_ms": 0.165, "load_throughput": 364405.213, "learn_time_ms": 12.25, "learn_throughput": 4897.799, "update_time_ms": 1.016}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 0.0005, "total_loss": 19124374.0, "policy_loss": -0.001183385686530869, "vf_loss": 19124374.0, "vf_explained_var": 4.172325134277344e-07, "kl": 5.345986435578709e-05, "entropy": 1.82832533121109, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1500, "num_agent_steps_sampled": 4500, "num_steps_trained": 1500, "num_agent_steps_trained": 4500, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15, "training_iteration": 25, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-33", "timestamp": 1742303373, "time_this_iter_s": 0.09636998176574707, "time_total_s": 2.3725829124450684, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277514c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.3725829124450684, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.190239494669963, "mean_inference_ms": 0.7542520076419212, "mean_action_processing_ms": 0.0481544462374548, "mean_env_wait_ms": 0.2884579394721151, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1560, "timesteps_this_iter": 0, "agent_timesteps_total": 4680, "timers": {"sample_time_ms": 108.55, "sample_throughput": 552.742, "load_time_ms": 0.17, "load_throughput": 353204.547, "learn_time_ms": 12.383, "learn_throughput": 4845.34, "update_time_ms": 1.008}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 0.0005, "total_loss": 4507877.75, "policy_loss": -0.0009913491033426425, "vf_loss": 4507877.75, "vf_explained_var": -4.76837158203125e-07, "kl": 0.000117736477017516, "entropy": 1.8326682448387146, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1560, "num_agent_steps_sampled": 4680, "num_steps_trained": 1560, "num_agent_steps_trained": 4680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15, "training_iteration": 26, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09572696685791016, "time_total_s": 2.4683098793029785, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.4683098793029785, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 13.5, "ram_util_percent": 21.0}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18960008680590976, "mean_inference_ms": 0.7538300929214491, "mean_action_processing_ms": 0.04813027454569351, "mean_env_wait_ms": 0.28854968182122, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1620, "timesteps_this_iter": 0, "agent_timesteps_total": 4860, "timers": {"sample_time_ms": 108.235, "sample_throughput": 554.347, "load_time_ms": 0.163, "load_throughput": 368136.688, "learn_time_ms": 12.388, "learn_throughput": 4843.503, "update_time_ms": 0.997}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 0.0005, "total_loss": 8014870.5, "policy_loss": 0.0011123856012176248, "vf_loss": 8014870.5, "vf_explained_var": 0.0, "kl": 5.463012180850768e-05, "entropy": 1.831928312778473, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1620, "num_agent_steps_sampled": 4860, "num_steps_trained": 1620, "num_agent_steps_trained": 4860, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16, "training_iteration": 27, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09336018562316895, "time_total_s": 2.5616700649261475, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.5616700649261475, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18960008680590976, "mean_inference_ms": 0.7538300929214491, "mean_action_processing_ms": 0.04813027454569351, "mean_env_wait_ms": 0.28854968182122, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1680, "timesteps_this_iter": 0, "agent_timesteps_total": 5040, "timers": {"sample_time_ms": 108.723, "sample_throughput": 551.862, "load_time_ms": 0.17, "load_throughput": 352907.362, "learn_time_ms": 12.441, "learn_throughput": 4822.859, "update_time_ms": 0.924}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 0.0005, "total_loss": 10540409.0, "policy_loss": -0.0007868054917921086, "vf_loss": 10540409.5, "vf_explained_var": -3.5762786865234375e-07, "kl": 2.6748018810529572e-05, "entropy": 1.8324639201164246, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1680, "num_agent_steps_sampled": 5040, "num_steps_trained": 1680, "num_agent_steps_trained": 5040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16, "training_iteration": 28, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09703302383422852, "time_total_s": 2.658703088760376, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277514c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.658703088760376, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18901129803385316, "mean_inference_ms": 0.7534573257796171, "mean_action_processing_ms": 0.048107993856967186, "mean_env_wait_ms": 0.28864750366329767, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1740, "timesteps_this_iter": 0, "agent_timesteps_total": 5220, "timers": {"sample_time_ms": 108.445, "sample_throughput": 553.275, "load_time_ms": 0.171, "load_throughput": 350694.314, "learn_time_ms": 12.369, "learn_throughput": 4851.019, "update_time_ms": 0.919}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 0.0005, "total_loss": 2122808.25, "policy_loss": -0.0006598601842071616, "vf_loss": 2122808.125, "vf_explained_var": -1.3113021850585938e-06, "kl": 3.2624493492505735e-05, "entropy": 1.8285383582115173, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1740, "num_agent_steps_sampled": 5220, "num_steps_trained": 1740, "num_agent_steps_trained": 5220, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17, "training_iteration": 29, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09147477149963379, "time_total_s": 2.7501778602600098, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.7501778602600098, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18845263244698618, "mean_inference_ms": 0.753077564030424, "mean_action_processing_ms": 0.048082871052839676, "mean_env_wait_ms": 0.28870675633620546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1800, "timesteps_this_iter": 0, "agent_timesteps_total": 5400, "timers": {"sample_time_ms": 108.031, "sample_throughput": 555.395, "load_time_ms": 0.176, "load_throughput": 340124.665, "learn_time_ms": 12.494, "learn_throughput": 4802.143, "update_time_ms": 0.906}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 0.0005, "total_loss": 19113617.0, "policy_loss": -0.0014601118190000761, "vf_loss": 19113617.0, "vf_explained_var": -1.1920928955078125e-07, "kl": 6.887456356707844e-05, "entropy": 1.824635088443756, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1800, "num_agent_steps_sampled": 5400, "num_steps_trained": 1800, "num_agent_steps_trained": 5400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18, "training_iteration": 30, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09112668037414551, "time_total_s": 2.8413045406341553, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a5e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.8413045406341553, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18845263244698618, "mean_inference_ms": 0.753077564030424, "mean_action_processing_ms": 0.048082871052839676, "mean_env_wait_ms": 0.28870675633620546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1860, "timesteps_this_iter": 0, "agent_timesteps_total": 5580, "timers": {"sample_time_ms": 107.526, "sample_throughput": 558.002, "load_time_ms": 0.174, "load_throughput": 344077.441, "learn_time_ms": 12.498, "learn_throughput": 4800.916, "update_time_ms": 0.916}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 0.0005, "total_loss": 4506286.25, "policy_loss": -0.002222544586079067, "vf_loss": 4506286.25, "vf_explained_var": -1.0728836059570312e-06, "kl": 0.00011199754897023295, "entropy": 1.8194411993026733, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1860, "num_agent_steps_sampled": 5580, "num_steps_trained": 1860, "num_agent_steps_trained": 5580, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18, "training_iteration": 31, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09276127815246582, "time_total_s": 2.934065818786621, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.934065818786621, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1879260429745576, "mean_inference_ms": 0.7527301021162812, "mean_action_processing_ms": 0.04805619946978903, "mean_env_wait_ms": 0.28874489248158786, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1920, "timesteps_this_iter": 0, "agent_timesteps_total": 5760, "timers": {"sample_time_ms": 107.648, "sample_throughput": 557.37, "load_time_ms": 0.174, "load_throughput": 344124.491, "learn_time_ms": 12.469, "learn_throughput": 4811.95, "update_time_ms": 0.901}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 0.0005, "total_loss": 8009292.0, "policy_loss": 0.0007449858925410169, "vf_loss": 8009292.0, "vf_explained_var": 2.384185791015625e-07, "kl": 9.017008065370646e-05, "entropy": 1.8109848499298096, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1920, "num_agent_steps_sampled": 5760, "num_steps_trained": 1920, "num_agent_steps_trained": 5760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19, "training_iteration": 32, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09398865699768066, "time_total_s": 3.0280544757843018, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.0280544757843018, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1879260429745576, "mean_inference_ms": 0.7527301021162812, "mean_action_processing_ms": 0.04805619946978903, "mean_env_wait_ms": 0.28874489248158786, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1980, "timesteps_this_iter": 0, "agent_timesteps_total": 5940, "timers": {"sample_time_ms": 108.153, "sample_throughput": 554.768, "load_time_ms": 0.168, "load_throughput": 356204.161, "learn_time_ms": 12.52, "learn_throughput": 4792.304, "update_time_ms": 0.906}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 0.0005, "total_loss": 10537974.5, "policy_loss": -0.0017648501425142626, "vf_loss": 10537974.5, "vf_explained_var": -2.980232238769531e-07, "kl": 8.04679223467275e-05, "entropy": 1.8049466013908386, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1980, "num_agent_steps_sampled": 5940, "num_steps_trained": 1980, "num_agent_steps_trained": 5940, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19, "training_iteration": 33, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09644651412963867, "time_total_s": 3.1245009899139404, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.1245009899139404, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 14.4, "ram_util_percent": 21.1}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18744628612556347, "mean_inference_ms": 0.7524499276334677, "mean_action_processing_ms": 0.04803268659670501, "mean_env_wait_ms": 0.2888390967133221, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2040, "timesteps_this_iter": 0, "agent_timesteps_total": 6120, "timers": {"sample_time_ms": 108.571, "sample_throughput": 552.636, "load_time_ms": 0.17, "load_throughput": 353551.897, "learn_time_ms": 12.581, "learn_throughput": 4769.217, "update_time_ms": 0.871}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 0.0005, "total_loss": 2120816.875, "policy_loss": -0.0016859769484867115, "vf_loss": 2120816.75, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00013372420511714722, "entropy": 1.7884185314178467, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2040, "num_agent_steps_sampled": 6120, "num_steps_trained": 2040, "num_agent_steps_trained": 6120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20, "training_iteration": 34, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-34", "timestamp": 1742303374, "time_this_iter_s": 0.09566736221313477, "time_total_s": 3.220168352127075, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.220168352127075, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18700166450532044, "mean_inference_ms": 0.7522470232127427, "mean_action_processing_ms": 0.04800977898293209, "mean_env_wait_ms": 0.28895499440360406, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2100, "timesteps_this_iter": 0, "agent_timesteps_total": 6300, "timers": {"sample_time_ms": 108.579, "sample_throughput": 552.592, "load_time_ms": 0.176, "load_throughput": 341231.512, "learn_time_ms": 12.512, "learn_throughput": 4795.491, "update_time_ms": 0.861}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1641532182693482e-11, "cur_lr": 0.0005, "total_loss": 19103030.0, "policy_loss": -0.00020956827793261468, "vf_loss": 19103030.0, "vf_explained_var": -1.7881393432617188e-07, "kl": 0.00013064803394868818, "entropy": 1.7709318399429321, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2100, "num_agent_steps_sampled": 6300, "num_steps_trained": 2100, "num_agent_steps_trained": 6300, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 21, "training_iteration": 35, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09644508361816406, "time_total_s": 3.3166134357452393, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277960d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.3166134357452393, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18700166450532044, "mean_inference_ms": 0.7522470232127427, "mean_action_processing_ms": 0.04800977898293209, "mean_env_wait_ms": 0.28895499440360406, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2160, "timesteps_this_iter": 0, "agent_timesteps_total": 6480, "timers": {"sample_time_ms": 108.335, "sample_throughput": 553.838, "load_time_ms": 0.181, "load_throughput": 332397.623, "learn_time_ms": 12.567, "learn_throughput": 4774.257, "update_time_ms": 0.868}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.820766091346741e-12, "cur_lr": 0.0005, "total_loss": 4504723.0, "policy_loss": -0.00012981759371655244, "vf_loss": 4504723.0, "vf_explained_var": -8.344650268554688e-07, "kl": 9.528472215514228e-05, "entropy": 1.7541863918304443, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2160, "num_agent_steps_sampled": 6480, "num_steps_trained": 2160, "num_agent_steps_trained": 6480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 21, "training_iteration": 36, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09525823593139648, "time_total_s": 3.4118716716766357, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.4118716716766357, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1865914354184046, "mean_inference_ms": 0.7520575592292218, "mean_action_processing_ms": 0.0479886732276609, "mean_env_wait_ms": 0.2890481843306309, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2220, "timesteps_this_iter": 0, "agent_timesteps_total": 6660, "timers": {"sample_time_ms": 108.436, "sample_throughput": 553.322, "load_time_ms": 0.191, "load_throughput": 314730.165, "learn_time_ms": 12.58, "learn_throughput": 4769.344, "update_time_ms": 0.863}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9103830456733705e-12, "cur_lr": 0.0005, "total_loss": 8003793.5, "policy_loss": -0.0018630881690318013, "vf_loss": 8003793.5, "vf_explained_var": -1.7881393432617188e-07, "kl": 0.00011320978117890235, "entropy": 1.7365570068359375, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2220, "num_agent_steps_sampled": 6660, "num_steps_trained": 2220, "num_agent_steps_trained": 6660, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 22, "training_iteration": 37, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09402585029602051, "time_total_s": 3.5058975219726562, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.5058975219726562, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1865914354184046, "mean_inference_ms": 0.7520575592292218, "mean_action_processing_ms": 0.0479886732276609, "mean_env_wait_ms": 0.2890481843306309, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2280, "timesteps_this_iter": 0, "agent_timesteps_total": 6840, "timers": {"sample_time_ms": 107.734, "sample_throughput": 556.926, "load_time_ms": 0.195, "load_throughput": 308329.135, "learn_time_ms": 12.6, "learn_throughput": 4762.007, "update_time_ms": 0.919}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4551915228366853e-12, "cur_lr": 0.0005, "total_loss": 10535572.5, "policy_loss": 8.462667739905783e-05, "vf_loss": 10535572.5, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00011925280724334186, "entropy": 1.7256965637207031, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2280, "num_agent_steps_sampled": 6840, "num_steps_trained": 2280, "num_agent_steps_trained": 6840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 22, "training_iteration": 38, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09330439567565918, "time_total_s": 3.5992019176483154, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.5992019176483154, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1862144094955762, "mean_inference_ms": 0.7518244802128595, "mean_action_processing_ms": 0.047965614972991684, "mean_env_wait_ms": 0.28912624482922117, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2340, "timesteps_this_iter": 0, "agent_timesteps_total": 7020, "timers": {"sample_time_ms": 108.091, "sample_throughput": 555.086, "load_time_ms": 0.201, "load_throughput": 298526.975, "learn_time_ms": 12.656, "learn_throughput": 4740.791, "update_time_ms": 0.92}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.275957614183426e-13, "cur_lr": 0.0005, "total_loss": 2118856.75, "policy_loss": -0.000280349131208002, "vf_loss": 2118856.75, "vf_explained_var": 1.1920928955078125e-07, "kl": 6.511782739515581e-05, "entropy": 1.7138159275054932, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2340, "num_agent_steps_sampled": 7020, "num_steps_trained": 2340, "num_agent_steps_trained": 7020, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 23, "training_iteration": 39, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09331774711608887, "time_total_s": 3.6925196647644043, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.6925196647644043, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 13.7, "ram_util_percent": 21.1}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18585325374817518, "mean_inference_ms": 0.7515827293030054, "mean_action_processing_ms": 0.0479421518103928, "mean_env_wait_ms": 0.2891807779080495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2400, "timesteps_this_iter": 0, "agent_timesteps_total": 7200, "timers": {"sample_time_ms": 108.362, "sample_throughput": 553.698, "load_time_ms": 0.202, "load_throughput": 297714.705, "learn_time_ms": 12.587, "learn_throughput": 4766.706, "update_time_ms": 0.909}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.637978807091713e-13, "cur_lr": 0.0005, "total_loss": 19092570.0, "policy_loss": -0.0010595503702965914, "vf_loss": 19092571.0, "vf_explained_var": -3.5762786865234375e-07, "kl": 8.464171995115066e-05, "entropy": 1.7059609293937683, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2400, "num_agent_steps_sampled": 7200, "num_steps_trained": 2400, "num_agent_steps_trained": 7200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 24, "training_iteration": 40, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09049391746520996, "time_total_s": 3.7830135822296143, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.7830135822296143, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18585325374817518, "mean_inference_ms": 0.7515827293030054, "mean_action_processing_ms": 0.0479421518103928, "mean_env_wait_ms": 0.2891807779080495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2460, "timesteps_this_iter": 0, "agent_timesteps_total": 7380, "timers": {"sample_time_ms": 108.818, "sample_throughput": 551.378, "load_time_ms": 0.203, "load_throughput": 295998.871, "learn_time_ms": 12.578, "learn_throughput": 4770.392, "update_time_ms": 0.901}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8189894035458566e-13, "cur_lr": 0.0005, "total_loss": 4503182.5, "policy_loss": -0.0019405619500005855, "vf_loss": 4503182.5, "vf_explained_var": 0.0, "kl": 0.00020554917619186597, "entropy": 1.691521406173706, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2460, "num_agent_steps_sampled": 7380, "num_steps_trained": 2460, "num_agent_steps_trained": 7380, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 24, "training_iteration": 41, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09036731719970703, "time_total_s": 3.8733808994293213, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.8733808994293213, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18552700467745628, "mean_inference_ms": 0.7513816564171256, "mean_action_processing_ms": 0.04791945556875984, "mean_env_wait_ms": 0.28924454513610354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2520, "timesteps_this_iter": 0, "agent_timesteps_total": 7560, "timers": {"sample_time_ms": 109.002, "sample_throughput": 550.449, "load_time_ms": 0.208, "load_throughput": 288301.34, "learn_time_ms": 12.608, "learn_throughput": 4758.945, "update_time_ms": 0.93}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 0.0005, "total_loss": 7998354.75, "policy_loss": -0.0025918695558289073, "vf_loss": 7998354.75, "vf_explained_var": 4.76837158203125e-07, "kl": 0.00035516236666310874, "entropy": 1.6746745705604553, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2520, "num_agent_steps_sampled": 7560, "num_steps_trained": 2520, "num_agent_steps_trained": 7560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 25, "training_iteration": 42, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09911346435546875, "time_total_s": 3.97249436378479, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.97249436378479, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18552700467745628, "mean_inference_ms": 0.7513816564171256, "mean_action_processing_ms": 0.04791945556875984, "mean_env_wait_ms": 0.28924454513610354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2580, "timesteps_this_iter": 0, "agent_timesteps_total": 7740, "timers": {"sample_time_ms": 109.021, "sample_throughput": 550.351, "load_time_ms": 0.218, "load_throughput": 275669.011, "learn_time_ms": 12.518, "learn_throughput": 4792.961, "update_time_ms": 0.944}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 0.0005, "total_loss": 10533167.0, "policy_loss": -0.0010909114032982004, "vf_loss": 10533167.0, "vf_explained_var": 8.940696716308594e-07, "kl": 0.00037565561279873094, "entropy": 1.6604015827178955, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2580, "num_agent_steps_sampled": 7740, "num_steps_trained": 2580, "num_agent_steps_trained": 7740, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 25, "training_iteration": 43, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-35", "timestamp": 1742303375, "time_this_iter_s": 0.09684109687805176, "time_total_s": 4.069335460662842, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.069335460662842, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18524389005100425, "mean_inference_ms": 0.7513178262613085, "mean_action_processing_ms": 0.047903670047159466, "mean_env_wait_ms": 0.28936684742103763, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2640, "timesteps_this_iter": 0, "agent_timesteps_total": 7920, "timers": {"sample_time_ms": 109.88, "sample_throughput": 546.048, "load_time_ms": 0.216, "load_throughput": 277737.821, "learn_time_ms": 12.495, "learn_throughput": 4802.033, "update_time_ms": 0.949}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2737367544323207e-14, "cur_lr": 0.0005, "total_loss": 2116915.375, "policy_loss": 0.0002835638129097262, "vf_loss": 2116915.375, "vf_explained_var": 1.4901161193847656e-06, "kl": 0.00027078464928820267, "entropy": 1.6646040678024292, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2640, "num_agent_steps_sampled": 7920, "num_steps_trained": 2640, "num_agent_steps_trained": 7920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 26, "training_iteration": 44, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-36", "timestamp": 1742303376, "time_this_iter_s": 0.1064906120300293, "time_total_s": 4.175826072692871, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.175826072692871, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18497513983871328, "mean_inference_ms": 0.7512525788831247, "mean_action_processing_ms": 0.047889419853762015, "mean_env_wait_ms": 0.2894888159424329, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2700, "timesteps_this_iter": 0, "agent_timesteps_total": 8100, "timers": {"sample_time_ms": 109.863, "sample_throughput": 546.137, "load_time_ms": 0.209, "load_throughput": 287708.06, "learn_time_ms": 12.517, "learn_throughput": 4793.326, "update_time_ms": 0.947}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 0.0005, "total_loss": 19082216.0, "policy_loss": -0.0011040505358121955, "vf_loss": 19082218.0, "vf_explained_var": -2.384185791015625e-07, "kl": 0.00022433918665820674, "entropy": 1.6833216547966003, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2700, "num_agent_steps_sampled": 8100, "num_steps_trained": 2700, "num_agent_steps_trained": 8100, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 27, "training_iteration": 45, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-36", "timestamp": 1742303376, "time_this_iter_s": 0.09381675720214844, "time_total_s": 4.2696428298950195, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.2696428298950195, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 13.9, "ram_util_percent": 21.0}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18497513983871328, "mean_inference_ms": 0.7512525788831247, "mean_action_processing_ms": 0.047889419853762015, "mean_env_wait_ms": 0.2894888159424329, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2760, "timesteps_this_iter": 0, "agent_timesteps_total": 8280, "timers": {"sample_time_ms": 109.783, "sample_throughput": 546.532, "load_time_ms": 0.199, "load_throughput": 301857.071, "learn_time_ms": 12.329, "learn_throughput": 4866.506, "update_time_ms": 0.978}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 0.0005, "total_loss": 4501658.0, "policy_loss": -0.0011812356041929206, "vf_loss": 4501658.0, "vf_explained_var": -1.2516975402832031e-06, "kl": 0.00021955616105628906, "entropy": 1.6858460307121277, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2760, "num_agent_steps_sampled": 8280, "num_steps_trained": 2760, "num_agent_steps_trained": 8280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 27, "training_iteration": 46, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-36", "timestamp": 1742303376, "time_this_iter_s": 0.09353208541870117, "time_total_s": 4.363174915313721, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.363174915313721, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.184723907500526, "mean_inference_ms": 0.7512005614289029, "mean_action_processing_ms": 0.04787480191894385, "mean_env_wait_ms": 0.2896147509784242, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2820, "timesteps_this_iter": 0, "agent_timesteps_total": 8460, "timers": {"sample_time_ms": 109.865, "sample_throughput": 546.125, "load_time_ms": 0.189, "load_throughput": 318272.72, "learn_time_ms": 12.29, "learn_throughput": 4881.923, "update_time_ms": 0.997}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 0.0005, "total_loss": 7992972.25, "policy_loss": -0.0007899714685561943, "vf_loss": 7992972.5, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00022181384535158166, "entropy": 1.6671427488327026, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2820, "num_agent_steps_sampled": 8460, "num_steps_trained": 2820, "num_agent_steps_trained": 8460, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 28, "training_iteration": 47, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-36", "timestamp": 1742303376, "time_this_iter_s": 0.09608912467956543, "time_total_s": 4.459264039993286, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.459264039993286, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.184723907500526, "mean_inference_ms": 0.7512005614289029, "mean_action_processing_ms": 0.04787480191894385, "mean_env_wait_ms": 0.2896147509784242, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2880, "timesteps_this_iter": 0, "agent_timesteps_total": 8640, "timers": {"sample_time_ms": 110.224, "sample_throughput": 544.348, "load_time_ms": 0.194, "load_throughput": 310076.688, "learn_time_ms": 12.281, "learn_throughput": 4885.439, "update_time_ms": 0.956}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 0.0005, "total_loss": 10530854.5, "policy_loss": -0.0003327568288042926, "vf_loss": 10530854.5, "vf_explained_var": -6.556510925292969e-07, "kl": 0.00018699949249345593, "entropy": 1.6389327645301819, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2880, "num_agent_steps_sampled": 8640, "num_steps_trained": 2880, "num_agent_steps_trained": 8640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 28, "training_iteration": 48, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-36", "timestamp": 1742303376, "time_this_iter_s": 0.09648799896240234, "time_total_s": 4.5557520389556885, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.5557520389556885, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18449689935873498, "mean_inference_ms": 0.7511532726747533, "mean_action_processing_ms": 0.04786073499454362, "mean_env_wait_ms": 0.28974440334428303, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2940, "timesteps_this_iter": 0, "agent_timesteps_total": 8820, "timers": {"sample_time_ms": 110.381, "sample_throughput": 543.571, "load_time_ms": 0.197, "load_throughput": 304966.36, "learn_time_ms": 12.29, "learn_throughput": 4882.036, "update_time_ms": 0.956}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.105427357601002e-16, "cur_lr": 0.0005, "total_loss": 2114995.0, "policy_loss": -0.0013298537504553565, "vf_loss": 2114994.875, "vf_explained_var": -4.172325134277344e-07, "kl": 0.00018238227706746102, "entropy": 1.6114003658294678, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2940, "num_agent_steps_sampled": 8820, "num_steps_trained": 2940, "num_agent_steps_trained": 8820, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 29, "training_iteration": 49, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-36", "timestamp": 1742303376, "time_this_iter_s": 0.09546637535095215, "time_total_s": 4.651218414306641, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.651218414306641, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.184284358887959, "mean_inference_ms": 0.7511093412278849, "mean_action_processing_ms": 0.04784828267746526, "mean_env_wait_ms": 0.2898651443444126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3000, "timesteps_this_iter": 0, "agent_timesteps_total": 9000, "timers": {"sample_time_ms": 110.493, "sample_throughput": 543.022, "load_time_ms": 0.187, "load_throughput": 320502.089, "learn_time_ms": 12.467, "learn_throughput": 4812.732, "update_time_ms": 0.96}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.552713678800501e-16, "cur_lr": 0.0005, "total_loss": 19071944.0, "policy_loss": -0.0012316223078716604, "vf_loss": 19071945.0, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00022786970244004223, "entropy": 1.5934886932373047, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3000, "num_agent_steps_sampled": 9000, "num_steps_trained": 3000, "num_agent_steps_trained": 9000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14370900172215478, "mean_inference_ms": 0.7516828093019042, "mean_action_processing_ms": 0.04615507402143755, "mean_env_wait_ms": 0.2818895982100175, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 30, "training_iteration": 50, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-37", "timestamp": 1742303377, "time_this_iter_s": 1.331780195236206, "time_total_s": 5.982998609542847, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.982998609542847, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 13.3, "ram_util_percent": 21.0}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.184284358887959, "mean_inference_ms": 0.7511093412278849, "mean_action_processing_ms": 0.04784828267746526, "mean_env_wait_ms": 0.2898651443444126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3060, "timesteps_this_iter": 0, "agent_timesteps_total": 9180, "timers": {"sample_time_ms": 234.779, "sample_throughput": 255.56, "load_time_ms": 0.186, "load_throughput": 322970.021, "learn_time_ms": 12.461, "learn_throughput": 4815.071, "update_time_ms": 0.958}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7763568394002506e-16, "cur_lr": 0.0005, "total_loss": 4500138.5, "policy_loss": -0.0014387881874831088, "vf_loss": 4500138.5, "vf_explained_var": 1.2516975402832031e-06, "kl": 0.000242023771270361, "entropy": 1.5651764273643494, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3060, "num_agent_steps_sampled": 9180, "num_steps_trained": 3060, "num_agent_steps_trained": 9180, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 30, "training_iteration": 51, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.0971071720123291, "time_total_s": 6.080105781555176, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.080105781555176, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1840765187580745, "mean_inference_ms": 0.7510466215658386, "mean_action_processing_ms": 0.04783534228924549, "mean_env_wait_ms": 0.2899691595910451, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3120, "timesteps_this_iter": 0, "agent_timesteps_total": 9360, "timers": {"sample_time_ms": 234.304, "sample_throughput": 256.078, "load_time_ms": 0.191, "load_throughput": 314769.531, "learn_time_ms": 12.438, "learn_throughput": 4823.969, "update_time_ms": 0.938}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.881784197001253e-17, "cur_lr": 0.0005, "total_loss": 7987617.75, "policy_loss": -0.002200902936358773, "vf_loss": 7987618.75, "vf_explained_var": 4.76837158203125e-07, "kl": 0.0002785450625459873, "entropy": 1.5481593608856201, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3120, "num_agent_steps_sampled": 9360, "num_steps_trained": 3120, "num_agent_steps_trained": 9360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 31, "training_iteration": 52, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.09303569793701172, "time_total_s": 6.1731414794921875, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.1731414794921875, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1840765187580745, "mean_inference_ms": 0.7510466215658386, "mean_action_processing_ms": 0.04783534228924549, "mean_env_wait_ms": 0.2899691595910451, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3180, "timesteps_this_iter": 0, "agent_timesteps_total": 9540, "timers": {"sample_time_ms": 234.35, "sample_throughput": 256.027, "load_time_ms": 0.185, "load_throughput": 323509.757, "learn_time_ms": 12.487, "learn_throughput": 4805.169, "update_time_ms": 0.917}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.4408920985006264e-17, "cur_lr": 0.0005, "total_loss": 10528499.5, "policy_loss": -0.00010881854589683826, "vf_loss": 10528499.5, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.00025658748598877956, "entropy": 1.5495298504829407, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3180, "num_agent_steps_sampled": 9540, "num_steps_trained": 3180, "num_agent_steps_trained": 9540, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 31, "training_iteration": 53, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.09787487983703613, "time_total_s": 6.271016359329224, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.271016359329224, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 14.1, "ram_util_percent": 21.1}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18389275953105633, "mean_inference_ms": 0.7510168929247182, "mean_action_processing_ms": 0.04782411200294116, "mean_env_wait_ms": 0.29007032714202086, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3240, "timesteps_this_iter": 0, "agent_timesteps_total": 9720, "timers": {"sample_time_ms": 233.385, "sample_throughput": 257.086, "load_time_ms": 0.196, "load_throughput": 306900.293, "learn_time_ms": 12.521, "learn_throughput": 4792.048, "update_time_ms": 0.924}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2204460492503132e-17, "cur_lr": 0.0005, "total_loss": 2113077.375, "policy_loss": -0.0023540761580482794, "vf_loss": 2113077.5, "vf_explained_var": -6.556510925292969e-07, "kl": 0.00022600244956905158, "entropy": 1.5446670651435852, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3240, "num_agent_steps_sampled": 9720, "num_steps_trained": 3240, "num_agent_steps_trained": 9720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 32, "training_iteration": 54, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.09574270248413086, "time_total_s": 6.3667590618133545, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771af70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.3667590618133545, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18371143386868694, "mean_inference_ms": 0.7509692927838499, "mean_action_processing_ms": 0.047813532311824045, "mean_env_wait_ms": 0.2901557488478613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3300, "timesteps_this_iter": 0, "agent_timesteps_total": 9900, "timers": {"sample_time_ms": 232.858, "sample_throughput": 257.668, "load_time_ms": 0.195, "load_throughput": 307725.899, "learn_time_ms": 12.536, "learn_throughput": 4786.188, "update_time_ms": 0.929}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1102230246251566e-17, "cur_lr": 0.0005, "total_loss": 19061725.0, "policy_loss": -0.000248889132244301, "vf_loss": 19061725.0, "vf_explained_var": 0.0, "kl": 0.00018056801327581695, "entropy": 1.5286498069763184, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3300, "num_agent_steps_sampled": 9900, "num_steps_trained": 3300, "num_agent_steps_trained": 9900, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 33, "training_iteration": 55, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.09073567390441895, "time_total_s": 6.457494735717773, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.457494735717773, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18371143386868694, "mean_inference_ms": 0.7509692927838499, "mean_action_processing_ms": 0.047813532311824045, "mean_env_wait_ms": 0.2901557488478613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3360, "timesteps_this_iter": 0, "agent_timesteps_total": 10080, "timers": {"sample_time_ms": 232.686, "sample_throughput": 257.859, "load_time_ms": 0.204, "load_throughput": 293821.646, "learn_time_ms": 12.705, "learn_throughput": 4722.367, "update_time_ms": 0.881}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.551115123125783e-18, "cur_lr": 0.0005, "total_loss": 4498616.0, "policy_loss": -0.0019223878884488954, "vf_loss": 4498616.0, "vf_explained_var": 2.6226043701171875e-06, "kl": 0.00018612798572004152, "entropy": 1.5161763429641724, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3360, "num_agent_steps_sampled": 10080, "num_steps_trained": 3360, "num_agent_steps_trained": 10080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 33, "training_iteration": 56, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.0919640064239502, "time_total_s": 6.549458742141724, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.549458742141724, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18353596247582166, "mean_inference_ms": 0.750902185739072, "mean_action_processing_ms": 0.04780290479718921, "mean_env_wait_ms": 0.2902264544033785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3420, "timesteps_this_iter": 0, "agent_timesteps_total": 10260, "timers": {"sample_time_ms": 232.661, "sample_throughput": 257.886, "load_time_ms": 0.204, "load_throughput": 294785.334, "learn_time_ms": 12.594, "learn_throughput": 4764.26, "update_time_ms": 0.887}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.7755575615628915e-18, "cur_lr": 0.0005, "total_loss": 7982299.0, "policy_loss": -0.0010124226592278518, "vf_loss": 7982299.0, "vf_explained_var": 1.1622905731201172e-06, "kl": 0.0003271057151899015, "entropy": 1.5234408378601074, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3420, "num_agent_steps_sampled": 10260, "num_steps_trained": 3420, "num_agent_steps_trained": 10260, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 34, "training_iteration": 57, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.09250354766845703, "time_total_s": 6.641962289810181, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.641962289810181, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18353596247582166, "mean_inference_ms": 0.750902185739072, "mean_action_processing_ms": 0.04780290479718921, "mean_env_wait_ms": 0.2902264544033785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3480, "timesteps_this_iter": 0, "agent_timesteps_total": 10440, "timers": {"sample_time_ms": 232.246, "sample_throughput": 258.347, "load_time_ms": 0.194, "load_throughput": 309962.114, "learn_time_ms": 12.714, "learn_throughput": 4719.294, "update_time_ms": 0.879}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3877787807814458e-18, "cur_lr": 0.0005, "total_loss": 10526177.0, "policy_loss": -0.0002454330439718433, "vf_loss": 10526177.0, "vf_explained_var": -8.344650268554688e-07, "kl": 0.0002940509638929001, "entropy": 1.5458715558052063, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3480, "num_agent_steps_sampled": 10440, "num_steps_trained": 3480, "num_agent_steps_trained": 10440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 34, "training_iteration": 58, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.09293985366821289, "time_total_s": 6.7349021434783936, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.7349021434783936, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18337537316663055, "mean_inference_ms": 0.7508217905015662, "mean_action_processing_ms": 0.04779096184466432, "mean_env_wait_ms": 0.2902793127031413, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3540, "timesteps_this_iter": 0, "agent_timesteps_total": 10620, "timers": {"sample_time_ms": 232.145, "sample_throughput": 258.46, "load_time_ms": 0.193, "load_throughput": 310765.918, "learn_time_ms": 12.594, "learn_throughput": 4764.233, "update_time_ms": 0.903}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.938893903907229e-19, "cur_lr": 0.0005, "total_loss": 2111181.25, "policy_loss": -0.004565399729957287, "vf_loss": 2111181.375, "vf_explained_var": 6.020069122314453e-06, "kl": 0.0005177807596439266, "entropy": 1.5609675645828247, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3540, "num_agent_steps_sampled": 10620, "num_steps_trained": 3540, "num_agent_steps_trained": 10620, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 35, "training_iteration": 59, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-38", "timestamp": 1742303378, "time_this_iter_s": 0.09427833557128906, "time_total_s": 6.829180479049683, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771af70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.829180479049683, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1832174158880923, "mean_inference_ms": 0.7507455994083992, "mean_action_processing_ms": 0.04777951539404971, "mean_env_wait_ms": 0.29032596360231677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3600, "timesteps_this_iter": 0, "agent_timesteps_total": 10800, "timers": {"sample_time_ms": 231.893, "sample_throughput": 258.739, "load_time_ms": 0.193, "load_throughput": 310881.087, "learn_time_ms": 12.559, "learn_throughput": 4777.347, "update_time_ms": 0.912}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4694469519536144e-19, "cur_lr": 0.0005, "total_loss": 19051609.0, "policy_loss": -0.0025790970513810407, "vf_loss": 19051613.0, "vf_explained_var": 9.5367431640625e-07, "kl": 0.000828528757969238, "entropy": 1.5776512622833252, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3600, "num_agent_steps_sampled": 10800, "num_steps_trained": 3600, "num_agent_steps_trained": 10800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 36, "training_iteration": 60, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.09373068809509277, "time_total_s": 6.922911167144775, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.922911167144775, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 13.8, "ram_util_percent": 21.1}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1832174158880923, "mean_inference_ms": 0.7507455994083992, "mean_action_processing_ms": 0.04777951539404971, "mean_env_wait_ms": 0.29032596360231677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3660, "timesteps_this_iter": 0, "agent_timesteps_total": 10980, "timers": {"sample_time_ms": 107.645, "sample_throughput": 557.385, "load_time_ms": 0.203, "load_throughput": 295165.658, "learn_time_ms": 12.611, "learn_throughput": 4757.685, "update_time_ms": 0.941}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7347234759768072e-19, "cur_lr": 0.0005, "total_loss": 4497113.25, "policy_loss": -6.33031133077111e-05, "vf_loss": 4497113.25, "vf_explained_var": 1.1920928955078125e-07, "kl": 0.0006838514956140074, "entropy": 1.583738088607788, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3660, "num_agent_steps_sampled": 10980, "num_steps_trained": 3660, "num_agent_steps_trained": 10980, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 36, "training_iteration": 61, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.09233331680297852, "time_total_s": 7.015244483947754, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.015244483947754, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18306928393214106, "mean_inference_ms": 0.7506694927978275, "mean_action_processing_ms": 0.04776722682968948, "mean_env_wait_ms": 0.2903688327459031, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3720, "timesteps_this_iter": 0, "agent_timesteps_total": 11160, "timers": {"sample_time_ms": 108.048, "sample_throughput": 555.307, "load_time_ms": 0.203, "load_throughput": 295477.563, "learn_time_ms": 12.681, "learn_throughput": 4731.405, "update_time_ms": 0.94}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.673617379884036e-20, "cur_lr": 0.0005, "total_loss": 7977041.25, "policy_loss": -0.001676240935921669, "vf_loss": 7977040.5, "vf_explained_var": 8.046627044677734e-07, "kl": 0.0006291316482656129, "entropy": 1.5834432244300842, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3720, "num_agent_steps_sampled": 11160, "num_steps_trained": 3720, "num_agent_steps_trained": 11160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 37, "training_iteration": 62, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.09686613082885742, "time_total_s": 7.112110614776611, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.112110614776611, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18306928393214106, "mean_inference_ms": 0.7506694927978275, "mean_action_processing_ms": 0.04776722682968948, "mean_env_wait_ms": 0.2903688327459031, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3780, "timesteps_this_iter": 0, "agent_timesteps_total": 11340, "timers": {"sample_time_ms": 107.211, "sample_throughput": 559.642, "load_time_ms": 0.204, "load_throughput": 293581.708, "learn_time_ms": 12.582, "learn_throughput": 4768.53, "update_time_ms": 0.939}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.336808689942018e-20, "cur_lr": 0.0005, "total_loss": 10523826.5, "policy_loss": -0.004187704322653474, "vf_loss": 10523826.5, "vf_explained_var": 0.0, "kl": 0.0009371811266465357, "entropy": 1.5747377276420593, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3780, "num_agent_steps_sampled": 11340, "num_steps_trained": 3780, "num_agent_steps_trained": 11340, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 37, "training_iteration": 63, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.08845710754394531, "time_total_s": 7.200567722320557, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ad30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.200567722320557, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18292339666413, "mean_inference_ms": 0.7505896633088693, "mean_action_processing_ms": 0.04775502577756876, "mean_env_wait_ms": 0.2904037690003206, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3840, "timesteps_this_iter": 0, "agent_timesteps_total": 11520, "timers": {"sample_time_ms": 107.158, "sample_throughput": 559.922, "load_time_ms": 0.2, "load_throughput": 300451.576, "learn_time_ms": 12.603, "learn_throughput": 4760.944, "update_time_ms": 0.912}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.168404344971009e-20, "cur_lr": 0.0005, "total_loss": 2109289.375, "policy_loss": 0.0018869823672673647, "vf_loss": 2109289.625, "vf_explained_var": -9.5367431640625e-07, "kl": 0.0007360515762115938, "entropy": 1.553085446357727, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3840, "num_agent_steps_sampled": 11520, "num_steps_trained": 3840, "num_agent_steps_trained": 11520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 38, "training_iteration": 64, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.09727311134338379, "time_total_s": 7.29784083366394, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.29784083366394, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18278682310370917, "mean_inference_ms": 0.7505160467600392, "mean_action_processing_ms": 0.04774330415041777, "mean_env_wait_ms": 0.2904377601966374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3900, "timesteps_this_iter": 0, "agent_timesteps_total": 11700, "timers": {"sample_time_ms": 107.905, "sample_throughput": 556.044, "load_time_ms": 0.212, "load_throughput": 283590.534, "learn_time_ms": 12.475, "learn_throughput": 4809.743, "update_time_ms": 0.973}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0842021724855045e-20, "cur_lr": 0.0005, "total_loss": 19041543.0, "policy_loss": -0.0035493098665035916, "vf_loss": 19041545.0, "vf_explained_var": 1.7881393432617188e-06, "kl": 0.0005729064846171639, "entropy": 1.533385455608368, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3900, "num_agent_steps_sampled": 11700, "num_steps_trained": 3900, "num_agent_steps_trained": 11700, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 39, "training_iteration": 65, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.09526300430297852, "time_total_s": 7.393103837966919, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.393103837966919, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18278682310370917, "mean_inference_ms": 0.7505160467600392, "mean_action_processing_ms": 0.04774330415041777, "mean_env_wait_ms": 0.2904377601966374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3960, "timesteps_this_iter": 0, "agent_timesteps_total": 11880, "timers": {"sample_time_ms": 107.956, "sample_throughput": 555.781, "load_time_ms": 0.201, "load_throughput": 298420.776, "learn_time_ms": 12.453, "learn_throughput": 4818.076, "update_time_ms": 0.976}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.4210108624275225e-21, "cur_lr": 0.0005, "total_loss": 4495624.0, "policy_loss": -0.002350277257050948, "vf_loss": 4495623.75, "vf_explained_var": 1.8477439880371094e-06, "kl": 0.0007308480523078309, "entropy": 1.4991058707237244, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3960, "num_agent_steps_sampled": 11880, "num_steps_trained": 3960, "num_agent_steps_trained": 11880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 39, "training_iteration": 66, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.09267687797546387, "time_total_s": 7.485780715942383, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.485780715942383, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 13.8, "ram_util_percent": 21.1}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18265701817063826, "mean_inference_ms": 0.7504472241190092, "mean_action_processing_ms": 0.047730452353077754, "mean_env_wait_ms": 0.29046809333267115, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4020, "timesteps_this_iter": 0, "agent_timesteps_total": 12060, "timers": {"sample_time_ms": 108.057, "sample_throughput": 555.262, "load_time_ms": 0.202, "load_throughput": 297749.929, "learn_time_ms": 12.461, "learn_throughput": 4815.126, "update_time_ms": 0.976}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.7105054312137612e-21, "cur_lr": 0.0005, "total_loss": 7971793.5, "policy_loss": -0.0024574214540835637, "vf_loss": 7971793.5, "vf_explained_var": 9.238719940185547e-07, "kl": 0.0006994922454044428, "entropy": 1.4529239535331726, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4020, "num_agent_steps_sampled": 12060, "num_steps_trained": 4020, "num_agent_steps_trained": 12060, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 40, "training_iteration": 67, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.09532809257507324, "time_total_s": 7.581108808517456, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.581108808517456, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18265701817063826, "mean_inference_ms": 0.7504472241190092, "mean_action_processing_ms": 0.047730452353077754, "mean_env_wait_ms": 0.29046809333267115, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4080, "timesteps_this_iter": 0, "agent_timesteps_total": 12240, "timers": {"sample_time_ms": 108.042, "sample_throughput": 555.339, "load_time_ms": 0.195, "load_throughput": 308291.363, "learn_time_ms": 12.318, "learn_throughput": 4870.981, "update_time_ms": 0.991}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3552527156068806e-21, "cur_lr": 0.0005, "total_loss": 10521537.5, "policy_loss": -0.000205267136657028, "vf_loss": 10521537.5, "vf_explained_var": -4.172325134277344e-07, "kl": 0.0005456692439018695, "entropy": 1.3963897824287415, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4080, "num_agent_steps_sampled": 12240, "num_steps_trained": 4080, "num_agent_steps_trained": 12240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 40, "training_iteration": 68, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.0916600227355957, "time_total_s": 7.672768831253052, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.672768831253052, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18252740107478116, "mean_inference_ms": 0.750370740048587, "mean_action_processing_ms": 0.04771690850958888, "mean_env_wait_ms": 0.2904934827502571, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4140, "timesteps_this_iter": 0, "agent_timesteps_total": 12420, "timers": {"sample_time_ms": 107.82, "sample_throughput": 556.486, "load_time_ms": 0.191, "load_throughput": 314848.292, "learn_time_ms": 12.394, "learn_throughput": 4840.959, "update_time_ms": 0.962}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.776263578034403e-22, "cur_lr": 0.0005, "total_loss": 2107416.625, "policy_loss": -0.0014459173402059378, "vf_loss": 2107416.75, "vf_explained_var": -2.0265579223632812e-06, "kl": 0.0003179153121131151, "entropy": 1.3424147963523865, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4140, "num_agent_steps_sampled": 12420, "num_steps_trained": 4140, "num_agent_steps_trained": 12420, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 41, "training_iteration": 69, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-39", "timestamp": 1742303379, "time_this_iter_s": 0.09295392036437988, "time_total_s": 7.765722751617432, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ac10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.765722751617432, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18240072299191684, "mean_inference_ms": 0.7503000045981446, "mean_action_processing_ms": 0.04770369069206444, "mean_env_wait_ms": 0.29051514081385993, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4200, "timesteps_this_iter": 0, "agent_timesteps_total": 12600, "timers": {"sample_time_ms": 108.066, "sample_throughput": 555.215, "load_time_ms": 0.202, "load_throughput": 296556.964, "learn_time_ms": 12.33, "learn_throughput": 4866.111, "update_time_ms": 0.966}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.3881317890172015e-22, "cur_lr": 0.0005, "total_loss": 19031485.0, "policy_loss": -0.0016737242281053, "vf_loss": 19031485.0, "vf_explained_var": -4.76837158203125e-07, "kl": 0.0003073558648196695, "entropy": 1.289261519908905, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4200, "num_agent_steps_sampled": 12600, "num_steps_trained": 4200, "num_agent_steps_trained": 12600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 42, "training_iteration": 70, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.0942239761352539, "time_total_s": 7.8599467277526855, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.8599467277526855, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18240072299191684, "mean_inference_ms": 0.7503000045981446, "mean_action_processing_ms": 0.04770369069206444, "mean_env_wait_ms": 0.29051514081385993, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4260, "timesteps_this_iter": 0, "agent_timesteps_total": 12780, "timers": {"sample_time_ms": 107.422, "sample_throughput": 558.543, "load_time_ms": 0.198, "load_throughput": 303751.648, "learn_time_ms": 13.003, "learn_throughput": 4614.264, "update_time_ms": 0.962}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6940658945086008e-22, "cur_lr": 0.0005, "total_loss": 4494146.25, "policy_loss": -0.00038598247467458435, "vf_loss": 4494146.25, "vf_explained_var": -4.76837158203125e-07, "kl": 0.00021640244525400476, "entropy": 1.2350083589553833, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4260, "num_agent_steps_sampled": 12780, "num_steps_trained": 4260, "num_agent_steps_trained": 12780, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 42, "training_iteration": 71, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.10221552848815918, "time_total_s": 7.962162256240845, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.962162256240845, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18227617442050012, "mean_inference_ms": 0.7502278657318943, "mean_action_processing_ms": 0.04769074339111483, "mean_env_wait_ms": 0.29052947700847065, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4320, "timesteps_this_iter": 0, "agent_timesteps_total": 12960, "timers": {"sample_time_ms": 108.704, "sample_throughput": 551.96, "load_time_ms": 0.187, "load_throughput": 320338.9, "learn_time_ms": 12.888, "learn_throughput": 4655.432, "update_time_ms": 0.957}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.470329472543004e-23, "cur_lr": 0.0005, "total_loss": 7966543.0, "policy_loss": 0.0008133802291325765, "vf_loss": 7966543.0, "vf_explained_var": 0.0, "kl": 7.618795998734496e-05, "entropy": 1.2198609709739685, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4320, "num_agent_steps_sampled": 12960, "num_steps_trained": 4320, "num_agent_steps_trained": 12960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 43, "training_iteration": 72, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.09332633018493652, "time_total_s": 8.055488586425781, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.055488586425781, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18227617442050012, "mean_inference_ms": 0.7502278657318943, "mean_action_processing_ms": 0.04769074339111483, "mean_env_wait_ms": 0.29052947700847065, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4380, "timesteps_this_iter": 0, "agent_timesteps_total": 13140, "timers": {"sample_time_ms": 109.035, "sample_throughput": 550.282, "load_time_ms": 0.179, "load_throughput": 334385.118, "learn_time_ms": 12.909, "learn_throughput": 4648.003, "update_time_ms": 0.964}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.235164736271502e-23, "cur_lr": 0.0005, "total_loss": 10519246.0, "policy_loss": -0.0030123307059142235, "vf_loss": 10519246.0, "vf_explained_var": -4.76837158203125e-07, "kl": 0.0002834021256551411, "entropy": 1.2037655115127563, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4380, "num_agent_steps_sampled": 13140, "num_steps_trained": 4380, "num_agent_steps_trained": 13140, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 43, "training_iteration": 73, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.09320497512817383, "time_total_s": 8.148693561553955, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f39d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.148693561553955, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 17.4, "ram_util_percent": 21.1}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18215931655122655, "mean_inference_ms": 0.7501600587760175, "mean_action_processing_ms": 0.04767845068578373, "mean_env_wait_ms": 0.2905519338999744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4440, "timesteps_this_iter": 0, "agent_timesteps_total": 13320, "timers": {"sample_time_ms": 109.21, "sample_throughput": 549.398, "load_time_ms": 0.175, "load_throughput": 343654.568, "learn_time_ms": 12.83, "learn_throughput": 4676.706, "update_time_ms": 0.969}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.117582368135751e-23, "cur_lr": 0.0005, "total_loss": 2105519.0, "policy_loss": 0.0009467793874335939, "vf_loss": 2105519.0, "vf_explained_var": 3.4570693969726562e-06, "kl": 0.0002452899443188272, "entropy": 1.197590172290802, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4440, "num_agent_steps_sampled": 13320, "num_steps_trained": 4440, "num_agent_steps_trained": 13320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 44, "training_iteration": 74, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.09738874435424805, "time_total_s": 8.246082305908203, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.246082305908203, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18204877728774968, "mean_inference_ms": 0.7501151890602914, "mean_action_processing_ms": 0.04766774412445501, "mean_env_wait_ms": 0.2905816115522302, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4500, "timesteps_this_iter": 0, "agent_timesteps_total": 13500, "timers": {"sample_time_ms": 109.423, "sample_throughput": 548.332, "load_time_ms": 0.176, "load_throughput": 340677.19, "learn_time_ms": 13.018, "learn_throughput": 4608.973, "update_time_ms": 0.907}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0587911840678755e-23, "cur_lr": 0.0005, "total_loss": 19021413.0, "policy_loss": 4.5313439478888995e-05, "vf_loss": 19021413.0, "vf_explained_var": -2.384185791015625e-07, "kl": 8.895922675655754e-05, "entropy": 1.218456745147705, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4500, "num_agent_steps_sampled": 13500, "num_steps_trained": 4500, "num_agent_steps_trained": 13500, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 45, "training_iteration": 75, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.10212087631225586, "time_total_s": 8.348203182220459, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f35e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.348203182220459, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18204877728774968, "mean_inference_ms": 0.7501151890602914, "mean_action_processing_ms": 0.04766774412445501, "mean_env_wait_ms": 0.2905816115522302, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4560, "timesteps_this_iter": 0, "agent_timesteps_total": 13680, "timers": {"sample_time_ms": 110.373, "sample_throughput": 543.611, "load_time_ms": 0.186, "load_throughput": 321978.301, "learn_time_ms": 13.043, "learn_throughput": 4599.993, "update_time_ms": 0.917}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.2939559203393774e-24, "cur_lr": 0.0005, "total_loss": 4492640.75, "policy_loss": -3.2812357648737134e-06, "vf_loss": 4492640.75, "vf_explained_var": -2.2649765014648438e-06, "kl": 4.380477076938727e-05, "entropy": 1.240752935409546, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4560, "num_agent_steps_sampled": 13680, "num_steps_trained": 4560, "num_agent_steps_trained": 13680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 45, "training_iteration": 76, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.09996962547302246, "time_total_s": 8.448172807693481, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.448172807693481, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1819437819316663, "mean_inference_ms": 0.750087263302062, "mean_action_processing_ms": 0.04765908920170485, "mean_env_wait_ms": 0.29062033937676846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4620, "timesteps_this_iter": 0, "agent_timesteps_total": 13860, "timers": {"sample_time_ms": 110.259, "sample_throughput": 544.172, "load_time_ms": 0.186, "load_throughput": 322473.398, "learn_time_ms": 13.184, "learn_throughput": 4551.07, "update_time_ms": 0.915}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.6469779601696887e-24, "cur_lr": 0.0005, "total_loss": 7961291.0, "policy_loss": -0.0007133688958766982, "vf_loss": 7961291.75, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.00016151669111152955, "entropy": 1.2649751901626587, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4620, "num_agent_steps_sampled": 13860, "num_steps_trained": 4620, "num_agent_steps_trained": 13860, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 46, "training_iteration": 77, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.09560179710388184, "time_total_s": 8.543774604797363, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277514c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.543774604797363, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1819437819316663, "mean_inference_ms": 0.750087263302062, "mean_action_processing_ms": 0.04765908920170485, "mean_env_wait_ms": 0.29062033937676846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4680, "timesteps_this_iter": 0, "agent_timesteps_total": 14040, "timers": {"sample_time_ms": 112.424, "sample_throughput": 533.693, "load_time_ms": 0.189, "load_throughput": 317629.989, "learn_time_ms": 13.243, "learn_throughput": 4530.766, "update_time_ms": 0.897}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3234889800848444e-24, "cur_lr": 0.0005, "total_loss": 10516996.0, "policy_loss": -0.0012804934832573167, "vf_loss": 10516996.0, "vf_explained_var": 6.854534149169922e-07, "kl": 0.00036569558386823076, "entropy": 1.2946404814720154, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4680, "num_agent_steps_sampled": 14040, "num_steps_trained": 4680, "num_agent_steps_trained": 14040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 46, "training_iteration": 78, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-40", "timestamp": 1742303380, "time_this_iter_s": 0.11198616027832031, "time_total_s": 8.655760765075684, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ae50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.655760765075684, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18184927279837013, "mean_inference_ms": 0.7501130060761483, "mean_action_processing_ms": 0.04765340947652427, "mean_env_wait_ms": 0.29067512920656036, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4740, "timesteps_this_iter": 0, "agent_timesteps_total": 14220, "timers": {"sample_time_ms": 112.862, "sample_throughput": 531.623, "load_time_ms": 0.194, "load_throughput": 309504.661, "learn_time_ms": 13.326, "learn_throughput": 4502.629, "update_time_ms": 0.907}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.617444900424222e-25, "cur_lr": 0.0005, "total_loss": 2103667.125, "policy_loss": 0.00041915244849377586, "vf_loss": 2103667.125, "vf_explained_var": -3.874301910400391e-06, "kl": 0.0002252994895481919, "entropy": 1.3220142722129822, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4740, "num_agent_steps_sampled": 14220, "num_steps_trained": 4740, "num_agent_steps_trained": 14220, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 47, "training_iteration": 79, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-41", "timestamp": 1742303381, "time_this_iter_s": 0.09543275833129883, "time_total_s": 8.751193523406982, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.751193523406982, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 17.5, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18176013154825235, "mean_inference_ms": 0.7501430756171289, "mean_action_processing_ms": 0.047648268896018996, "mean_env_wait_ms": 0.2907310160679111, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4800, "timesteps_this_iter": 0, "agent_timesteps_total": 14400, "timers": {"sample_time_ms": 113.242, "sample_throughput": 529.84, "load_time_ms": 0.196, "load_throughput": 306675.896, "learn_time_ms": 13.245, "learn_throughput": 4530.008, "update_time_ms": 0.914}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.308722450212111e-25, "cur_lr": 0.0005, "total_loss": 19011404.0, "policy_loss": -0.001261401173863419, "vf_loss": 19011404.0, "vf_explained_var": 4.172325134277344e-07, "kl": 0.00010336152755030525, "entropy": 1.3258941769599915, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4800, "num_agent_steps_sampled": 14400, "num_steps_trained": 4800, "num_agent_steps_trained": 14400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 48, "training_iteration": 80, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-41", "timestamp": 1742303381, "time_this_iter_s": 0.09676623344421387, "time_total_s": 8.847959756851196, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.847959756851196, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18176013154825235, "mean_inference_ms": 0.7501430756171289, "mean_action_processing_ms": 0.047648268896018996, "mean_env_wait_ms": 0.2907310160679111, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4860, "timesteps_this_iter": 0, "agent_timesteps_total": 14580, "timers": {"sample_time_ms": 114.519, "sample_throughput": 523.929, "load_time_ms": 0.19, "load_throughput": 315479.804, "learn_time_ms": 12.529, "learn_throughput": 4788.948, "update_time_ms": 0.909}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6543612251060554e-25, "cur_lr": 0.0005, "total_loss": 4491147.75, "policy_loss": -0.0019878722416848404, "vf_loss": 4491147.5, "vf_explained_var": 5.364418029785156e-06, "kl": 0.00036049037589025446, "entropy": 1.3478546142578125, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4860, "num_agent_steps_sampled": 14580, "num_steps_trained": 4860, "num_agent_steps_trained": 14580, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 48, "training_iteration": 81, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-41", "timestamp": 1742303381, "time_this_iter_s": 0.09811806678771973, "time_total_s": 8.946077823638916, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772adc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.946077823638916, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18168005091973108, "mean_inference_ms": 0.7501859239105646, "mean_action_processing_ms": 0.04764385470849878, "mean_env_wait_ms": 0.2907978872628888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4920, "timesteps_this_iter": 0, "agent_timesteps_total": 14760, "timers": {"sample_time_ms": 113.551, "sample_throughput": 528.398, "load_time_ms": 0.19, "load_throughput": 315440.261, "learn_time_ms": 12.543, "learn_throughput": 4783.677, "update_time_ms": 0.937}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.271806125530277e-26, "cur_lr": 0.0005, "total_loss": 7956106.75, "policy_loss": 5.3576629822416066e-05, "vf_loss": 7956106.0, "vf_explained_var": -2.0265579223632812e-06, "kl": 0.0003563061028195591, "entropy": 1.380323588848114, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4920, "num_agent_steps_sampled": 14760, "num_steps_trained": 4920, "num_agent_steps_trained": 14760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 49, "training_iteration": 82, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-41", "timestamp": 1742303381, "time_this_iter_s": 0.09912323951721191, "time_total_s": 9.045201063156128, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a5e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.045201063156128, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18168005091973108, "mean_inference_ms": 0.7501859239105646, "mean_action_processing_ms": 0.04764385470849878, "mean_env_wait_ms": 0.2907978872628888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4980, "timesteps_this_iter": 0, "agent_timesteps_total": 14940, "timers": {"sample_time_ms": 113.642, "sample_throughput": 527.976, "load_time_ms": 0.19, "load_throughput": 315519.358, "learn_time_ms": 13.044, "learn_throughput": 4599.967, "update_time_ms": 0.968}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.1359030627651386e-26, "cur_lr": 0.0005, "total_loss": 10514694.5, "policy_loss": 9.769797050296347e-05, "vf_loss": 10514694.0, "vf_explained_var": -1.430511474609375e-06, "kl": 9.278430428238948e-05, "entropy": 1.395615816116333, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4980, "num_agent_steps_sampled": 14940, "num_steps_trained": 4980, "num_agent_steps_trained": 14940, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 49, "training_iteration": 83, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-41", "timestamp": 1742303381, "time_this_iter_s": 0.09837913513183594, "time_total_s": 9.143580198287964, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772aa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.143580198287964, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18160032074132018, "mean_inference_ms": 0.7502358561413758, "mean_action_processing_ms": 0.047639782345949434, "mean_env_wait_ms": 0.2908616476148176, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5040, "timesteps_this_iter": 0, "agent_timesteps_total": 15120, "timers": {"sample_time_ms": 114.762, "sample_throughput": 522.82, "load_time_ms": 0.194, "load_throughput": 309809.479, "learn_time_ms": 13.041, "learn_throughput": 4600.893, "update_time_ms": 0.952}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.0679515313825693e-26, "cur_lr": 0.0005, "total_loss": 2101785.125, "policy_loss": -0.0006872673919942063, "vf_loss": 2101785.125, "vf_explained_var": 7.62939453125e-06, "kl": 0.00012936910383487543, "entropy": 1.4115831851959229, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5040, "num_agent_steps_sampled": 15120, "num_steps_trained": 5040, "num_agent_steps_trained": 15120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 50, "training_iteration": 84, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-41", "timestamp": 1742303381, "time_this_iter_s": 0.09747004508972168, "time_total_s": 9.241050243377686, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.241050243377686, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18152236999665808, "mean_inference_ms": 0.7502791977466335, "mean_action_processing_ms": 0.047635309976142494, "mean_env_wait_ms": 0.29091997673695424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5100, "timesteps_this_iter": 0, "agent_timesteps_total": 15300, "timers": {"sample_time_ms": 114.059, "sample_throughput": 526.041, "load_time_ms": 0.18, "load_throughput": 332705.235, "learn_time_ms": 12.96, "learn_throughput": 4629.756, "update_time_ms": 1.012}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0339757656912847e-26, "cur_lr": 0.0005, "total_loss": 19001457.0, "policy_loss": 0.0005842460591034548, "vf_loss": 19001457.0, "vf_explained_var": -2.7418136596679688e-06, "kl": 8.536890727306456e-05, "entropy": 1.4424684047698975, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5100, "num_agent_steps_sampled": 15300, "num_steps_trained": 5100, "num_agent_steps_trained": 15300, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 51, "training_iteration": 85, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-41", "timestamp": 1742303381, "time_this_iter_s": 0.09269022941589355, "time_total_s": 9.333740472793579, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.333740472793579, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 17.5, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18152236999665808, "mean_inference_ms": 0.7502791977466335, "mean_action_processing_ms": 0.047635309976142494, "mean_env_wait_ms": 0.29091997673695424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5160, "timesteps_this_iter": 0, "agent_timesteps_total": 15480, "timers": {"sample_time_ms": 113.285, "sample_throughput": 529.639, "load_time_ms": 0.18, "load_throughput": 332617.288, "learn_time_ms": 12.916, "learn_throughput": 4645.532, "update_time_ms": 1.001}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.169878828456423e-27, "cur_lr": 0.0005, "total_loss": 4489764.25, "policy_loss": -0.0019570717122405767, "vf_loss": 4489764.25, "vf_explained_var": -1.138448715209961e-05, "kl": 0.00010039339155909488, "entropy": 1.439212143421173, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5160, "num_agent_steps_sampled": 15480, "num_steps_trained": 5160, "num_agent_steps_trained": 15480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 51, "training_iteration": 86, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-41", "timestamp": 1742303381, "time_this_iter_s": 0.09072613716125488, "time_total_s": 9.424466609954834, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.424466609954834, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18144334128472173, "mean_inference_ms": 0.7503064600336621, "mean_action_processing_ms": 0.04762978009469465, "mean_env_wait_ms": 0.2909697924798004, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5220, "timesteps_this_iter": 0, "agent_timesteps_total": 15660, "timers": {"sample_time_ms": 113.468, "sample_throughput": 528.782, "load_time_ms": 0.182, "load_throughput": 329309.395, "learn_time_ms": 12.929, "learn_throughput": 4640.906, "update_time_ms": 0.994}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.5849394142282116e-27, "cur_lr": 0.0005, "total_loss": 7950884.25, "policy_loss": -0.0005993359411746724, "vf_loss": 7950884.25, "vf_explained_var": 2.6226043701171875e-06, "kl": 0.00013873704874711734, "entropy": 1.4092714190483093, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5220, "num_agent_steps_sampled": 15660, "num_steps_trained": 5220, "num_agent_steps_trained": 15660, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 52, "training_iteration": 87, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.09284543991088867, "time_total_s": 9.517312049865723, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.517312049865723, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18144334128472173, "mean_inference_ms": 0.7503064600336621, "mean_action_processing_ms": 0.04762978009469465, "mean_env_wait_ms": 0.2909697924798004, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5280, "timesteps_this_iter": 0, "agent_timesteps_total": 15840, "timers": {"sample_time_ms": 111.393, "sample_throughput": 538.634, "load_time_ms": 0.182, "load_throughput": 329094.076, "learn_time_ms": 12.888, "learn_throughput": 4655.338, "update_time_ms": 0.993}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2924697071141058e-27, "cur_lr": 0.0005, "total_loss": 10512492.5, "policy_loss": -0.00016090406894164744, "vf_loss": 10512492.5, "vf_explained_var": -2.2649765014648438e-06, "kl": 0.00015219599443305754, "entropy": 1.3845996856689453, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5280, "num_agent_steps_sampled": 15840, "num_steps_trained": 5280, "num_agent_steps_trained": 15840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 52, "training_iteration": 88, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.09018945693969727, "time_total_s": 9.60750150680542, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.60750150680542, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18137039863167706, "mean_inference_ms": 0.750330754351001, "mean_action_processing_ms": 0.047624357897080305, "mean_env_wait_ms": 0.2910174044374402, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5340, "timesteps_this_iter": 0, "agent_timesteps_total": 16020, "timers": {"sample_time_ms": 111.792, "sample_throughput": 536.709, "load_time_ms": 0.179, "load_throughput": 335276.099, "learn_time_ms": 12.99, "learn_throughput": 4619.006, "update_time_ms": 0.986}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.462348535570529e-28, "cur_lr": 0.0005, "total_loss": 2099951.125, "policy_loss": -0.00029904311264150607, "vf_loss": 2099951.0, "vf_explained_var": 2.205371856689453e-06, "kl": 4.4787623975750535e-05, "entropy": 1.3652417063713074, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5340, "num_agent_steps_sampled": 16020, "num_steps_trained": 5340, "num_agent_steps_trained": 16020, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 53, "training_iteration": 89, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.10151267051696777, "time_total_s": 9.709014177322388, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.709014177322388, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18129819006100178, "mean_inference_ms": 0.7503582968571785, "mean_action_processing_ms": 0.04761911354579265, "mean_env_wait_ms": 0.2910679117635448, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5400, "timesteps_this_iter": 0, "agent_timesteps_total": 16200, "timers": {"sample_time_ms": 111.785, "sample_throughput": 536.745, "load_time_ms": 0.165, "load_throughput": 363457.886, "learn_time_ms": 12.99, "learn_throughput": 4618.803, "update_time_ms": 0.985}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.2311742677852645e-28, "cur_lr": 0.0005, "total_loss": 18991472.0, "policy_loss": -0.0006691598139383359, "vf_loss": 18991473.0, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00010840368373266074, "entropy": 1.3702843189239502, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5400, "num_agent_steps_sampled": 16200, "num_steps_trained": 5400, "num_agent_steps_trained": 16200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 54, "training_iteration": 90, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.09614419937133789, "time_total_s": 9.805158376693726, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277515e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.805158376693726, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18129819006100178, "mean_inference_ms": 0.7503582968571785, "mean_action_processing_ms": 0.04761911354579265, "mean_env_wait_ms": 0.2910679117635448, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5460, "timesteps_this_iter": 0, "agent_timesteps_total": 16380, "timers": {"sample_time_ms": 110.396, "sample_throughput": 543.5, "load_time_ms": 0.165, "load_throughput": 363983.57, "learn_time_ms": 13.022, "learn_throughput": 4607.682, "update_time_ms": 0.961}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6155871338926323e-28, "cur_lr": 0.0005, "total_loss": 4488188.75, "policy_loss": -0.00024079216236705392, "vf_loss": 4488188.5, "vf_explained_var": 7.748603820800781e-07, "kl": 0.0001503048846469568, "entropy": 1.3833308815956116, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5460, "num_agent_steps_sampled": 16380, "num_steps_trained": 5460, "num_agent_steps_trained": 16380, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 54, "training_iteration": 91, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.09236693382263184, "time_total_s": 9.897525310516357, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771aee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.897525310516357, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1812263552941973, "mean_inference_ms": 0.7503779775258371, "mean_action_processing_ms": 0.047614100265378115, "mean_env_wait_ms": 0.2911157426505468, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5520, "timesteps_this_iter": 0, "agent_timesteps_total": 16560, "timers": {"sample_time_ms": 109.666, "sample_throughput": 547.118, "load_time_ms": 0.177, "load_throughput": 339207.764, "learn_time_ms": 13.072, "learn_throughput": 4590.025, "update_time_ms": 0.943}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.077935669463161e-29, "cur_lr": 0.0005, "total_loss": 7945735.75, "policy_loss": -0.001563079528406064, "vf_loss": 7945735.75, "vf_explained_var": -5.0067901611328125e-06, "kl": 0.00015293598086607574, "entropy": 1.3944054245948792, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5520, "num_agent_steps_sampled": 16560, "num_steps_trained": 5520, "num_agent_steps_trained": 16560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 55, "training_iteration": 92, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.09390759468078613, "time_total_s": 9.991432905197144, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.991432905197144, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 15.4, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1812263552941973, "mean_inference_ms": 0.7503779775258371, "mean_action_processing_ms": 0.047614100265378115, "mean_env_wait_ms": 0.2911157426505468, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5580, "timesteps_this_iter": 0, "agent_timesteps_total": 16740, "timers": {"sample_time_ms": 109.755, "sample_throughput": 546.674, "load_time_ms": 0.187, "load_throughput": 320461.276, "learn_time_ms": 12.727, "learn_throughput": 4714.228, "update_time_ms": 0.912}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.0389678347315807e-29, "cur_lr": 0.0005, "total_loss": 10510178.5, "policy_loss": 0.0003064003307358121, "vf_loss": 10510178.5, "vf_explained_var": 5.066394805908203e-06, "kl": 9.954849335391813e-05, "entropy": 1.3808229565620422, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5580, "num_agent_steps_sampled": 16740, "num_steps_trained": 5580, "num_agent_steps_trained": 16740, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 55, "training_iteration": 93, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.09346795082092285, "time_total_s": 10.084900856018066, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.084900856018066, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18115523105501263, "mean_inference_ms": 0.750390449849237, "mean_action_processing_ms": 0.0476086390664621, "mean_env_wait_ms": 0.2911568422482688, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5640, "timesteps_this_iter": 0, "agent_timesteps_total": 16920, "timers": {"sample_time_ms": 108.202, "sample_throughput": 554.516, "load_time_ms": 0.201, "load_throughput": 297926.175, "learn_time_ms": 12.81, "learn_throughput": 4683.687, "update_time_ms": 0.917}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.0194839173657903e-29, "cur_lr": 0.0005, "total_loss": 2098081.5, "policy_loss": -2.3473632808190814e-05, "vf_loss": 2098081.5, "vf_explained_var": -3.5762786865234375e-07, "kl": 7.365782019341793e-05, "entropy": 1.3748725652694702, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5640, "num_agent_steps_sampled": 16920, "num_steps_trained": 5640, "num_agent_steps_trained": 16920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 56, "training_iteration": 94, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.0924673080444336, "time_total_s": 10.1773681640625, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.1773681640625, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18108460179810815, "mean_inference_ms": 0.7503992001191362, "mean_action_processing_ms": 0.04760312625713915, "mean_env_wait_ms": 0.29119617114388374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5700, "timesteps_this_iter": 0, "agent_timesteps_total": 17100, "timers": {"sample_time_ms": 108.345, "sample_throughput": 553.787, "load_time_ms": 0.202, "load_throughput": 297117.166, "learn_time_ms": 12.84, "learn_throughput": 4673.033, "update_time_ms": 0.895}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0097419586828952e-29, "cur_lr": 0.0005, "total_loss": 18981565.0, "policy_loss": -0.0004993004918409927, "vf_loss": 18981565.0, "vf_explained_var": 1.1920928955078125e-06, "kl": 6.626221819505673e-05, "entropy": 1.3706415295600891, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5700, "num_agent_steps_sampled": 17100, "num_steps_trained": 5700, "num_agent_steps_trained": 17100, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 57, "training_iteration": 95, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.0931549072265625, "time_total_s": 10.270523071289062, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.270523071289062, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18108460179810815, "mean_inference_ms": 0.7503992001191362, "mean_action_processing_ms": 0.04760312625713915, "mean_env_wait_ms": 0.29119617114388374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5760, "timesteps_this_iter": 0, "agent_timesteps_total": 17280, "timers": {"sample_time_ms": 108.595, "sample_throughput": 552.512, "load_time_ms": 0.211, "load_throughput": 284745.689, "learn_time_ms": 12.798, "learn_throughput": 4688.076, "update_time_ms": 0.899}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.048709793414476e-30, "cur_lr": 0.0005, "total_loss": 4486841.25, "policy_loss": -0.002219826562537719, "vf_loss": 4486841.25, "vf_explained_var": 1.1324882507324219e-05, "kl": 0.00024763334391053604, "entropy": 1.379688799381256, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5760, "num_agent_steps_sampled": 17280, "num_steps_trained": 5760, "num_agent_steps_trained": 17280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 57, "training_iteration": 96, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-42", "timestamp": 1742303382, "time_this_iter_s": 0.09537935256958008, "time_total_s": 10.365902423858643, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.365902423858643, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18101567775405597, "mean_inference_ms": 0.7504158728694563, "mean_action_processing_ms": 0.047597766078085246, "mean_env_wait_ms": 0.29123613928740333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5820, "timesteps_this_iter": 0, "agent_timesteps_total": 17460, "timers": {"sample_time_ms": 108.688, "sample_throughput": 552.036, "load_time_ms": 0.209, "load_throughput": 287576.551, "learn_time_ms": 12.806, "learn_throughput": 4685.361, "update_time_ms": 0.896}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.524354896707238e-30, "cur_lr": 0.0005, "total_loss": 7940565.75, "policy_loss": 0.0006534967067040043, "vf_loss": 7940565.0, "vf_explained_var": -1.0728836059570312e-06, "kl": 0.0003202748597033178, "entropy": 1.400562584400177, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5820, "num_agent_steps_sampled": 17460, "num_steps_trained": 5820, "num_agent_steps_trained": 17460, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 58, "training_iteration": 97, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-43", "timestamp": 1742303383, "time_this_iter_s": 0.09799504280090332, "time_total_s": 10.463897466659546, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ad30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.463897466659546, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18101567775405597, "mean_inference_ms": 0.7504158728694563, "mean_action_processing_ms": 0.047597766078085246, "mean_env_wait_ms": 0.29123613928740333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5880, "timesteps_this_iter": 0, "agent_timesteps_total": 17640, "timers": {"sample_time_ms": 108.92, "sample_throughput": 550.865, "load_time_ms": 0.217, "load_throughput": 276334.951, "learn_time_ms": 12.737, "learn_throughput": 4710.655, "update_time_ms": 0.903}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.262177448353619e-30, "cur_lr": 0.0005, "total_loss": 10507955.0, "policy_loss": 7.734927558986082e-05, "vf_loss": 10507955.0, "vf_explained_var": -1.7881393432617188e-06, "kl": 0.00013308991334382014, "entropy": 1.4113897681236267, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5880, "num_agent_steps_sampled": 17640, "num_steps_trained": 5880, "num_agent_steps_trained": 17640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 58, "training_iteration": 98, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-43", "timestamp": 1742303383, "time_this_iter_s": 0.09342098236083984, "time_total_s": 10.557318449020386, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.557318449020386, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 13.8, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18094786863167167, "mean_inference_ms": 0.7504280013453953, "mean_action_processing_ms": 0.04759264000049752, "mean_env_wait_ms": 0.29126916579467227, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5940, "timesteps_this_iter": 0, "agent_timesteps_total": 17820, "timers": {"sample_time_ms": 108.084, "sample_throughput": 555.123, "load_time_ms": 0.211, "load_throughput": 284456.019, "learn_time_ms": 12.514, "learn_throughput": 4794.604, "update_time_ms": 0.91}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.310887241768095e-31, "cur_lr": 0.0005, "total_loss": 2096249.1875, "policy_loss": 0.00033365023684517325, "vf_loss": 2096249.1875, "vf_explained_var": -5.066394805908203e-06, "kl": 7.435793705878879e-06, "entropy": 1.4174482226371765, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5940, "num_agent_steps_sampled": 17820, "num_steps_trained": 5940, "num_agent_steps_trained": 17820, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 59, "training_iteration": 99, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-43", "timestamp": 1742303383, "time_this_iter_s": 0.09255266189575195, "time_total_s": 10.649871110916138, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.649871110916138, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18087996763117017, "mean_inference_ms": 0.7504364647681256, "mean_action_processing_ms": 0.047587262822611956, "mean_env_wait_ms": 0.2912994768344474, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6000, "timesteps_this_iter": 0, "agent_timesteps_total": 18000, "timers": {"sample_time_ms": 107.412, "sample_throughput": 558.596, "load_time_ms": 0.212, "load_throughput": 283590.534, "learn_time_ms": 12.598, "learn_throughput": 4762.511, "update_time_ms": 0.891}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.1554436208840474e-31, "cur_lr": 0.0005, "total_loss": 18971708.0, "policy_loss": -0.0015234652725553133, "vf_loss": 18971708.0, "vf_explained_var": 7.0035457611083984e-06, "kl": 4.573870378266065e-05, "entropy": 1.4191659688949585, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6000, "num_agent_steps_sampled": 18000, "num_steps_trained": 6000, "num_agent_steps_trained": 18000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14259635299995263, "mean_inference_ms": 0.7553259055058044, "mean_action_processing_ms": 0.04582807816367695, "mean_env_wait_ms": 0.2831699012935549, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 60, "training_iteration": 100, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-44", "timestamp": 1742303384, "time_this_iter_s": 1.332489252090454, "time_total_s": 11.982360363006592, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11.982360363006592, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 13.149999999999999, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18087996763117017, "mean_inference_ms": 0.7504364647681256, "mean_action_processing_ms": 0.047587262822611956, "mean_env_wait_ms": 0.2912994768344474, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6060, "timesteps_this_iter": 0, "agent_timesteps_total": 18180, "timers": {"sample_time_ms": 232.782, "sample_throughput": 257.751, "load_time_ms": 0.223, "load_throughput": 268779.494, "learn_time_ms": 12.55, "learn_throughput": 4780.714, "update_time_ms": 0.917}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5777218104420237e-31, "cur_lr": 0.0005, "total_loss": 4485307.75, "policy_loss": -0.003621201455182188, "vf_loss": 4485307.0, "vf_explained_var": 8.702278137207031e-06, "kl": 0.00038205762597431914, "entropy": 1.4354763627052307, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6060, "num_agent_steps_sampled": 18180, "num_steps_trained": 6060, "num_agent_steps_trained": 18180, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 60, "training_iteration": 101, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-44", "timestamp": 1742303384, "time_this_iter_s": 0.09316849708557129, "time_total_s": 12.075528860092163, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.075528860092163, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.180812949084497, "mean_inference_ms": 0.7504419928651905, "mean_action_processing_ms": 0.04758173515719188, "mean_env_wait_ms": 0.29132673865259096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6120, "timesteps_this_iter": 0, "agent_timesteps_total": 18360, "timers": {"sample_time_ms": 232.887, "sample_throughput": 257.635, "load_time_ms": 0.214, "load_throughput": 280149.438, "learn_time_ms": 12.657, "learn_throughput": 4740.273, "update_time_ms": 0.905}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.888609052210118e-32, "cur_lr": 0.0005, "total_loss": 7935431.0, "policy_loss": -0.0005294773507759643, "vf_loss": 7935430.75, "vf_explained_var": 5.364418029785156e-07, "kl": 0.0004899570609369075, "entropy": 1.4613070487976074, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6120, "num_agent_steps_sampled": 18360, "num_steps_trained": 6120, "num_agent_steps_trained": 18360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 61, "training_iteration": 102, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-44", "timestamp": 1742303384, "time_this_iter_s": 0.09407877922058105, "time_total_s": 12.169607639312744, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a3a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.169607639312744, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.180812949084497, "mean_inference_ms": 0.7504419928651905, "mean_action_processing_ms": 0.04758173515719188, "mean_env_wait_ms": 0.29132673865259096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6180, "timesteps_this_iter": 0, "agent_timesteps_total": 18540, "timers": {"sample_time_ms": 233.007, "sample_throughput": 257.503, "load_time_ms": 0.204, "load_throughput": 293650.222, "learn_time_ms": 12.498, "learn_throughput": 4800.577, "update_time_ms": 0.913}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.944304526105059e-32, "cur_lr": 0.0005, "total_loss": 10505605.5, "policy_loss": 3.6885341749837153e-06, "vf_loss": 10505605.5, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00036356979060370165, "entropy": 1.4894102215766907, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6180, "num_agent_steps_sampled": 18540, "num_steps_trained": 6180, "num_agent_steps_trained": 18540, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 61, "training_iteration": 103, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-44", "timestamp": 1742303384, "time_this_iter_s": 0.09287238121032715, "time_total_s": 12.262480020523071, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277514c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.262480020523071, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18074658761041076, "mean_inference_ms": 0.750446584286976, "mean_action_processing_ms": 0.04757637240726661, "mean_env_wait_ms": 0.2913521858308096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6240, "timesteps_this_iter": 0, "agent_timesteps_total": 18720, "timers": {"sample_time_ms": 233.372, "sample_throughput": 257.1, "load_time_ms": 0.187, "load_throughput": 320951.715, "learn_time_ms": 12.545, "learn_throughput": 4782.713, "update_time_ms": 0.913}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9721522630525296e-32, "cur_lr": 0.0005, "total_loss": 2094414.375, "policy_loss": -8.969704585126692e-05, "vf_loss": 2094414.375, "vf_explained_var": -1.3470649719238281e-05, "kl": 0.0001345527294773774, "entropy": 1.5007840394973755, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6240, "num_agent_steps_sampled": 18720, "num_steps_trained": 6240, "num_agent_steps_trained": 18720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 62, "training_iteration": 104, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.09495329856872559, "time_total_s": 12.357433319091797, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.357433319091797, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1806804129250506, "mean_inference_ms": 0.7504477845416606, "mean_action_processing_ms": 0.04757076508739599, "mean_env_wait_ms": 0.29137348229304055, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6300, "timesteps_this_iter": 0, "agent_timesteps_total": 18900, "timers": {"sample_time_ms": 233.254, "sample_throughput": 257.231, "load_time_ms": 0.187, "load_throughput": 321690.196, "learn_time_ms": 12.454, "learn_throughput": 4817.634, "update_time_ms": 0.893}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.860761315262648e-33, "cur_lr": 0.0005, "total_loss": 18961913.0, "policy_loss": -0.001691276507660433, "vf_loss": 18961913.0, "vf_explained_var": -1.2516975402832031e-06, "kl": 0.00013356361346961165, "entropy": 1.5028084516525269, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6300, "num_agent_steps_sampled": 18900, "num_steps_trained": 6300, "num_agent_steps_trained": 18900, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 63, "training_iteration": 105, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.09064507484436035, "time_total_s": 12.448078393936157, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.448078393936157, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1806804129250506, "mean_inference_ms": 0.7504477845416606, "mean_action_processing_ms": 0.04757076508739599, "mean_env_wait_ms": 0.29137348229304055, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6360, "timesteps_this_iter": 0, "agent_timesteps_total": 19080, "timers": {"sample_time_ms": 232.876, "sample_throughput": 257.647, "load_time_ms": 0.168, "load_throughput": 357977.582, "learn_time_ms": 12.451, "learn_throughput": 4818.962, "update_time_ms": 0.891}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.930380657631324e-33, "cur_lr": 0.0005, "total_loss": 4483887.0, "policy_loss": -0.0006733629348047998, "vf_loss": 4483887.25, "vf_explained_var": -1.3530254364013672e-05, "kl": 0.00022601818924883332, "entropy": 1.5189939141273499, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6360, "num_agent_steps_sampled": 19080, "num_steps_trained": 6360, "num_agent_steps_trained": 19080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 63, "training_iteration": 106, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.09135603904724121, "time_total_s": 12.539434432983398, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.539434432983398, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 13.4, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18061597700429632, "mean_inference_ms": 0.7504423790393834, "mean_action_processing_ms": 0.047565122294796716, "mean_env_wait_ms": 0.2913916865835829, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6420, "timesteps_this_iter": 0, "agent_timesteps_total": 19260, "timers": {"sample_time_ms": 232.731, "sample_throughput": 257.809, "load_time_ms": 0.168, "load_throughput": 357418.321, "learn_time_ms": 12.262, "learn_throughput": 4893.047, "update_time_ms": 0.918}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.465190328815662e-33, "cur_lr": 0.0005, "total_loss": 7930285.25, "policy_loss": -0.0006206075505659214, "vf_loss": 7930284.75, "vf_explained_var": -4.76837158203125e-07, "kl": 0.0002812338611848375, "entropy": 1.5118598937988281, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6420, "num_agent_steps_sampled": 19260, "num_steps_trained": 6420, "num_agent_steps_trained": 19260, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 64, "training_iteration": 107, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.09285306930541992, "time_total_s": 12.632287502288818, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.632287502288818, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18061597700429632, "mean_inference_ms": 0.7504423790393834, "mean_action_processing_ms": 0.047565122294796716, "mean_env_wait_ms": 0.2913916865835829, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6480, "timesteps_this_iter": 0, "agent_timesteps_total": 19440, "timers": {"sample_time_ms": 232.797, "sample_throughput": 257.735, "load_time_ms": 0.157, "load_throughput": 382459.331, "learn_time_ms": 12.327, "learn_throughput": 4867.184, "update_time_ms": 0.919}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.232595164407831e-33, "cur_lr": 0.0005, "total_loss": 10503364.5, "policy_loss": -0.002095697416613973, "vf_loss": 10503364.5, "vf_explained_var": -2.1457672119140625e-06, "kl": 0.0003297352158160294, "entropy": 1.4962724447250366, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6480, "num_agent_steps_sampled": 19440, "num_steps_trained": 6480, "num_agent_steps_trained": 19440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 64, "training_iteration": 108, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.09515595436096191, "time_total_s": 12.72744345664978, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.72744345664978, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18055546297056355, "mean_inference_ms": 0.7504415903251119, "mean_action_processing_ms": 0.047560094796372236, "mean_env_wait_ms": 0.29141240235740645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6540, "timesteps_this_iter": 0, "agent_timesteps_total": 19620, "timers": {"sample_time_ms": 233.283, "sample_throughput": 257.198, "load_time_ms": 0.159, "load_throughput": 377921.97, "learn_time_ms": 12.335, "learn_throughput": 4864.362, "update_time_ms": 0.915}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.162975822039155e-34, "cur_lr": 0.0005, "total_loss": 2092563.875, "policy_loss": -0.00028892820636627903, "vf_loss": 2092563.8125, "vf_explained_var": -5.960464477539062e-07, "kl": 0.00030830096890999137, "entropy": 1.4696276187896729, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6540, "num_agent_steps_sampled": 19620, "num_steps_trained": 6540, "num_agent_steps_trained": 19620, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 65, "training_iteration": 109, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.09681987762451172, "time_total_s": 12.824263334274292, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.824263334274292, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1804952768673007, "mean_inference_ms": 0.7504381822313771, "mean_action_processing_ms": 0.04755486507369677, "mean_env_wait_ms": 0.2914297935376322, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6600, "timesteps_this_iter": 0, "agent_timesteps_total": 19800, "timers": {"sample_time_ms": 233.333, "sample_throughput": 257.143, "load_time_ms": 0.158, "load_throughput": 379976.204, "learn_time_ms": 12.329, "learn_throughput": 4866.563, "update_time_ms": 0.922}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0814879110195775e-34, "cur_lr": 0.0005, "total_loss": 18951981.0, "policy_loss": -0.0004067407713996829, "vf_loss": 18951982.0, "vf_explained_var": 1.6689300537109375e-06, "kl": 0.00017274643045084304, "entropy": 1.4458398818969727, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6600, "num_agent_steps_sampled": 19800, "num_steps_trained": 6600, "num_agent_steps_trained": 19800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 66, "training_iteration": 110, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.0911870002746582, "time_total_s": 12.91545033454895, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.91545033454895, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1804952768673007, "mean_inference_ms": 0.7504381822313771, "mean_action_processing_ms": 0.04755486507369677, "mean_env_wait_ms": 0.2914297935376322, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6660, "timesteps_this_iter": 0, "agent_timesteps_total": 19980, "timers": {"sample_time_ms": 108.262, "sample_throughput": 554.212, "load_time_ms": 0.146, "load_throughput": 409600.0, "learn_time_ms": 12.232, "learn_throughput": 4905.255, "update_time_ms": 0.913}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5407439555097888e-34, "cur_lr": 0.0005, "total_loss": 4482374.0, "policy_loss": 7.432599636203463e-05, "vf_loss": 4482374.0, "vf_explained_var": 2.682209014892578e-06, "kl": 7.40357663540081e-05, "entropy": 1.430411696434021, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6660, "num_agent_steps_sampled": 19980, "num_steps_trained": 6660, "num_agent_steps_trained": 19980, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 66, "training_iteration": 111, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.09238624572753906, "time_total_s": 13.00783658027649, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771aca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.00783658027649, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1804387599376251, "mean_inference_ms": 0.7504322331323404, "mean_action_processing_ms": 0.0475491259050657, "mean_env_wait_ms": 0.2914448599255343, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6720, "timesteps_this_iter": 0, "agent_timesteps_total": 20160, "timers": {"sample_time_ms": 108.258, "sample_throughput": 554.23, "load_time_ms": 0.143, "load_throughput": 419710.207, "learn_time_ms": 12.178, "learn_throughput": 4927.007, "update_time_ms": 0.925}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.703719777548944e-35, "cur_lr": 0.0005, "total_loss": 7925136.0, "policy_loss": -0.0008979300670839407, "vf_loss": 7925135.5, "vf_explained_var": -7.152557373046875e-07, "kl": 8.071282470734076e-05, "entropy": 1.4218135476112366, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6720, "num_agent_steps_sampled": 20160, "num_steps_trained": 6720, "num_agent_steps_trained": 20160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 67, "training_iteration": 112, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-45", "timestamp": 1742303385, "time_this_iter_s": 0.0947880744934082, "time_total_s": 13.102624654769897, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.102624654769897, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 13.5, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1804387599376251, "mean_inference_ms": 0.7504322331323404, "mean_action_processing_ms": 0.0475491259050657, "mean_env_wait_ms": 0.2914448599255343, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6780, "timesteps_this_iter": 0, "agent_timesteps_total": 20340, "timers": {"sample_time_ms": 108.127, "sample_throughput": 554.904, "load_time_ms": 0.154, "load_throughput": 388721.409, "learn_time_ms": 12.188, "learn_throughput": 4922.719, "update_time_ms": 0.986}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.851859888774472e-35, "cur_lr": 0.0005, "total_loss": 10501085.5, "policy_loss": -0.0003194517475364478, "vf_loss": 10501086.0, "vf_explained_var": 5.841255187988281e-06, "kl": 0.00012120006749505308, "entropy": 1.399630069732666, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6780, "num_agent_steps_sampled": 20340, "num_steps_trained": 6780, "num_agent_steps_trained": 20340, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 67, "training_iteration": 113, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.09427905082702637, "time_total_s": 13.196903705596924, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.196903705596924, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18038449037882953, "mean_inference_ms": 0.7504240305353086, "mean_action_processing_ms": 0.04754344195581395, "mean_env_wait_ms": 0.2914595085594656, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6840, "timesteps_this_iter": 0, "agent_timesteps_total": 20520, "timers": {"sample_time_ms": 107.853, "sample_throughput": 556.311, "load_time_ms": 0.164, "load_throughput": 366688.387, "learn_time_ms": 12.212, "learn_throughput": 4913.386, "update_time_ms": 0.993}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.925929944387236e-35, "cur_lr": 0.0005, "total_loss": 2090737.0, "policy_loss": -0.0009248210466452633, "vf_loss": 2090736.875, "vf_explained_var": 5.662441253662109e-06, "kl": 0.00010443650830627149, "entropy": 1.3923229575157166, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6840, "num_agent_steps_sampled": 20520, "num_steps_trained": 6840, "num_agent_steps_trained": 20520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 68, "training_iteration": 114, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.0951073169708252, "time_total_s": 13.292011022567749, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.292011022567749, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18032965976097393, "mean_inference_ms": 0.7504119904413719, "mean_action_processing_ms": 0.047537884774851526, "mean_env_wait_ms": 0.2914709055444316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6900, "timesteps_this_iter": 0, "agent_timesteps_total": 20700, "timers": {"sample_time_ms": 107.628, "sample_throughput": 557.475, "load_time_ms": 0.179, "load_throughput": 335365.458, "learn_time_ms": 12.382, "learn_throughput": 4845.741, "update_time_ms": 0.979}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.62964972193618e-36, "cur_lr": 0.0005, "total_loss": 18942129.0, "policy_loss": -0.0010944886107182583, "vf_loss": 18942129.0, "vf_explained_var": 2.682209014892578e-06, "kl": 0.00013812210183772322, "entropy": 1.4003874063491821, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6900, "num_agent_steps_sampled": 20700, "num_steps_trained": 6900, "num_agent_steps_trained": 20700, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 69, "training_iteration": 115, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.09102916717529297, "time_total_s": 13.383040189743042, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.383040189743042, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18032965976097393, "mean_inference_ms": 0.7504119904413719, "mean_action_processing_ms": 0.047537884774851526, "mean_env_wait_ms": 0.2914709055444316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6960, "timesteps_this_iter": 0, "agent_timesteps_total": 20880, "timers": {"sample_time_ms": 107.755, "sample_throughput": 556.818, "load_time_ms": 0.179, "load_throughput": 334696.422, "learn_time_ms": 12.337, "learn_throughput": 4863.469, "update_time_ms": 1.003}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.81482486096809e-36, "cur_lr": 0.0005, "total_loss": 4480949.75, "policy_loss": 0.000224572422709457, "vf_loss": 4480950.0, "vf_explained_var": 7.748603820800781e-07, "kl": 0.00013692417126875966, "entropy": 1.4222410917282104, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6960, "num_agent_steps_sampled": 20880, "num_steps_trained": 6960, "num_agent_steps_trained": 20880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 69, "training_iteration": 116, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.09305119514465332, "time_total_s": 13.476091384887695, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.476091384887695, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1802771955464904, "mean_inference_ms": 0.750400888786915, "mean_action_processing_ms": 0.04753227806122559, "mean_env_wait_ms": 0.2914794057150294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7020, "timesteps_this_iter": 0, "agent_timesteps_total": 21060, "timers": {"sample_time_ms": 107.577, "sample_throughput": 557.738, "load_time_ms": 0.179, "load_throughput": 334963.716, "learn_time_ms": 12.467, "learn_throughput": 4812.622, "update_time_ms": 0.973}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.407412430484045e-36, "cur_lr": 0.0005, "total_loss": 7920039.0, "policy_loss": -0.00014213588114664333, "vf_loss": 7920039.75, "vf_explained_var": -3.337860107421875e-06, "kl": 6.922363322914293e-05, "entropy": 1.4448776245117188, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7020, "num_agent_steps_sampled": 21060, "num_steps_trained": 7020, "num_agent_steps_trained": 21060, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 70, "training_iteration": 117, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.09465551376342773, "time_total_s": 13.570746898651123, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.570746898651123, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1802771955464904, "mean_inference_ms": 0.750400888786915, "mean_action_processing_ms": 0.04753227806122559, "mean_env_wait_ms": 0.2914794057150294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7080, "timesteps_this_iter": 0, "agent_timesteps_total": 21240, "timers": {"sample_time_ms": 107.442, "sample_throughput": 558.441, "load_time_ms": 0.179, "load_throughput": 335231.437, "learn_time_ms": 12.414, "learn_throughput": 4833.335, "update_time_ms": 1.026}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2037062152420225e-36, "cur_lr": 0.0005, "total_loss": 10498971.0, "policy_loss": 0.00030713644745361535, "vf_loss": 10498971.0, "vf_explained_var": -1.430511474609375e-06, "kl": 5.825860668329241e-05, "entropy": 1.438341498374939, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7080, "num_agent_steps_sampled": 21240, "num_steps_trained": 7080, "num_agent_steps_trained": 21240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 70, "training_iteration": 118, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.0930325984954834, "time_total_s": 13.663779497146606, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.663779497146606, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18022572792079372, "mean_inference_ms": 0.7503860046998035, "mean_action_processing_ms": 0.04752648644554589, "mean_env_wait_ms": 0.2914872612874135, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7140, "timesteps_this_iter": 0, "agent_timesteps_total": 21420, "timers": {"sample_time_ms": 107.161, "sample_throughput": 559.904, "load_time_ms": 0.175, "load_throughput": 342485.357, "learn_time_ms": 12.484, "learn_throughput": 4806.142, "update_time_ms": 1.022}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.018531076210112e-37, "cur_lr": 0.0005, "total_loss": 2088911.875, "policy_loss": -0.0018798205949774882, "vf_loss": 2088911.875, "vf_explained_var": 1.4901161193847656e-06, "kl": 0.00013205516688330476, "entropy": 1.4272612929344177, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7140, "num_agent_steps_sampled": 21420, "num_steps_trained": 7140, "num_agent_steps_trained": 21420, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 71, "training_iteration": 119, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.09363389015197754, "time_total_s": 13.757413387298584, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277514c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.757413387298584, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 14.0, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18017407007434505, "mean_inference_ms": 0.7503692267135131, "mean_action_processing_ms": 0.047520678019677014, "mean_env_wait_ms": 0.29149362553330793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7200, "timesteps_this_iter": 0, "agent_timesteps_total": 21600, "timers": {"sample_time_ms": 107.126, "sample_throughput": 560.09, "load_time_ms": 0.176, "load_throughput": 340262.628, "learn_time_ms": 12.398, "learn_throughput": 4839.526, "update_time_ms": 1.015}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.009265538105056e-37, "cur_lr": 0.0005, "total_loss": 18932319.0, "policy_loss": 0.0006516152216740068, "vf_loss": 18932320.0, "vf_explained_var": 8.940696716308594e-07, "kl": 0.00017178160237607543, "entropy": 1.3909628987312317, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7200, "num_agent_steps_sampled": 21600, "num_steps_trained": 7200, "num_agent_steps_trained": 21600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 72, "training_iteration": 120, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.09242463111877441, "time_total_s": 13.849838018417358, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.849838018417358, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18017407007434505, "mean_inference_ms": 0.7503692267135131, "mean_action_processing_ms": 0.047520678019677014, "mean_env_wait_ms": 0.29149362553330793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7260, "timesteps_this_iter": 0, "agent_timesteps_total": 21780, "timers": {"sample_time_ms": 107.803, "sample_throughput": 556.569, "load_time_ms": 0.185, "load_throughput": 324678.416, "learn_time_ms": 12.542, "learn_throughput": 4783.886, "update_time_ms": 0.996}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.504632769052528e-37, "cur_lr": 0.0005, "total_loss": 4479359.0, "policy_loss": -0.0008276429454170398, "vf_loss": 4479358.75, "vf_explained_var": 1.3262033462524414e-05, "kl": 6.914648341904694e-05, "entropy": 1.3737261295318604, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7260, "num_agent_steps_sampled": 21780, "num_steps_trained": 7260, "num_agent_steps_trained": 21780, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 72, "training_iteration": 121, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-46", "timestamp": 1742303386, "time_this_iter_s": 0.0909268856048584, "time_total_s": 13.940764904022217, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.940764904022217, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18012318307088795, "mean_inference_ms": 0.7503558399854202, "mean_action_processing_ms": 0.047515009379167965, "mean_env_wait_ms": 0.29150112254447147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7320, "timesteps_this_iter": 0, "agent_timesteps_total": 21960, "timers": {"sample_time_ms": 108.249, "sample_throughput": 554.279, "load_time_ms": 0.194, "load_throughput": 309124.481, "learn_time_ms": 12.525, "learn_throughput": 4790.251, "update_time_ms": 0.996}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.52316384526264e-38, "cur_lr": 0.0005, "total_loss": 7914897.75, "policy_loss": -0.0004947761629914282, "vf_loss": 7914897.25, "vf_explained_var": 2.294778823852539e-06, "kl": 0.00010368067827926097, "entropy": 1.3860328793525696, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7320, "num_agent_steps_sampled": 21960, "num_steps_trained": 7320, "num_agent_steps_trained": 21960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 73, "training_iteration": 122, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.09923052787780762, "time_total_s": 14.039995431900024, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.039995431900024, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18012318307088795, "mean_inference_ms": 0.7503558399854202, "mean_action_processing_ms": 0.047515009379167965, "mean_env_wait_ms": 0.29150112254447147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7380, "timesteps_this_iter": 0, "agent_timesteps_total": 22140, "timers": {"sample_time_ms": 108.42, "sample_throughput": 553.405, "load_time_ms": 0.19, "load_throughput": 315361.203, "learn_time_ms": 12.629, "learn_throughput": 4751.128, "update_time_ms": 0.927}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.76158192263132e-38, "cur_lr": 0.0005, "total_loss": 10496588.0, "policy_loss": -0.000684382511664694, "vf_loss": 10496588.0, "vf_explained_var": -4.410743713378906e-06, "kl": 0.00017836952791938643, "entropy": 1.4232395887374878, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7380, "num_agent_steps_sampled": 22140, "num_steps_trained": 7380, "num_agent_steps_trained": 22140, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 73, "training_iteration": 123, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.09674835205078125, "time_total_s": 14.136743783950806, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.136743783950806, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18007521851285352, "mean_inference_ms": 0.7503417662131301, "mean_action_processing_ms": 0.04750952180255274, "mean_env_wait_ms": 0.29150786097491915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7440, "timesteps_this_iter": 0, "agent_timesteps_total": 22320, "timers": {"sample_time_ms": 108.328, "sample_throughput": 553.874, "load_time_ms": 0.18, "load_throughput": 333498.86, "learn_time_ms": 12.633, "learn_throughput": 4749.353, "update_time_ms": 0.924}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.88079096131566e-38, "cur_lr": 0.0005, "total_loss": 2087087.75, "policy_loss": 0.00021067858421375263, "vf_loss": 2087087.4375, "vf_explained_var": 1.6093254089355469e-06, "kl": 0.00020184561026725945, "entropy": 1.4735141396522522, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7440, "num_agent_steps_sampled": 22320, "num_steps_trained": 7440, "num_agent_steps_trained": 22320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 74, "training_iteration": 124, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.09349870681762695, "time_total_s": 14.230242490768433, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.230242490768433, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18002798704961379, "mean_inference_ms": 0.7503294098534542, "mean_action_processing_ms": 0.04750423508298548, "mean_env_wait_ms": 0.29151727266461896, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7500, "timesteps_this_iter": 0, "agent_timesteps_total": 22500, "timers": {"sample_time_ms": 109.126, "sample_throughput": 549.825, "load_time_ms": 0.175, "load_throughput": 341926.957, "learn_time_ms": 12.479, "learn_throughput": 4808.089, "update_time_ms": 0.926}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.4039548065783e-39, "cur_lr": 0.0005, "total_loss": 18922523.0, "policy_loss": -0.0010137919000214879, "vf_loss": 18922523.0, "vf_explained_var": 1.6391277313232422e-06, "kl": 0.00022020597047972545, "entropy": 1.5157484412193298, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7500, "num_agent_steps_sampled": 22500, "num_steps_trained": 7500, "num_agent_steps_trained": 22500, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 75, "training_iteration": 125, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.09601259231567383, "time_total_s": 14.326255083084106, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.326255083084106, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 13.6, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18002798704961379, "mean_inference_ms": 0.7503294098534542, "mean_action_processing_ms": 0.04750423508298548, "mean_env_wait_ms": 0.29151727266461896, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7560, "timesteps_this_iter": 0, "agent_timesteps_total": 22680, "timers": {"sample_time_ms": 108.934, "sample_throughput": 550.794, "load_time_ms": 0.186, "load_throughput": 322514.725, "learn_time_ms": 12.684, "learn_throughput": 4730.454, "update_time_ms": 0.902}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.70197740328915e-39, "cur_lr": 0.0005, "total_loss": 4477983.75, "policy_loss": -0.0007394028814609044, "vf_loss": 4477983.5, "vf_explained_var": -1.9073486328125e-06, "kl": 0.00025411991218327046, "entropy": 1.563761293888092, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7560, "num_agent_steps_sampled": 22680, "num_steps_trained": 7560, "num_agent_steps_trained": 22680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 75, "training_iteration": 126, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.0930318832397461, "time_total_s": 14.419286966323853, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.419286966323853, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17998194010951027, "mean_inference_ms": 0.7503142667092956, "mean_action_processing_ms": 0.04749899455711914, "mean_env_wait_ms": 0.29152678904382795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7620, "timesteps_this_iter": 0, "agent_timesteps_total": 22860, "timers": {"sample_time_ms": 109.12, "sample_throughput": 549.852, "load_time_ms": 0.197, "load_throughput": 304892.464, "learn_time_ms": 12.65, "learn_throughput": 4742.944, "update_time_ms": 0.943}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.350988701644575e-39, "cur_lr": 0.0005, "total_loss": 7909836.5, "policy_loss": -0.0018179191069478406, "vf_loss": 7909837.25, "vf_explained_var": 1.4007091522216797e-06, "kl": 0.00031208426241069454, "entropy": 1.598448097705841, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7620, "num_agent_steps_sampled": 22860, "num_steps_trained": 7620, "num_agent_steps_trained": 22860, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 76, "training_iteration": 127, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.09553098678588867, "time_total_s": 14.514817953109741, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.514817953109741, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17998194010951027, "mean_inference_ms": 0.7503142667092956, "mean_action_processing_ms": 0.04749899455711914, "mean_env_wait_ms": 0.29152678904382795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7680, "timesteps_this_iter": 0, "agent_timesteps_total": 23040, "timers": {"sample_time_ms": 109.23, "sample_throughput": 549.301, "load_time_ms": 0.197, "load_throughput": 304781.688, "learn_time_ms": 12.74, "learn_throughput": 4709.658, "update_time_ms": 0.911}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1754943508222876e-39, "cur_lr": 0.0005, "total_loss": 10494285.0, "policy_loss": 0.00045780141695583865, "vf_loss": 10494284.5, "vf_explained_var": -4.172325134277344e-06, "kl": 0.0002894894348639543, "entropy": 1.6259637475013733, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7680, "num_agent_steps_sampled": 23040, "num_steps_trained": 7680, "num_agent_steps_trained": 23040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 76, "training_iteration": 128, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.0950326919555664, "time_total_s": 14.609850645065308, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.609850645065308, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17993801051240468, "mean_inference_ms": 0.7503066920061053, "mean_action_processing_ms": 0.04749360127251532, "mean_env_wait_ms": 0.29153584206075395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7740, "timesteps_this_iter": 0, "agent_timesteps_total": 23220, "timers": {"sample_time_ms": 110.122, "sample_throughput": 544.851, "load_time_ms": 0.207, "load_throughput": 289428.683, "learn_time_ms": 12.801, "learn_throughput": 4687.115, "update_time_ms": 0.913}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.877471754111438e-40, "cur_lr": 0.0005, "total_loss": 2085279.4375, "policy_loss": -0.0004596077604217541, "vf_loss": 2085279.5625, "vf_explained_var": 1.055002212524414e-05, "kl": 0.00018399201680754929, "entropy": 1.6409295797348022, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7740, "num_agent_steps_sampled": 23220, "num_steps_trained": 7740, "num_agent_steps_trained": 23220, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 77, "training_iteration": 129, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.10016942024230957, "time_total_s": 14.710020065307617, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.710020065307617, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17989420710258058, "mean_inference_ms": 0.7502965926380225, "mean_action_processing_ms": 0.04748810804440576, "mean_env_wait_ms": 0.2915429430033446, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7800, "timesteps_this_iter": 0, "agent_timesteps_total": 23400, "timers": {"sample_time_ms": 110.182, "sample_throughput": 544.553, "load_time_ms": 0.207, "load_throughput": 289895.45, "learn_time_ms": 12.766, "learn_throughput": 4699.807, "update_time_ms": 0.92}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.938735877055719e-40, "cur_lr": 0.0005, "total_loss": 18912884.0, "policy_loss": -0.0012809442537324855, "vf_loss": 18912885.0, "vf_explained_var": -1.9073486328125e-06, "kl": 0.0002207722816951474, "entropy": 1.6564449667930603, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7800, "num_agent_steps_sampled": 23400, "num_steps_trained": 7800, "num_agent_steps_trained": 23400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 78, "training_iteration": 130, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-47", "timestamp": 1742303387, "time_this_iter_s": 0.09090781211853027, "time_total_s": 14.800927877426147, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.800927877426147, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17989420710258058, "mean_inference_ms": 0.7502965926380225, "mean_action_processing_ms": 0.04748810804440576, "mean_env_wait_ms": 0.2915429430033446, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7860, "timesteps_this_iter": 0, "agent_timesteps_total": 23580, "timers": {"sample_time_ms": 109.562, "sample_throughput": 547.635, "load_time_ms": 0.198, "load_throughput": 302401.154, "learn_time_ms": 12.808, "learn_throughput": 4684.663, "update_time_ms": 0.92}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4693679385278595e-40, "cur_lr": 0.0005, "total_loss": 4476542.25, "policy_loss": -0.0023052264418872426, "vf_loss": 4476542.25, "vf_explained_var": 6.973743438720703e-06, "kl": 0.00037819600400013087, "entropy": 1.6708966493606567, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7860, "num_agent_steps_sampled": 23580, "num_steps_trained": 7860, "num_agent_steps_trained": 23580, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 78, "training_iteration": 131, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.09451770782470703, "time_total_s": 14.895445585250854, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.895445585250854, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.179852427779951, "mean_inference_ms": 0.7502900750519077, "mean_action_processing_ms": 0.04748263133243097, "mean_env_wait_ms": 0.2915489941199653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7920, "timesteps_this_iter": 0, "agent_timesteps_total": 23760, "timers": {"sample_time_ms": 109.392, "sample_throughput": 548.486, "load_time_ms": 0.189, "load_throughput": 316750.459, "learn_time_ms": 12.797, "learn_throughput": 4688.774, "update_time_ms": 0.934}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.346839692639297e-41, "cur_lr": 0.0005, "total_loss": 7904793.5, "policy_loss": -0.00044175784051869726, "vf_loss": 7904793.5, "vf_explained_var": -3.874301910400391e-06, "kl": 0.0004308032337343448, "entropy": 1.6704269647598267, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7920, "num_agent_steps_sampled": 23760, "num_steps_trained": 7920, "num_agent_steps_trained": 23760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 79, "training_iteration": 132, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.09689188003540039, "time_total_s": 14.992337465286255, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.992337465286255, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 14.2, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.179852427779951, "mean_inference_ms": 0.7502900750519077, "mean_action_processing_ms": 0.04748263133243097, "mean_env_wait_ms": 0.2915489941199653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7980, "timesteps_this_iter": 0, "agent_timesteps_total": 23940, "timers": {"sample_time_ms": 109.404, "sample_throughput": 548.426, "load_time_ms": 0.182, "load_throughput": 330086.884, "learn_time_ms": 12.754, "learn_throughput": 4704.543, "update_time_ms": 0.932}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.6734198463196487e-41, "cur_lr": 0.0005, "total_loss": 10492222.5, "policy_loss": -0.000495194053899084, "vf_loss": 10492223.0, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00037322933549077675, "entropy": 1.6499078869819641, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7980, "num_agent_steps_sampled": 23940, "num_steps_trained": 7980, "num_agent_steps_trained": 23940, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 79, "training_iteration": 133, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.09597969055175781, "time_total_s": 15.088317155838013, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.088317155838013, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17981149150708514, "mean_inference_ms": 0.7502873687020165, "mean_action_processing_ms": 0.04747724973778329, "mean_env_wait_ms": 0.29155669967610176, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8040, "timesteps_this_iter": 0, "agent_timesteps_total": 24120, "timers": {"sample_time_ms": 109.622, "sample_throughput": 547.336, "load_time_ms": 0.182, "load_throughput": 329654.493, "learn_time_ms": 12.635, "learn_throughput": 4748.896, "update_time_ms": 0.945}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8367099231598243e-41, "cur_lr": 0.0005, "total_loss": 2083456.0625, "policy_loss": 0.00033190911959135594, "vf_loss": 2083456.0, "vf_explained_var": -6.079673767089844e-06, "kl": 0.0001505346091192905, "entropy": 1.6325875520706177, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8040, "num_agent_steps_sampled": 24120, "num_steps_trained": 8040, "num_agent_steps_trained": 24120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 80, "training_iteration": 134, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.09533095359802246, "time_total_s": 15.183648109436035, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.183648109436035, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1797705511213968, "mean_inference_ms": 0.7502861515918668, "mean_action_processing_ms": 0.047472189942192745, "mean_env_wait_ms": 0.29156448281327557, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8100, "timesteps_this_iter": 0, "agent_timesteps_total": 24300, "timers": {"sample_time_ms": 109.273, "sample_throughput": 549.083, "load_time_ms": 0.172, "load_throughput": 347930.651, "learn_time_ms": 12.673, "learn_throughput": 4734.423, "update_time_ms": 0.932}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.183549615799122e-42, "cur_lr": 0.0005, "total_loss": 18903127.0, "policy_loss": -0.001026294331271771, "vf_loss": 18903128.0, "vf_explained_var": 6.556510925292969e-07, "kl": 0.0001096541958268693, "entropy": 1.637526273727417, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8100, "num_agent_steps_sampled": 24300, "num_steps_trained": 8100, "num_agent_steps_trained": 24300, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 81, "training_iteration": 135, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.0945122241973877, "time_total_s": 15.278160333633423, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.278160333633423, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1797705511213968, "mean_inference_ms": 0.7502861515918668, "mean_action_processing_ms": 0.047472189942192745, "mean_env_wait_ms": 0.29156448281327557, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8160, "timesteps_this_iter": 0, "agent_timesteps_total": 24480, "timers": {"sample_time_ms": 109.01, "sample_throughput": 550.407, "load_time_ms": 0.173, "load_throughput": 347210.596, "learn_time_ms": 12.466, "learn_throughput": 4813.266, "update_time_ms": 0.928}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.591774807899561e-42, "cur_lr": 0.0005, "total_loss": 4475049.5, "policy_loss": -0.0008226579844219373, "vf_loss": 4475049.25, "vf_explained_var": -2.9206275939941406e-06, "kl": 0.00022255322645226006, "entropy": 1.6600964069366455, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8160, "num_agent_steps_sampled": 24480, "num_steps_trained": 8160, "num_agent_steps_trained": 24480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 81, "training_iteration": 136, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.09046411514282227, "time_total_s": 15.368624448776245, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.368624448776245, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17973174103331038, "mean_inference_ms": 0.7502857194788108, "mean_action_processing_ms": 0.04746732188538004, "mean_env_wait_ms": 0.2915712907522484, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8220, "timesteps_this_iter": 0, "agent_timesteps_total": 24660, "timers": {"sample_time_ms": 109.208, "sample_throughput": 549.413, "load_time_ms": 0.162, "load_throughput": 370303.473, "learn_time_ms": 12.573, "learn_throughput": 4772.301, "update_time_ms": 0.882}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2958874039497804e-42, "cur_lr": 0.0005, "total_loss": 7899710.25, "policy_loss": -0.0032507856221251075, "vf_loss": 7899710.5, "vf_explained_var": -6.020069122314453e-06, "kl": 0.0004000764625313735, "entropy": 1.6879935264587402, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8220, "num_agent_steps_sampled": 24660, "num_steps_trained": 8220, "num_agent_steps_trained": 24660, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 82, "training_iteration": 137, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.10005640983581543, "time_total_s": 15.46868085861206, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f30d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.46868085861206, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17973174103331038, "mean_inference_ms": 0.7502857194788108, "mean_action_processing_ms": 0.04746732188538004, "mean_env_wait_ms": 0.2915712907522484, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8280, "timesteps_this_iter": 0, "agent_timesteps_total": 24840, "timers": {"sample_time_ms": 108.941, "sample_throughput": 550.757, "load_time_ms": 0.163, "load_throughput": 368460.088, "learn_time_ms": 12.455, "learn_throughput": 4817.182, "update_time_ms": 0.872}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1479437019748902e-42, "cur_lr": 0.0005, "total_loss": 10489968.5, "policy_loss": -0.0045685202504230915, "vf_loss": 10489968.5, "vf_explained_var": 1.5497207641601562e-06, "kl": 0.0007629865826164206, "entropy": 1.7170062065124512, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8280, "num_agent_steps_sampled": 24840, "num_steps_trained": 8280, "num_agent_steps_trained": 24840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 82, "training_iteration": 138, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.09206032752990723, "time_total_s": 15.560741186141968, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.560741186141968, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 13.6, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17969341508294048, "mean_inference_ms": 0.7502836941331926, "mean_action_processing_ms": 0.047462468290514225, "mean_env_wait_ms": 0.2915762756791799, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8340, "timesteps_this_iter": 0, "agent_timesteps_total": 25020, "timers": {"sample_time_ms": 107.887, "sample_throughput": 556.136, "load_time_ms": 0.159, "load_throughput": 376903.16, "learn_time_ms": 12.39, "learn_throughput": 4842.552, "update_time_ms": 0.883}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.739718509874451e-43, "cur_lr": 0.0005, "total_loss": 2081655.5625, "policy_loss": 0.0016459207231589446, "vf_loss": 2081655.5625, "vf_explained_var": 4.76837158203125e-06, "kl": 0.0006205611274623379, "entropy": 1.7445178031921387, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8340, "num_agent_steps_sampled": 25020, "num_steps_trained": 8340, "num_agent_steps_trained": 25020, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 83, "training_iteration": 139, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-48", "timestamp": 1742303388, "time_this_iter_s": 0.09493255615234375, "time_total_s": 15.655673742294312, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.655673742294312, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17965497341664424, "mean_inference_ms": 0.7502798198623056, "mean_action_processing_ms": 0.04745765182024069, "mean_env_wait_ms": 0.29158112825413174, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8400, "timesteps_this_iter": 0, "agent_timesteps_total": 25200, "timers": {"sample_time_ms": 108.044, "sample_throughput": 555.327, "load_time_ms": 0.178, "load_throughput": 337117.535, "learn_time_ms": 12.492, "learn_throughput": 4802.913, "update_time_ms": 0.875}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.8698592549372255e-43, "cur_lr": 0.0005, "total_loss": 18893380.0, "policy_loss": 0.0008573446202921886, "vf_loss": 18893380.0, "vf_explained_var": 1.2516975402832031e-06, "kl": 0.00023382961366080757, "entropy": 1.757910430431366, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8400, "num_agent_steps_sampled": 25200, "num_steps_trained": 8400, "num_agent_steps_trained": 25200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 84, "training_iteration": 140, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09324836730957031, "time_total_s": 15.748922109603882, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.748922109603882, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17965497341664424, "mean_inference_ms": 0.7502798198623056, "mean_action_processing_ms": 0.04745765182024069, "mean_env_wait_ms": 0.29158112825413174, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8460, "timesteps_this_iter": 0, "agent_timesteps_total": 25380, "timers": {"sample_time_ms": 108.814, "sample_throughput": 551.4, "load_time_ms": 0.18, "load_throughput": 334251.879, "learn_time_ms": 12.392, "learn_throughput": 4841.667, "update_time_ms": 0.879}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4349296274686128e-43, "cur_lr": 0.0005, "total_loss": 4473717.0, "policy_loss": 0.0002740071989437709, "vf_loss": 4473717.0, "vf_explained_var": -1.1444091796875e-05, "kl": 6.161685922367877e-05, "entropy": 1.761804461479187, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8460, "num_agent_steps_sampled": 25380, "num_steps_trained": 8460, "num_agent_steps_trained": 25380, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 84, "training_iteration": 141, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09239315986633301, "time_total_s": 15.841315269470215, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.841315269470215, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17961715336538073, "mean_inference_ms": 0.7502778402012104, "mean_action_processing_ms": 0.047453321963422654, "mean_env_wait_ms": 0.29158770303376585, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8520, "timesteps_this_iter": 0, "agent_timesteps_total": 25560, "timers": {"sample_time_ms": 109.104, "sample_throughput": 549.932, "load_time_ms": 0.187, "load_throughput": 320379.682, "learn_time_ms": 12.468, "learn_throughput": 4812.456, "update_time_ms": 0.858}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.174648137343064e-44, "cur_lr": 0.0005, "total_loss": 7894605.5, "policy_loss": -0.0024279038163106392, "vf_loss": 7894605.25, "vf_explained_var": -2.9206275939941406e-06, "kl": 0.000135848199743549, "entropy": 1.7565671801567078, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8520, "num_agent_steps_sampled": 25560, "num_steps_trained": 8520, "num_agent_steps_trained": 25560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 85, "training_iteration": 142, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09926581382751465, "time_total_s": 15.94058108329773, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.94058108329773, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17961715336538073, "mean_inference_ms": 0.7502778402012104, "mean_action_processing_ms": 0.047453321963422654, "mean_env_wait_ms": 0.29158770303376585, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8580, "timesteps_this_iter": 0, "agent_timesteps_total": 25740, "timers": {"sample_time_ms": 109.157, "sample_throughput": 549.667, "load_time_ms": 0.198, "load_throughput": 303605.067, "learn_time_ms": 12.45, "learn_throughput": 4819.359, "update_time_ms": 0.874}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.587324068671532e-44, "cur_lr": 0.0005, "total_loss": 10487640.5, "policy_loss": -0.0005145380790878562, "vf_loss": 10487640.5, "vf_explained_var": -7.927417755126953e-06, "kl": 0.00017329783471176086, "entropy": 1.7435792684555054, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8580, "num_agent_steps_sampled": 25740, "num_steps_trained": 8580, "num_agent_steps_trained": 25740, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 85, "training_iteration": 143, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09418106079101562, "time_total_s": 16.034762144088745, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.034762144088745, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17957927015116842, "mean_inference_ms": 0.7502755496518034, "mean_action_processing_ms": 0.04744909858273969, "mean_env_wait_ms": 0.2915948955920742, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8640, "timesteps_this_iter": 0, "agent_timesteps_total": 25920, "timers": {"sample_time_ms": 108.993, "sample_throughput": 550.494, "load_time_ms": 0.205, "load_throughput": 293239.618, "learn_time_ms": 12.508, "learn_throughput": 4796.816, "update_time_ms": 0.85}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.793662034335766e-44, "cur_lr": 0.0005, "total_loss": 2079787.1875, "policy_loss": 3.43064475210042e-05, "vf_loss": 2079787.4375, "vf_explained_var": -1.2516975402832031e-06, "kl": 0.0001624580293402289, "entropy": 1.7241807579994202, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8640, "num_agent_steps_sampled": 25920, "num_steps_trained": 8640, "num_agent_steps_trained": 25920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 86, "training_iteration": 144, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09431958198547363, "time_total_s": 16.12908172607422, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.12908172607422, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17954167821681863, "mean_inference_ms": 0.7502758707781378, "mean_action_processing_ms": 0.04744496264900384, "mean_env_wait_ms": 0.29160209536494713, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8700, "timesteps_this_iter": 0, "agent_timesteps_total": 26100, "timers": {"sample_time_ms": 109.254, "sample_throughput": 549.178, "load_time_ms": 0.204, "load_throughput": 294233.883, "learn_time_ms": 12.548, "learn_throughput": 4781.623, "update_time_ms": 0.868}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.96831017167883e-45, "cur_lr": 0.0005, "total_loss": 18883546.0, "policy_loss": -0.0006086988788496228, "vf_loss": 18883545.0, "vf_explained_var": 6.854534149169922e-07, "kl": 0.00014681366425151055, "entropy": 1.7072607278823853, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8700, "num_agent_steps_sampled": 26100, "num_steps_trained": 8700, "num_agent_steps_trained": 26100, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 87, "training_iteration": 145, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09636259078979492, "time_total_s": 16.225444316864014, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.225444316864014, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 13.6, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17954167821681863, "mean_inference_ms": 0.7502758707781378, "mean_action_processing_ms": 0.04744496264900384, "mean_env_wait_ms": 0.29160209536494713, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8760, "timesteps_this_iter": 0, "agent_timesteps_total": 26280, "timers": {"sample_time_ms": 109.741, "sample_throughput": 546.743, "load_time_ms": 0.205, "load_throughput": 292966.519, "learn_time_ms": 12.602, "learn_throughput": 4760.98, "update_time_ms": 0.877}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.484155085839415e-45, "cur_lr": 0.0005, "total_loss": 4472341.0, "policy_loss": -0.0009922097281869213, "vf_loss": 4472341.25, "vf_explained_var": -9.953975677490234e-06, "kl": 0.00012861893851057182, "entropy": 1.6951713562011719, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8760, "num_agent_steps_sampled": 26280, "num_steps_trained": 8760, "num_agent_steps_trained": 26280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 87, "training_iteration": 146, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09226226806640625, "time_total_s": 16.31770658493042, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.31770658493042, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17950469704686356, "mean_inference_ms": 0.7502750459958338, "mean_action_processing_ms": 0.047440738023445214, "mean_env_wait_ms": 0.29160847029565695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8820, "timesteps_this_iter": 0, "agent_timesteps_total": 26460, "timers": {"sample_time_ms": 109.457, "sample_throughput": 548.161, "load_time_ms": 0.205, "load_throughput": 292864.238, "learn_time_ms": 12.546, "learn_throughput": 4782.431, "update_time_ms": 0.887}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2420775429197074e-45, "cur_lr": 0.0005, "total_loss": 7889486.0, "policy_loss": -0.001468055066652596, "vf_loss": 7889486.25, "vf_explained_var": 4.976987838745117e-06, "kl": 0.00015850519597404578, "entropy": 1.6808956265449524, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8820, "num_agent_steps_sampled": 26460, "num_steps_trained": 8820, "num_agent_steps_trained": 26460, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 88, "training_iteration": 147, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09480476379394531, "time_total_s": 16.412511348724365, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a79d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.412511348724365, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17950469704686356, "mean_inference_ms": 0.7502750459958338, "mean_action_processing_ms": 0.047440738023445214, "mean_env_wait_ms": 0.29160847029565695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8880, "timesteps_this_iter": 0, "agent_timesteps_total": 26640, "timers": {"sample_time_ms": 109.493, "sample_throughput": 547.979, "load_time_ms": 0.206, "load_throughput": 290900.751, "learn_time_ms": 12.721, "learn_throughput": 4716.526, "update_time_ms": 0.87}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1210387714598537e-45, "cur_lr": 0.0005, "total_loss": 10485343.0, "policy_loss": 0.0004090511065442115, "vf_loss": 10485343.0, "vf_explained_var": 1.7881393432617188e-06, "kl": 0.0001764728043340824, "entropy": 1.6758679151535034, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8880, "num_agent_steps_sampled": 26640, "num_steps_trained": 8880, "num_agent_steps_trained": 26640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 88, "training_iteration": 148, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.09099483489990234, "time_total_s": 16.503506183624268, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f39d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.503506183624268, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17946802009453788, "mean_inference_ms": 0.7502715481001904, "mean_action_processing_ms": 0.047436626095952276, "mean_env_wait_ms": 0.29161580710124463, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8940, "timesteps_this_iter": 0, "agent_timesteps_total": 26820, "timers": {"sample_time_ms": 110.12, "sample_throughput": 544.86, "load_time_ms": 0.2, "load_throughput": 300164.885, "learn_time_ms": 12.708, "learn_throughput": 4721.33, "update_time_ms": 0.865}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.6051938572992686e-46, "cur_lr": 0.0005, "total_loss": 2078033.8125, "policy_loss": -0.0007103701186785827, "vf_loss": 2078033.625, "vf_explained_var": -7.450580596923828e-06, "kl": 0.0001230316997621328, "entropy": 1.6730273365974426, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8940, "num_agent_steps_sampled": 26820, "num_steps_trained": 8940, "num_agent_steps_trained": 26820, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 89, "training_iteration": 149, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-49", "timestamp": 1742303389, "time_this_iter_s": 0.0964517593383789, "time_total_s": 16.599957942962646, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.599957942962646, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17943159506197032, "mean_inference_ms": 0.7502671123990322, "mean_action_processing_ms": 0.0474325067280443, "mean_env_wait_ms": 0.29162363335436164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9000, "timesteps_this_iter": 0, "agent_timesteps_total": 27000, "timers": {"sample_time_ms": 110.293, "sample_throughput": 544.007, "load_time_ms": 0.181, "load_throughput": 331303.633, "learn_time_ms": 12.633, "learn_throughput": 4749.496, "update_time_ms": 0.885}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.8025969286496343e-46, "cur_lr": 0.0005, "total_loss": 18873823.0, "policy_loss": -0.0005674328810201246, "vf_loss": 18873824.0, "vf_explained_var": -1.6689300537109375e-06, "kl": 0.0001468696023856353, "entropy": 1.66689133644104, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9000, "num_agent_steps_sampled": 27000, "num_steps_trained": 9000, "num_agent_steps_trained": 27000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14379635448258782, "mean_inference_ms": 0.7608372225279967, "mean_action_processing_ms": 0.04597863766480509, "mean_env_wait_ms": 0.28730590754213114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 90, "training_iteration": 150, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-51", "timestamp": 1742303391, "time_this_iter_s": 1.3633313179016113, "time_total_s": 17.963289260864258, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ac10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17.963289260864258, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 13.2, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17943159506197032, "mean_inference_ms": 0.7502671123990322, "mean_action_processing_ms": 0.0474325067280443, "mean_env_wait_ms": 0.29162363335436164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9060, "timesteps_this_iter": 0, "agent_timesteps_total": 27180, "timers": {"sample_time_ms": 236.778, "sample_throughput": 253.402, "load_time_ms": 0.189, "load_throughput": 317750.303, "learn_time_ms": 12.61, "learn_throughput": 4757.964, "update_time_ms": 0.884}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4012984643248171e-46, "cur_lr": 0.0005, "total_loss": 4470664.75, "policy_loss": -0.0001704368358730335, "vf_loss": 4470664.5, "vf_explained_var": 1.341104507446289e-05, "kl": 0.00014772654062822355, "entropy": 1.6607529520988464, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9060, "num_agent_steps_sampled": 27180, "num_steps_trained": 9060, "num_agent_steps_trained": 27180, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 90, "training_iteration": 151, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-51", "timestamp": 1742303391, "time_this_iter_s": 0.09137988090515137, "time_total_s": 18.05466914176941, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.05466914176941, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1793954620902015, "mean_inference_ms": 0.7502611198975958, "mean_action_processing_ms": 0.04742834977338786, "mean_env_wait_ms": 0.2916302283598546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9120, "timesteps_this_iter": 0, "agent_timesteps_total": 27360, "timers": {"sample_time_ms": 236.136, "sample_throughput": 254.091, "load_time_ms": 0.191, "load_throughput": 313710.097, "learn_time_ms": 12.563, "learn_throughput": 4775.978, "update_time_ms": 0.897}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.006492321624086e-47, "cur_lr": 0.0005, "total_loss": 7884445.25, "policy_loss": -0.000968933792321991, "vf_loss": 7884445.5, "vf_explained_var": -4.827976226806641e-06, "kl": 0.00016576815755797725, "entropy": 1.6607939004898071, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9120, "num_agent_steps_sampled": 27360, "num_steps_trained": 9120, "num_agent_steps_trained": 27360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 91, "training_iteration": 152, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-51", "timestamp": 1742303391, "time_this_iter_s": 0.09509539604187012, "time_total_s": 18.14976453781128, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.14976453781128, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 12.6, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1793954620902015, "mean_inference_ms": 0.7502611198975958, "mean_action_processing_ms": 0.04742834977338786, "mean_env_wait_ms": 0.2916302283598546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9180, "timesteps_this_iter": 0, "agent_timesteps_total": 27540, "timers": {"sample_time_ms": 235.856, "sample_throughput": 254.393, "load_time_ms": 0.189, "load_throughput": 317790.428, "learn_time_ms": 12.569, "learn_throughput": 4773.478, "update_time_ms": 0.876}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.503246160812043e-47, "cur_lr": 0.0005, "total_loss": 10483075.0, "policy_loss": -0.0031867758215717856, "vf_loss": 10483075.0, "vf_explained_var": 4.649162292480469e-06, "kl": 0.00041410337310643364, "entropy": 1.6494090557098389, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9180, "num_agent_steps_sampled": 27540, "num_steps_trained": 9180, "num_agent_steps_trained": 27540, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 91, "training_iteration": 153, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-51", "timestamp": 1742303391, "time_this_iter_s": 0.0925452709197998, "time_total_s": 18.24230980873108, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.24230980873108, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1793588602503366, "mean_inference_ms": 0.750253353696101, "mean_action_processing_ms": 0.047424079824787205, "mean_env_wait_ms": 0.29163507448901826, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9240, "timesteps_this_iter": 0, "agent_timesteps_total": 27720, "timers": {"sample_time_ms": 235.904, "sample_throughput": 254.341, "load_time_ms": 0.192, "load_throughput": 312618.932, "learn_time_ms": 12.721, "learn_throughput": 4716.552, "update_time_ms": 0.888}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7516230804060214e-47, "cur_lr": 0.0005, "total_loss": 2076145.5, "policy_loss": 0.002321416077514016, "vf_loss": 2076145.3125, "vf_explained_var": 2.4437904357910156e-06, "kl": 0.00022065133283000193, "entropy": 1.6290332078933716, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9240, "num_agent_steps_sampled": 27720, "num_steps_trained": 9240, "num_agent_steps_trained": 27720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 92, "training_iteration": 154, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-51", "timestamp": 1742303391, "time_this_iter_s": 0.09401106834411621, "time_total_s": 18.336320877075195, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.336320877075195, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17932373795303694, "mean_inference_ms": 0.7502541831334437, "mean_action_processing_ms": 0.047420403109692436, "mean_env_wait_ms": 0.29164415693520895, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9300, "timesteps_this_iter": 0, "agent_timesteps_total": 27900, "timers": {"sample_time_ms": 236.952, "sample_throughput": 253.216, "load_time_ms": 0.203, "load_throughput": 296242.778, "learn_time_ms": 12.81, "learn_throughput": 4683.661, "update_time_ms": 0.881}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.758115402030107e-48, "cur_lr": 0.0005, "total_loss": 18864106.0, "policy_loss": -0.0010663939432964398, "vf_loss": 18864106.0, "vf_explained_var": -5.245208740234375e-06, "kl": 4.683395760352038e-05, "entropy": 1.62458997964859, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9300, "num_agent_steps_sampled": 27900, "num_steps_trained": 9300, "num_agent_steps_trained": 27900, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 93, "training_iteration": 155, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-51", "timestamp": 1742303391, "time_this_iter_s": 0.10793924331665039, "time_total_s": 18.444260120391846, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.444260120391846, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17932373795303694, "mean_inference_ms": 0.7502541831334437, "mean_action_processing_ms": 0.047420403109692436, "mean_env_wait_ms": 0.29164415693520895, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9360, "timesteps_this_iter": 0, "agent_timesteps_total": 28080, "timers": {"sample_time_ms": 237.134, "sample_throughput": 253.022, "load_time_ms": 0.201, "load_throughput": 298385.392, "learn_time_ms": 12.886, "learn_throughput": 4656.233, "update_time_ms": 0.914}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.3790577010150536e-48, "cur_lr": 0.0005, "total_loss": 4469354.25, "policy_loss": -0.0004469285395725109, "vf_loss": 4469354.25, "vf_explained_var": 6.258487701416016e-06, "kl": 0.00012491226854643989, "entropy": 1.6255099177360535, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9360, "num_agent_steps_sampled": 28080, "num_steps_trained": 9360, "num_agent_steps_trained": 28080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 93, "training_iteration": 156, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.09569859504699707, "time_total_s": 18.539958715438843, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.539958715438843, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17929164778301307, "mean_inference_ms": 0.750253515074157, "mean_action_processing_ms": 0.047416761487456764, "mean_env_wait_ms": 0.29165074537566243, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9420, "timesteps_this_iter": 0, "agent_timesteps_total": 28260, "timers": {"sample_time_ms": 237.158, "sample_throughput": 252.996, "load_time_ms": 0.213, "load_throughput": 282317.972, "learn_time_ms": 12.916, "learn_throughput": 4645.515, "update_time_ms": 0.905}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.1895288505075268e-48, "cur_lr": 0.0005, "total_loss": 7879339.0, "policy_loss": -0.0004149966711541886, "vf_loss": 7879338.25, "vf_explained_var": 3.3974647521972656e-06, "kl": 0.0001324285844432893, "entropy": 1.6314259767532349, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9420, "num_agent_steps_sampled": 28260, "num_steps_trained": 9420, "num_agent_steps_trained": 28260, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 94, "training_iteration": 157, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.09439682960510254, "time_total_s": 18.634355545043945, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f31f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.634355545043945, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17929164778301307, "mean_inference_ms": 0.750253515074157, "mean_action_processing_ms": 0.047416761487456764, "mean_env_wait_ms": 0.29165074537566243, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9480, "timesteps_this_iter": 0, "agent_timesteps_total": 28440, "timers": {"sample_time_ms": 238.041, "sample_throughput": 252.057, "load_time_ms": 0.221, "load_throughput": 271886.603, "learn_time_ms": 13.116, "learn_throughput": 4574.64, "update_time_ms": 0.9}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0947644252537634e-48, "cur_lr": 0.0005, "total_loss": 10481024.5, "policy_loss": -0.0006837477196128816, "vf_loss": 10481024.5, "vf_explained_var": -5.9604644775390625e-06, "kl": 0.00012196773833850205, "entropy": 1.640630304813385, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9480, "num_agent_steps_sampled": 28440, "num_steps_trained": 9480, "num_agent_steps_trained": 28440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 94, "training_iteration": 158, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.1011343002319336, "time_total_s": 18.73548984527588, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.73548984527588, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 16.6, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17926155251438758, "mean_inference_ms": 0.7502541600553828, "mean_action_processing_ms": 0.047413603407534144, "mean_env_wait_ms": 0.2916578587576901, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9540, "timesteps_this_iter": 0, "agent_timesteps_total": 28620, "timers": {"sample_time_ms": 237.923, "sample_throughput": 252.183, "load_time_ms": 0.231, "load_throughput": 259602.063, "learn_time_ms": 13.255, "learn_throughput": 4526.748, "update_time_ms": 0.897}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.473822126268817e-49, "cur_lr": 0.0005, "total_loss": 2074399.3125, "policy_loss": -0.0006123953615322364, "vf_loss": 2074399.3125, "vf_explained_var": 1.5407800674438477e-05, "kl": 0.00013531118234944017, "entropy": 1.6485415697097778, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9540, "num_agent_steps_sampled": 28620, "num_steps_trained": 9540, "num_agent_steps_trained": 28620, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 95, "training_iteration": 159, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.09535741806030273, "time_total_s": 18.83084726333618, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.83084726333618, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17923139778356859, "mean_inference_ms": 0.750254183224901, "mean_action_processing_ms": 0.04741047922211054, "mean_env_wait_ms": 0.29166390452024066, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9600, "timesteps_this_iter": 0, "agent_timesteps_total": 28800, "timers": {"sample_time_ms": 237.815, "sample_throughput": 252.297, "load_time_ms": 0.231, "load_throughput": 259281.104, "learn_time_ms": 13.406, "learn_throughput": 4475.715, "update_time_ms": 0.876}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.7369110631344085e-49, "cur_lr": 0.0005, "total_loss": 18854317.0, "policy_loss": -0.0036177949514240026, "vf_loss": 18854317.0, "vf_explained_var": 2.86102294921875e-06, "kl": 0.0002801168453832048, "entropy": 1.6641218066215515, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9600, "num_agent_steps_sampled": 28800, "num_steps_trained": 9600, "num_agent_steps_trained": 28800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 96, "training_iteration": 160, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.09267020225524902, "time_total_s": 18.92351746559143, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.92351746559143, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17923139778356859, "mean_inference_ms": 0.750254183224901, "mean_action_processing_ms": 0.04741047922211054, "mean_env_wait_ms": 0.29166390452024066, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9660, "timesteps_this_iter": 0, "agent_timesteps_total": 28980, "timers": {"sample_time_ms": 111.352, "sample_throughput": 538.834, "load_time_ms": 0.233, "load_throughput": 257872.979, "learn_time_ms": 13.558, "learn_throughput": 4425.453, "update_time_ms": 0.878}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3684555315672042e-49, "cur_lr": 0.0005, "total_loss": 4467809.0, "policy_loss": 0.0012847112698679553, "vf_loss": 4467809.25, "vf_explained_var": -5.543231964111328e-06, "kl": 0.00023833729181532703, "entropy": 1.6782728433609009, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9660, "num_agent_steps_sampled": 28980, "num_steps_trained": 9660, "num_agent_steps_trained": 28980, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 96, "training_iteration": 161, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.0950155258178711, "time_total_s": 19.0185329914093, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.0185329914093, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17920127433535, "mean_inference_ms": 0.7502543044251793, "mean_action_processing_ms": 0.04740727378977951, "mean_env_wait_ms": 0.2916692831885523, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9720, "timesteps_this_iter": 0, "agent_timesteps_total": 29160, "timers": {"sample_time_ms": 111.747, "sample_throughput": 536.925, "load_time_ms": 0.225, "load_throughput": 267068.067, "learn_time_ms": 13.546, "learn_throughput": 4429.269, "update_time_ms": 0.865}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.842277657836021e-50, "cur_lr": 0.0005, "total_loss": 7874275.0, "policy_loss": -0.001696064742283454, "vf_loss": 7874275.25, "vf_explained_var": 3.993511199951172e-06, "kl": 0.00018184039121926787, "entropy": 1.6829426884651184, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9720, "num_agent_steps_sampled": 29160, "num_steps_trained": 9720, "num_agent_steps_trained": 29160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 97, "training_iteration": 162, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.09369707107543945, "time_total_s": 19.11223006248474, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.11223006248474, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17920127433535, "mean_inference_ms": 0.7502543044251793, "mean_action_processing_ms": 0.04740727378977951, "mean_env_wait_ms": 0.2916692831885523, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9780, "timesteps_this_iter": 0, "agent_timesteps_total": 29340, "timers": {"sample_time_ms": 113.831, "sample_throughput": 527.096, "load_time_ms": 0.217, "load_throughput": 276243.952, "learn_time_ms": 13.45, "learn_throughput": 4460.879, "update_time_ms": 0.879}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4211388289180106e-50, "cur_lr": 0.0005, "total_loss": 10478691.5, "policy_loss": 0.00029848947500177303, "vf_loss": 10478691.5, "vf_explained_var": -8.344650268554688e-07, "kl": 0.00017883213694802613, "entropy": 1.6854177117347717, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9780, "num_agent_steps_sampled": 29340, "num_steps_trained": 9780, "num_agent_steps_trained": 29340, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 97, "training_iteration": 163, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.10819578170776367, "time_total_s": 19.220425844192505, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.220425844192505, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.179173985780778, "mean_inference_ms": 0.7502623357095686, "mean_action_processing_ms": 0.04740461757888598, "mean_env_wait_ms": 0.2916791928459738, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9840, "timesteps_this_iter": 0, "agent_timesteps_total": 29520, "timers": {"sample_time_ms": 114.159, "sample_throughput": 525.583, "load_time_ms": 0.208, "load_throughput": 289062.991, "learn_time_ms": 13.287, "learn_throughput": 4515.653, "update_time_ms": 0.875}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7105694144590053e-50, "cur_lr": 0.0005, "total_loss": 2072601.5, "policy_loss": -0.0017439252567577057, "vf_loss": 2072601.6875, "vf_explained_var": -1.704692840576172e-05, "kl": 0.00018096619311369633, "entropy": 1.6869856119155884, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9840, "num_agent_steps_sampled": 29520, "num_steps_trained": 9840, "num_agent_steps_trained": 29520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 98, "training_iteration": 164, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-52", "timestamp": 1742303392, "time_this_iter_s": 0.09527349472045898, "time_total_s": 19.315699338912964, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.315699338912964, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17914717761370885, "mean_inference_ms": 0.7502707014923494, "mean_action_processing_ms": 0.04740196226575928, "mean_env_wait_ms": 0.29169019914531047, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9900, "timesteps_this_iter": 0, "agent_timesteps_total": 29700, "timers": {"sample_time_ms": 113.007, "sample_throughput": 530.94, "load_time_ms": 0.197, "load_throughput": 303898.37, "learn_time_ms": 13.154, "learn_throughput": 4561.232, "update_time_ms": 0.88}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.552847072295027e-51, "cur_lr": 0.0005, "total_loss": 18844645.0, "policy_loss": -0.00020394093751718856, "vf_loss": 18844645.0, "vf_explained_var": -3.4570693969726562e-06, "kl": 0.00019646061470268705, "entropy": 1.6692184805870056, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9900, "num_agent_steps_sampled": 29700, "num_steps_trained": 9900, "num_agent_steps_trained": 29700, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 99, "training_iteration": 165, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09604835510253906, "time_total_s": 19.411747694015503, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277961f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.411747694015503, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 18.0, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17914717761370885, "mean_inference_ms": 0.7502707014923494, "mean_action_processing_ms": 0.04740196226575928, "mean_env_wait_ms": 0.29169019914531047, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9960, "timesteps_this_iter": 0, "agent_timesteps_total": 29880, "timers": {"sample_time_ms": 113.104, "sample_throughput": 530.486, "load_time_ms": 0.198, "load_throughput": 302983.674, "learn_time_ms": 12.997, "learn_throughput": 4616.515, "update_time_ms": 0.845}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.276423536147513e-51, "cur_lr": 0.0005, "total_loss": 4466424.5, "policy_loss": 3.1056337157053804e-05, "vf_loss": 4466424.5, "vf_explained_var": -2.9802322387695312e-06, "kl": 9.872171802427498e-05, "entropy": 1.653601050376892, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9960, "num_agent_steps_sampled": 29880, "num_steps_trained": 9960, "num_agent_steps_trained": 29880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 99, "training_iteration": 166, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09695029258728027, "time_total_s": 19.508697986602783, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771adc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.508697986602783, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17912192142549266, "mean_inference_ms": 0.7502781119122246, "mean_action_processing_ms": 0.04739944351719078, "mean_env_wait_ms": 0.29170175965677114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10020, "timesteps_this_iter": 0, "agent_timesteps_total": 30060, "timers": {"sample_time_ms": 112.954, "sample_throughput": 531.189, "load_time_ms": 0.187, "load_throughput": 321649.08, "learn_time_ms": 12.944, "learn_throughput": 4635.512, "update_time_ms": 0.843}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.1382117680737566e-51, "cur_lr": 0.0005, "total_loss": 7869219.25, "policy_loss": -0.0023003869586522008, "vf_loss": 7869218.75, "vf_explained_var": -8.940696716308594e-07, "kl": 0.0001511265999170064, "entropy": 1.6385973691940308, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10020, "num_agent_steps_sampled": 30060, "num_steps_trained": 10020, "num_agent_steps_trained": 30060, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 100, "training_iteration": 167, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09331583976745605, "time_total_s": 19.60201382637024, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.60201382637024, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17912192142549266, "mean_inference_ms": 0.7502781119122246, "mean_action_processing_ms": 0.04739944351719078, "mean_env_wait_ms": 0.29170175965677114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10080, "timesteps_this_iter": 0, "agent_timesteps_total": 30240, "timers": {"sample_time_ms": 112.051, "sample_throughput": 535.468, "load_time_ms": 0.186, "load_throughput": 323052.94, "learn_time_ms": 12.675, "learn_throughput": 4733.595, "update_time_ms": 0.845}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0691058840368783e-51, "cur_lr": 0.0005, "total_loss": 10476417.5, "policy_loss": 0.0013058037031434822, "vf_loss": 10476418.5, "vf_explained_var": 8.314847946166992e-06, "kl": 8.905553269578093e-05, "entropy": 1.6205515265464783, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10080, "num_agent_steps_sampled": 30240, "num_steps_trained": 10080, "num_agent_steps_trained": 30240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 100, "training_iteration": 168, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09098458290100098, "time_total_s": 19.69299840927124, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f34c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.69299840927124, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17850826126143338, "mean_inference_ms": 0.7501207605502764, "mean_action_processing_ms": 0.0473742222247471, "mean_env_wait_ms": 0.29174514929827133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10140, "timesteps_this_iter": 0, "agent_timesteps_total": 30420, "timers": {"sample_time_ms": 112.012, "sample_throughput": 535.657, "load_time_ms": 0.175, "load_throughput": 343373.23, "learn_time_ms": 12.518, "learn_throughput": 4793.207, "update_time_ms": 0.841}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.3455294201843916e-52, "cur_lr": 0.0005, "total_loss": 2070765.875, "policy_loss": -0.0004339304183504922, "vf_loss": 2070765.9375, "vf_explained_var": 2.5033950805664062e-06, "kl": 3.54236025650323e-05, "entropy": 1.6214726567268372, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10140, "num_agent_steps_sampled": 30420, "num_steps_trained": 10140, "num_agent_steps_trained": 30420, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 101, "training_iteration": 169, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09462141990661621, "time_total_s": 19.787619829177856, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.787619829177856, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17819806680333194, "mean_inference_ms": 0.7499505753257165, "mean_action_processing_ms": 0.04735760971749154, "mean_env_wait_ms": 0.2917700514843744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10200, "timesteps_this_iter": 0, "agent_timesteps_total": 30600, "timers": {"sample_time_ms": 112.086, "sample_throughput": 535.304, "load_time_ms": 0.175, "load_throughput": 342811.933, "learn_time_ms": 12.389, "learn_throughput": 4843.093, "update_time_ms": 0.843}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.6727647100921958e-52, "cur_lr": 0.0005, "total_loss": 18834888.0, "policy_loss": -0.001437223324965764, "vf_loss": 18834888.0, "vf_explained_var": 1.1920928955078125e-06, "kl": 0.00012671713959022668, "entropy": 1.6163740754127502, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10200, "num_agent_steps_sampled": 30600, "num_steps_trained": 10200, "num_agent_steps_trained": 30600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 102, "training_iteration": 170, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09491443634033203, "time_total_s": 19.88253426551819, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772aa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.88253426551819, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17819806680333194, "mean_inference_ms": 0.7499505753257165, "mean_action_processing_ms": 0.04735760971749154, "mean_env_wait_ms": 0.2917700514843744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10260, "timesteps_this_iter": 0, "agent_timesteps_total": 30780, "timers": {"sample_time_ms": 110.896, "sample_throughput": 541.046, "load_time_ms": 0.164, "load_throughput": 365039.513, "learn_time_ms": 12.207, "learn_throughput": 4915.325, "update_time_ms": 0.851}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3363823550460979e-52, "cur_lr": 0.0005, "total_loss": 4465026.25, "policy_loss": -0.0012799760042199182, "vf_loss": 4465026.0, "vf_explained_var": 2.3245811462402344e-06, "kl": 0.0002018241466039683, "entropy": 1.6066818833351135, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10260, "num_agent_steps_sampled": 30780, "num_steps_trained": 10260, "num_agent_steps_trained": 30780, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 102, "training_iteration": 171, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09011363983154297, "time_total_s": 19.97264790534973, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a79d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.97264790534973, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 13.5, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17797571985859148, "mean_inference_ms": 0.7498365294987225, "mean_action_processing_ms": 0.04734413535993797, "mean_env_wait_ms": 0.2918128447636687, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10320, "timesteps_this_iter": 0, "agent_timesteps_total": 30960, "timers": {"sample_time_ms": 110.507, "sample_throughput": 542.954, "load_time_ms": 0.162, "load_throughput": 369922.446, "learn_time_ms": 12.31, "learn_throughput": 4874.179, "update_time_ms": 0.845}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.6819117752304895e-53, "cur_lr": 0.0005, "total_loss": 7864176.0, "policy_loss": 0.0003784484378734909, "vf_loss": 7864176.0, "vf_explained_var": -2.086162567138672e-06, "kl": 0.00011994474209409134, "entropy": 1.596339464187622, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10320, "num_agent_steps_sampled": 30960, "num_steps_trained": 10320, "num_agent_steps_trained": 30960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 103, "training_iteration": 172, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09293842315673828, "time_total_s": 20.06558632850647, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.06558632850647, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17797571985859148, "mean_inference_ms": 0.7498365294987225, "mean_action_processing_ms": 0.04734413535993797, "mean_env_wait_ms": 0.2918128447636687, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10380, "timesteps_this_iter": 0, "agent_timesteps_total": 31140, "timers": {"sample_time_ms": 108.329, "sample_throughput": 553.867, "load_time_ms": 0.162, "load_throughput": 369922.446, "learn_time_ms": 12.281, "learn_throughput": 4885.657, "update_time_ms": 0.847}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.3409558876152447e-53, "cur_lr": 0.0005, "total_loss": 10474331.5, "policy_loss": -0.000689037953917282, "vf_loss": 10474331.5, "vf_explained_var": -2.1457672119140625e-06, "kl": 9.40062185328383e-05, "entropy": 1.600713849067688, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10380, "num_agent_steps_sampled": 31140, "num_steps_trained": 10380, "num_agent_steps_trained": 31140, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 103, "training_iteration": 173, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-53", "timestamp": 1742303393, "time_this_iter_s": 0.09136843681335449, "time_total_s": 20.156954765319824, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772aa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.156954765319824, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17781918915237893, "mean_inference_ms": 0.7497671537835459, "mean_action_processing_ms": 0.04733087438214616, "mean_env_wait_ms": 0.2918514737966413, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10440, "timesteps_this_iter": 0, "agent_timesteps_total": 31320, "timers": {"sample_time_ms": 108.335, "sample_throughput": 553.838, "load_time_ms": 0.172, "load_throughput": 347930.651, "learn_time_ms": 12.325, "learn_throughput": 4868.248, "update_time_ms": 0.845}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6704779438076224e-53, "cur_lr": 0.0005, "total_loss": 2068971.5625, "policy_loss": -0.0014877498382701582, "vf_loss": 2068971.625, "vf_explained_var": 7.808208465576172e-06, "kl": 0.00021689556588500025, "entropy": 1.5960732102394104, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10440, "num_agent_steps_sampled": 31320, "num_steps_trained": 10440, "num_agent_steps_trained": 31320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 104, "training_iteration": 174, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09824204444885254, "time_total_s": 20.255196809768677, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.255196809768677, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17769395143066063, "mean_inference_ms": 0.7497279089094401, "mean_action_processing_ms": 0.04732075433016798, "mean_env_wait_ms": 0.2919015924511207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10500, "timesteps_this_iter": 0, "agent_timesteps_total": 31500, "timers": {"sample_time_ms": 108.352, "sample_throughput": 553.75, "load_time_ms": 0.179, "load_throughput": 336126.94, "learn_time_ms": 12.316, "learn_throughput": 4871.829, "update_time_ms": 0.83}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.352389719038112e-54, "cur_lr": 0.0005, "total_loss": 18825253.0, "policy_loss": -0.0008985261070648676, "vf_loss": 18825253.0, "vf_explained_var": -1.4901161193847656e-06, "kl": 0.00035926424007470814, "entropy": 1.5836126208305359, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10500, "num_agent_steps_sampled": 31500, "num_steps_trained": 10500, "num_agent_steps_trained": 31500, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 105, "training_iteration": 175, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09541654586791992, "time_total_s": 20.350613355636597, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.350613355636597, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17769395143066063, "mean_inference_ms": 0.7497279089094401, "mean_action_processing_ms": 0.04732075433016798, "mean_env_wait_ms": 0.2919015924511207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10560, "timesteps_this_iter": 0, "agent_timesteps_total": 31680, "timers": {"sample_time_ms": 107.713, "sample_throughput": 557.037, "load_time_ms": 0.167, "load_throughput": 358487.521, "learn_time_ms": 12.425, "learn_throughput": 4828.93, "update_time_ms": 0.832}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.176194859519056e-54, "cur_lr": 0.0005, "total_loss": 4463634.0, "policy_loss": -0.00017832286410168763, "vf_loss": 4463633.75, "vf_explained_var": -9.5367431640625e-06, "kl": 0.00027748500926172426, "entropy": 1.5591732859611511, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10560, "num_agent_steps_sampled": 31680, "num_steps_trained": 10560, "num_agent_steps_trained": 31680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 105, "training_iteration": 176, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09154319763183594, "time_total_s": 20.442156553268433, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.442156553268433, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17759444309853656, "mean_inference_ms": 0.7496814893902313, "mean_action_processing_ms": 0.04731147096641916, "mean_env_wait_ms": 0.2919545557850553, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10620, "timesteps_this_iter": 0, "agent_timesteps_total": 31860, "timers": {"sample_time_ms": 107.359, "sample_throughput": 558.872, "load_time_ms": 0.175, "load_throughput": 343373.23, "learn_time_ms": 12.38, "learn_throughput": 4846.488, "update_time_ms": 0.831}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.088097429759528e-54, "cur_lr": 0.0005, "total_loss": 7859152.0, "policy_loss": -0.0006964464852998731, "vf_loss": 7859151.25, "vf_explained_var": -2.0265579223632812e-06, "kl": 0.00021974912139377523, "entropy": 1.5302265882492065, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10620, "num_agent_steps_sampled": 31860, "num_steps_trained": 10620, "num_agent_steps_trained": 31860, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 106, "training_iteration": 177, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09087419509887695, "time_total_s": 20.53303074836731, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.53303074836731, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17759444309853656, "mean_inference_ms": 0.7496814893902313, "mean_action_processing_ms": 0.04731147096641916, "mean_env_wait_ms": 0.2919545557850553, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10680, "timesteps_this_iter": 0, "agent_timesteps_total": 32040, "timers": {"sample_time_ms": 107.577, "sample_throughput": 557.741, "load_time_ms": 0.165, "load_throughput": 363143.203, "learn_time_ms": 12.355, "learn_throughput": 4856.242, "update_time_ms": 0.838}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.044048714879764e-54, "cur_lr": 0.0005, "total_loss": 10471986.5, "policy_loss": -0.004158404593667342, "vf_loss": 10471986.0, "vf_explained_var": -7.808208465576172e-06, "kl": 0.0004901125404357387, "entropy": 1.4848829507827759, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10680, "num_agent_steps_sampled": 32040, "num_steps_trained": 10680, "num_agent_steps_trained": 32040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 106, "training_iteration": 178, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09453511238098145, "time_total_s": 20.62756586074829, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.62756586074829, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 13.5, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17751278192754377, "mean_inference_ms": 0.7496520167266055, "mean_action_processing_ms": 0.047304402945656694, "mean_env_wait_ms": 0.29200320628149146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10740, "timesteps_this_iter": 0, "agent_timesteps_total": 32220, "timers": {"sample_time_ms": 107.187, "sample_throughput": 559.77, "load_time_ms": 0.166, "load_throughput": 360696.918, "learn_time_ms": 12.351, "learn_throughput": 4857.864, "update_time_ms": 0.837}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.22024357439882e-55, "cur_lr": 0.0005, "total_loss": 2067164.625, "policy_loss": -3.9182107460788984e-05, "vf_loss": 2067164.5625, "vf_explained_var": 1.7881393432617188e-07, "kl": 0.00045190837268904716, "entropy": 1.4116933941841125, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10740, "num_agent_steps_sampled": 32220, "num_steps_trained": 10740, "num_agent_steps_trained": 32220, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 107, "training_iteration": 179, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09330320358276367, "time_total_s": 20.720869064331055, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.720869064331055, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17743000591227356, "mean_inference_ms": 0.7496367373174582, "mean_action_processing_ms": 0.047295210563236705, "mean_env_wait_ms": 0.2920455436622375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10800, "timesteps_this_iter": 0, "agent_timesteps_total": 32400, "timers": {"sample_time_ms": 107.088, "sample_throughput": 560.286, "load_time_ms": 0.165, "load_throughput": 362986.067, "learn_time_ms": 12.399, "learn_throughput": 4838.939, "update_time_ms": 0.852}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.61012178719941e-55, "cur_lr": 0.0005, "total_loss": 18815569.0, "policy_loss": -0.0006326662104889635, "vf_loss": 18815569.0, "vf_explained_var": -4.172325134277344e-06, "kl": 0.00011879680760529254, "entropy": 1.3696532249450684, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10800, "num_agent_steps_sampled": 32400, "num_steps_trained": 10800, "num_agent_steps_trained": 32400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 108, "training_iteration": 180, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09193897247314453, "time_total_s": 20.8128080368042, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.8128080368042, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17743000591227356, "mean_inference_ms": 0.7496367373174582, "mean_action_processing_ms": 0.047295210563236705, "mean_env_wait_ms": 0.2920455436622375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10860, "timesteps_this_iter": 0, "agent_timesteps_total": 32580, "timers": {"sample_time_ms": 107.72, "sample_throughput": 556.998, "load_time_ms": 0.177, "load_throughput": 338432.275, "learn_time_ms": 12.476, "learn_throughput": 4809.081, "update_time_ms": 0.839}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.305060893599705e-55, "cur_lr": 0.0005, "total_loss": 4461949.5, "policy_loss": -0.0007712320967887543, "vf_loss": 4461949.5, "vf_explained_var": -9.5367431640625e-06, "kl": 0.00013579515787220942, "entropy": 1.3687856793403625, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10860, "num_agent_steps_sampled": 32580, "num_steps_trained": 10860, "num_agent_steps_trained": 32580, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 108, "training_iteration": 181, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09192681312561035, "time_total_s": 20.90473484992981, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.90473484992981, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17735647448485248, "mean_inference_ms": 0.749605919940882, "mean_action_processing_ms": 0.047286015534144486, "mean_env_wait_ms": 0.2920727440759457, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10920, "timesteps_this_iter": 0, "agent_timesteps_total": 32760, "timers": {"sample_time_ms": 107.753, "sample_throughput": 556.829, "load_time_ms": 0.187, "load_throughput": 320135.148, "learn_time_ms": 12.55, "learn_throughput": 4780.851, "update_time_ms": 0.844}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.525304467998525e-56, "cur_lr": 0.0005, "total_loss": 7854079.75, "policy_loss": -0.0005124708133124045, "vf_loss": 7854079.5, "vf_explained_var": 4.172325134277344e-07, "kl": 0.00020486779427741908, "entropy": 1.3752914667129517, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10920, "num_agent_steps_sampled": 32760, "num_steps_trained": 10920, "num_agent_steps_trained": 32760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 109, "training_iteration": 182, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-54", "timestamp": 1742303394, "time_this_iter_s": 0.09545660018920898, "time_total_s": 21.00019145011902, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f31f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.00019145011902, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17735647448485248, "mean_inference_ms": 0.749605919940882, "mean_action_processing_ms": 0.047286015534144486, "mean_env_wait_ms": 0.2920727440759457, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10980, "timesteps_this_iter": 0, "agent_timesteps_total": 32940, "timers": {"sample_time_ms": 108.267, "sample_throughput": 554.187, "load_time_ms": 0.198, "load_throughput": 303458.628, "learn_time_ms": 12.586, "learn_throughput": 4767.266, "update_time_ms": 0.84}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.2626522339992624e-56, "cur_lr": 0.0005, "total_loss": 10469746.0, "policy_loss": 0.0008966399369656486, "vf_loss": 10469746.0, "vf_explained_var": 7.450580596923828e-07, "kl": 0.00012491308190032413, "entropy": 1.3996363282203674, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10980, "num_agent_steps_sampled": 32940, "num_steps_trained": 10980, "num_agent_steps_trained": 32940, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 109, "training_iteration": 183, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09762430191040039, "time_total_s": 21.09781575202942, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.09781575202942, "timesteps_since_restore": 0, "iterations_since_restore": 183, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17728845560754677, "mean_inference_ms": 0.7495862876207817, "mean_action_processing_ms": 0.04727649363009211, "mean_env_wait_ms": 0.29210495026220107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11040, "timesteps_this_iter": 0, "agent_timesteps_total": 33120, "timers": {"sample_time_ms": 108.011, "sample_throughput": 555.497, "load_time_ms": 0.194, "load_throughput": 309124.481, "learn_time_ms": 12.619, "learn_throughput": 4754.755, "update_time_ms": 0.839}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6313261169996312e-56, "cur_lr": 0.0005, "total_loss": 2065377.1875, "policy_loss": 6.844798917882144e-05, "vf_loss": 2065377.1875, "vf_explained_var": 8.940696716308594e-07, "kl": 1.489968871393188e-05, "entropy": 1.4043920040130615, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11040, "num_agent_steps_sampled": 33120, "num_steps_trained": 11040, "num_agent_steps_trained": 33120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 110, "training_iteration": 184, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09330558776855469, "time_total_s": 21.191121339797974, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.191121339797974, "timesteps_since_restore": 0, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 13.3, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17723414905097834, "mean_inference_ms": 0.7495891163924812, "mean_action_processing_ms": 0.0472692946307327, "mean_env_wait_ms": 0.29214931021954177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11100, "timesteps_this_iter": 0, "agent_timesteps_total": 33300, "timers": {"sample_time_ms": 107.62, "sample_throughput": 557.518, "load_time_ms": 0.192, "load_throughput": 312463.67, "learn_time_ms": 12.589, "learn_throughput": 4766.209, "update_time_ms": 0.836}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.156630584998156e-57, "cur_lr": 0.0005, "total_loss": 18805850.0, "policy_loss": -0.0007908615943357233, "vf_loss": 18805850.0, "vf_explained_var": -1.0728836059570312e-06, "kl": 5.3402612028463636e-05, "entropy": 1.413490891456604, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11100, "num_agent_steps_sampled": 33300, "num_steps_trained": 11100, "num_agent_steps_trained": 33300, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 111, "training_iteration": 185, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09193658828735352, "time_total_s": 21.283057928085327, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.283057928085327, "timesteps_since_restore": 0, "iterations_since_restore": 185, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17723414905097834, "mean_inference_ms": 0.7495891163924812, "mean_action_processing_ms": 0.0472692946307327, "mean_env_wait_ms": 0.29214931021954177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11160, "timesteps_this_iter": 0, "agent_timesteps_total": 33480, "timers": {"sample_time_ms": 108.181, "sample_throughput": 554.626, "load_time_ms": 0.192, "load_throughput": 312114.895, "learn_time_ms": 12.655, "learn_throughput": 4741.068, "update_time_ms": 0.831}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.078315292499078e-57, "cur_lr": 0.0005, "total_loss": 4460642.75, "policy_loss": -0.00031326941680154263, "vf_loss": 4460643.0, "vf_explained_var": 4.827976226806641e-06, "kl": 0.00011765296843435635, "entropy": 1.4375523924827576, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11160, "num_agent_steps_sampled": 33480, "num_steps_trained": 11160, "num_agent_steps_trained": 33480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 111, "training_iteration": 186, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09217405319213867, "time_total_s": 21.375231981277466, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.375231981277466, "timesteps_since_restore": 0, "iterations_since_restore": 186, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17717789991761518, "mean_inference_ms": 0.7495965450485556, "mean_action_processing_ms": 0.047261406352107266, "mean_env_wait_ms": 0.2921868211018887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11220, "timesteps_this_iter": 0, "agent_timesteps_total": 33660, "timers": {"sample_time_ms": 108.424, "sample_throughput": 553.385, "load_time_ms": 0.186, "load_throughput": 322638.769, "learn_time_ms": 12.645, "learn_throughput": 4744.795, "update_time_ms": 0.83}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.039157646249539e-57, "cur_lr": 0.0005, "total_loss": 7849033.75, "policy_loss": -0.0015478749992325902, "vf_loss": 7849033.5, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00018521131763460374, "entropy": 1.4679223895072937, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11220, "num_agent_steps_sampled": 33660, "num_steps_trained": 11220, "num_agent_steps_trained": 33660, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 112, "training_iteration": 187, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09258508682250977, "time_total_s": 21.467817068099976, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771aca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.467817068099976, "timesteps_since_restore": 0, "iterations_since_restore": 187, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17717789991761518, "mean_inference_ms": 0.7495965450485556, "mean_action_processing_ms": 0.047261406352107266, "mean_env_wait_ms": 0.2921868211018887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11280, "timesteps_this_iter": 0, "agent_timesteps_total": 33840, "timers": {"sample_time_ms": 108.365, "sample_throughput": 553.683, "load_time_ms": 0.186, "load_throughput": 322887.144, "learn_time_ms": 12.624, "learn_throughput": 4752.681, "update_time_ms": 0.833}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0195788231247695e-57, "cur_lr": 0.0005, "total_loss": 10467608.5, "policy_loss": -0.0018697874879194387, "vf_loss": 10467608.5, "vf_explained_var": 2.980232238769531e-07, "kl": 0.00029513575721695773, "entropy": 1.5024558305740356, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11280, "num_agent_steps_sampled": 33840, "num_steps_trained": 11280, "num_agent_steps_trained": 33840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 112, "training_iteration": 188, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09342622756958008, "time_total_s": 21.561243295669556, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277961f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.561243295669556, "timesteps_since_restore": 0, "iterations_since_restore": 188, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1771275945524543, "mean_inference_ms": 0.7496112395578807, "mean_action_processing_ms": 0.04725337300531758, "mean_env_wait_ms": 0.2922222537105875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11340, "timesteps_this_iter": 0, "agent_timesteps_total": 34020, "timers": {"sample_time_ms": 108.542, "sample_throughput": 552.78, "load_time_ms": 0.187, "load_throughput": 321607.974, "learn_time_ms": 12.553, "learn_throughput": 4779.688, "update_time_ms": 0.828}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.0978941156238476e-58, "cur_lr": 0.0005, "total_loss": 2063578.1875, "policy_loss": -0.0007346703088835227, "vf_loss": 2063578.1875, "vf_explained_var": -1.043081283569336e-05, "kl": 0.0003167012146425563, "entropy": 1.5293715596199036, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11340, "num_agent_steps_sampled": 34020, "num_steps_trained": 11340, "num_agent_steps_trained": 34020, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 113, "training_iteration": 189, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09527087211608887, "time_total_s": 21.656514167785645, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.656514167785645, "timesteps_since_restore": 0, "iterations_since_restore": 189, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1770842870741375, "mean_inference_ms": 0.7496367772667394, "mean_action_processing_ms": 0.047246931783168244, "mean_env_wait_ms": 0.2922537885108953, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11400, "timesteps_this_iter": 0, "agent_timesteps_total": 34200, "timers": {"sample_time_ms": 108.71, "sample_throughput": 551.927, "load_time_ms": 0.186, "load_throughput": 321895.932, "learn_time_ms": 12.583, "learn_throughput": 4768.512, "update_time_ms": 0.819}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.5489470578119238e-58, "cur_lr": 0.0005, "total_loss": 18796154.0, "policy_loss": -0.0007326920904873191, "vf_loss": 18796155.0, "vf_explained_var": -2.7418136596679688e-06, "kl": 0.0002887702552660798, "entropy": 1.5441632866859436, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11400, "num_agent_steps_sampled": 34200, "num_steps_trained": 11400, "num_agent_steps_trained": 34200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 114, "training_iteration": 190, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09413313865661621, "time_total_s": 21.75064730644226, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.75064730644226, "timesteps_since_restore": 0, "iterations_since_restore": 190, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1770842870741375, "mean_inference_ms": 0.7496367772667394, "mean_action_processing_ms": 0.047246931783168244, "mean_env_wait_ms": 0.2922537885108953, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11460, "timesteps_this_iter": 0, "agent_timesteps_total": 34380, "timers": {"sample_time_ms": 108.235, "sample_throughput": 554.35, "load_time_ms": 0.181, "load_throughput": 332309.838, "learn_time_ms": 12.578, "learn_throughput": 4770.284, "update_time_ms": 0.829}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2744735289059619e-58, "cur_lr": 0.0005, "total_loss": 4459265.75, "policy_loss": -0.0009991086243346103, "vf_loss": 4459265.5, "vf_explained_var": -1.1682510375976562e-05, "kl": 0.0003066590357788668, "entropy": 1.5564554929733276, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11460, "num_agent_steps_sampled": 34380, "num_steps_trained": 11460, "num_agent_steps_trained": 34380, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 114, "training_iteration": 191, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09090948104858398, "time_total_s": 21.841556787490845, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a5e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.841556787490845, "timesteps_since_restore": 0, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 13.9, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1770457912267128, "mean_inference_ms": 0.7496486376300315, "mean_action_processing_ms": 0.047239964113367554, "mean_env_wait_ms": 0.29227768635305407, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11520, "timesteps_this_iter": 0, "agent_timesteps_total": 34560, "timers": {"sample_time_ms": 108.661, "sample_throughput": 552.176, "load_time_ms": 0.17, "load_throughput": 352561.278, "learn_time_ms": 12.404, "learn_throughput": 4836.958, "update_time_ms": 0.832}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.3723676445298095e-59, "cur_lr": 0.0005, "total_loss": 7843988.75, "policy_loss": 0.00041648879220357315, "vf_loss": 7843988.75, "vf_explained_var": -1.1920928955078125e-07, "kl": 0.0002600342062084593, "entropy": 1.5650608539581299, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11520, "num_agent_steps_sampled": 34560, "num_steps_trained": 11520, "num_agent_steps_trained": 34560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 115, "training_iteration": 192, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-55", "timestamp": 1742303395, "time_this_iter_s": 0.09325194358825684, "time_total_s": 21.9348087310791, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.9348087310791, "timesteps_since_restore": 0, "iterations_since_restore": 192, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1770457912267128, "mean_inference_ms": 0.7496486376300315, "mean_action_processing_ms": 0.047239964113367554, "mean_env_wait_ms": 0.29227768635305407, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11580, "timesteps_this_iter": 0, "agent_timesteps_total": 34740, "timers": {"sample_time_ms": 108.127, "sample_throughput": 554.903, "load_time_ms": 0.16, "load_throughput": 374547.165, "learn_time_ms": 12.42, "learn_throughput": 4831.044, "update_time_ms": 0.825}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.1861838222649047e-59, "cur_lr": 0.0005, "total_loss": 10465318.5, "policy_loss": -0.0006092044899972393, "vf_loss": 10465318.5, "vf_explained_var": 3.606081008911133e-06, "kl": 0.00020533419554524812, "entropy": 1.5707603693008423, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11580, "num_agent_steps_sampled": 34740, "num_steps_trained": 11580, "num_agent_steps_trained": 34740, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 115, "training_iteration": 193, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-56", "timestamp": 1742303396, "time_this_iter_s": 0.09210515022277832, "time_total_s": 22.02691388130188, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772aa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.02691388130188, "timesteps_since_restore": 0, "iterations_since_restore": 193, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17700706922568002, "mean_inference_ms": 0.7496668247197584, "mean_action_processing_ms": 0.047232651075160906, "mean_env_wait_ms": 0.2922948256438934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11640, "timesteps_this_iter": 0, "agent_timesteps_total": 34920, "timers": {"sample_time_ms": 107.877, "sample_throughput": 556.188, "load_time_ms": 0.153, "load_throughput": 392786.39, "learn_time_ms": 12.383, "learn_throughput": 4845.219, "update_time_ms": 0.836}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5930919111324524e-59, "cur_lr": 0.0005, "total_loss": 2061734.75, "policy_loss": -0.003623314641622244, "vf_loss": 2061734.9375, "vf_explained_var": -1.7881393432617188e-07, "kl": 0.0004559528097066723, "entropy": 1.582500159740448, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11640, "num_agent_steps_sampled": 34920, "num_steps_trained": 11640, "num_agent_steps_trained": 34920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 116, "training_iteration": 194, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-56", "timestamp": 1742303396, "time_this_iter_s": 0.09524130821228027, "time_total_s": 22.12215518951416, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277514c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.12215518951416, "timesteps_since_restore": 0, "iterations_since_restore": 194, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17697192756563201, "mean_inference_ms": 0.7496839196160462, "mean_action_processing_ms": 0.04722549875806215, "mean_env_wait_ms": 0.2923085010786195, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11700, "timesteps_this_iter": 0, "agent_timesteps_total": 35100, "timers": {"sample_time_ms": 107.841, "sample_throughput": 556.375, "load_time_ms": 0.148, "load_throughput": 406424.806, "learn_time_ms": 12.481, "learn_throughput": 4807.299, "update_time_ms": 0.841}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.965459555662262e-60, "cur_lr": 0.0005, "total_loss": 18786426.0, "policy_loss": -0.0022171428892754363, "vf_loss": 18786426.0, "vf_explained_var": 2.086162567138672e-07, "kl": 0.0006703849724671862, "entropy": 1.5928320288658142, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11700, "num_agent_steps_sampled": 35100, "num_steps_trained": 11700, "num_agent_steps_trained": 35100, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 117, "training_iteration": 195, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-56", "timestamp": 1742303396, "time_this_iter_s": 0.09169745445251465, "time_total_s": 22.213852643966675, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.213852643966675, "timesteps_since_restore": 0, "iterations_since_restore": 195, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17697192756563201, "mean_inference_ms": 0.7496839196160462, "mean_action_processing_ms": 0.04722549875806215, "mean_env_wait_ms": 0.2923085010786195, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11760, "timesteps_this_iter": 0, "agent_timesteps_total": 35280, "timers": {"sample_time_ms": 107.658, "sample_throughput": 557.322, "load_time_ms": 0.148, "load_throughput": 406031.365, "learn_time_ms": 12.281, "learn_throughput": 4885.429, "update_time_ms": 0.872}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.982729777831131e-60, "cur_lr": 0.0005, "total_loss": 4457863.75, "policy_loss": -0.001088819520858486, "vf_loss": 4457864.0, "vf_explained_var": -1.6689300537109375e-06, "kl": 0.0006049265950012206, "entropy": 1.5939304828643799, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11760, "num_agent_steps_sampled": 35280, "num_steps_trained": 11760, "num_agent_steps_trained": 35280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 117, "training_iteration": 196, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-56", "timestamp": 1742303396, "time_this_iter_s": 0.09423971176147461, "time_total_s": 22.30809235572815, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.30809235572815, "timesteps_since_restore": 0, "iterations_since_restore": 196, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17694438127497591, "mean_inference_ms": 0.7497093642305674, "mean_action_processing_ms": 0.04721925318653084, "mean_env_wait_ms": 0.29232712700555225, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11820, "timesteps_this_iter": 0, "agent_timesteps_total": 35460, "timers": {"sample_time_ms": 107.854, "sample_throughput": 556.307, "load_time_ms": 0.147, "load_throughput": 409000.878, "learn_time_ms": 12.351, "learn_throughput": 4857.798, "update_time_ms": 0.879}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9913648889155655e-60, "cur_lr": 0.0005, "total_loss": 7838952.25, "policy_loss": -0.0027774684389854087, "vf_loss": 7838952.25, "vf_explained_var": -1.7881393432617188e-06, "kl": 0.0005762022750346318, "entropy": 1.5841323733329773, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11820, "num_agent_steps_sampled": 35460, "num_steps_trained": 11820, "num_agent_steps_trained": 35460, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 118, "training_iteration": 197, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-56", "timestamp": 1742303396, "time_this_iter_s": 0.09536886215209961, "time_total_s": 22.40346121788025, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.40346121788025, "timesteps_since_restore": 0, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 13.4, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17694438127497591, "mean_inference_ms": 0.7497093642305674, "mean_action_processing_ms": 0.04721925318653084, "mean_env_wait_ms": 0.29232712700555225, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11880, "timesteps_this_iter": 0, "agent_timesteps_total": 35640, "timers": {"sample_time_ms": 108.13, "sample_throughput": 554.886, "load_time_ms": 0.15, "load_throughput": 399077.45, "learn_time_ms": 12.38, "learn_throughput": 4846.721, "update_time_ms": 0.886}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.956824444577827e-61, "cur_lr": 0.0005, "total_loss": 10463025.5, "policy_loss": -0.001809171468226456, "vf_loss": 10463026.0, "vf_explained_var": -1.0728836059570312e-06, "kl": 0.0005595190700215247, "entropy": 1.5640920996665955, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11880, "num_agent_steps_sampled": 35640, "num_steps_trained": 11880, "num_agent_steps_trained": 35640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 118, "training_iteration": 198, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-56", "timestamp": 1742303396, "time_this_iter_s": 0.09705042839050293, "time_total_s": 22.500511646270752, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.500511646270752, "timesteps_since_restore": 0, "iterations_since_restore": 198, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17692207122726203, "mean_inference_ms": 0.7497380809310826, "mean_action_processing_ms": 0.04721386352118648, "mean_env_wait_ms": 0.2923501431214218, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11940, "timesteps_this_iter": 0, "agent_timesteps_total": 35820, "timers": {"sample_time_ms": 108.263, "sample_throughput": 554.207, "load_time_ms": 0.166, "load_throughput": 361941.953, "learn_time_ms": 12.397, "learn_throughput": 4839.917, "update_time_ms": 0.889}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.9784122222889136e-61, "cur_lr": 0.0005, "total_loss": 2059951.5625, "policy_loss": -0.0024073534179507305, "vf_loss": 2059951.5625, "vf_explained_var": -5.543231964111328e-06, "kl": 0.0004511634277921672, "entropy": 1.5367748737335205, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 11940, "num_agent_steps_sampled": 35820, "num_steps_trained": 11940, "num_agent_steps_trained": 35820, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 119, "training_iteration": 199, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-56", "timestamp": 1742303396, "time_this_iter_s": 0.09647679328918457, "time_total_s": 22.596988439559937, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276740d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.596988439559937, "timesteps_since_restore": 0, "iterations_since_restore": 199, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17690054673157105, "mean_inference_ms": 0.7497618428567037, "mean_action_processing_ms": 0.047208505614857114, "mean_env_wait_ms": 0.292361076213307, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12000, "timesteps_this_iter": 0, "agent_timesteps_total": 36000, "timers": {"sample_time_ms": 108.296, "sample_throughput": 554.038, "load_time_ms": 0.166, "load_throughput": 361837.872, "learn_time_ms": 12.39, "learn_throughput": 4842.431, "update_time_ms": 0.895}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.4892061111444568e-61, "cur_lr": 0.0005, "total_loss": 18776771.0, "policy_loss": -0.0004968010768706677, "vf_loss": 18776771.0, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.00042271926718484565, "entropy": 1.5083364248275757, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12000, "num_agent_steps_sampled": 36000, "num_steps_trained": 12000, "num_agent_steps_trained": 36000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14404719008770145, "mean_inference_ms": 0.7611493175252024, "mean_action_processing_ms": 0.04589054114340067, "mean_env_wait_ms": 0.28651489433244715, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 120, "training_iteration": 200, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 1.3416190147399902, "time_total_s": 23.938607454299927, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23.938607454299927, "timesteps_since_restore": 0, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 13.350000000000001, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17690054673157105, "mean_inference_ms": 0.7497618428567037, "mean_action_processing_ms": 0.047208505614857114, "mean_env_wait_ms": 0.292361076213307, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12060, "timesteps_this_iter": 0, "agent_timesteps_total": 36180, "timers": {"sample_time_ms": 233.883, "sample_throughput": 256.539, "load_time_ms": 0.17, "load_throughput": 352956.858, "learn_time_ms": 12.323, "learn_throughput": 4868.86, "update_time_ms": 0.942}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2446030555722284e-61, "cur_lr": 0.0005, "total_loss": 4456378.75, "policy_loss": 0.0010048346490494353, "vf_loss": 4456378.75, "vf_explained_var": 1.6689300537109375e-06, "kl": 0.0002508154267228946, "entropy": 1.4795222878456116, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12060, "num_agent_steps_sampled": 36180, "num_steps_trained": 12060, "num_agent_steps_trained": 36180, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 120, "training_iteration": 201, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 0.09168076515197754, "time_total_s": 24.030288219451904, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a3a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.030288219451904, "timesteps_since_restore": 0, "iterations_since_restore": 201, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1768809453978679, "mean_inference_ms": 0.7497752860262988, "mean_action_processing_ms": 0.04720337085235452, "mean_env_wait_ms": 0.29236508873770634, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12120, "timesteps_this_iter": 0, "agent_timesteps_total": 36360, "timers": {"sample_time_ms": 233.673, "sample_throughput": 256.769, "load_time_ms": 0.17, "load_throughput": 353006.368, "learn_time_ms": 12.325, "learn_throughput": 4868.135, "update_time_ms": 0.935}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.223015277861142e-62, "cur_lr": 0.0005, "total_loss": 7833929.25, "policy_loss": -0.0008304516526146388, "vf_loss": 7833929.25, "vf_explained_var": -6.079673767089844e-06, "kl": 0.00013876313541238972, "entropy": 1.454500436782837, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12120, "num_agent_steps_sampled": 36360, "num_steps_trained": 12120, "num_agent_steps_trained": 36360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 121, "training_iteration": 202, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 0.09612655639648438, "time_total_s": 24.12641477584839, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.12641477584839, "timesteps_since_restore": 0, "iterations_since_restore": 202, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1768809453978679, "mean_inference_ms": 0.7497752860262988, "mean_action_processing_ms": 0.04720337085235452, "mean_env_wait_ms": 0.29236508873770634, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12180, "timesteps_this_iter": 0, "agent_timesteps_total": 36540, "timers": {"sample_time_ms": 233.594, "sample_throughput": 256.856, "load_time_ms": 0.17, "load_throughput": 353452.584, "learn_time_ms": 12.271, "learn_throughput": 4889.606, "update_time_ms": 0.936}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.111507638930571e-62, "cur_lr": 0.0005, "total_loss": 10460892.0, "policy_loss": -0.0004468344999217777, "vf_loss": 10460892.0, "vf_explained_var": 2.8014183044433594e-06, "kl": 9.34098902689584e-05, "entropy": 1.4302743673324585, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12180, "num_agent_steps_sampled": 36540, "num_steps_trained": 12180, "num_agent_steps_trained": 36540, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 121, "training_iteration": 203, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 0.09132575988769531, "time_total_s": 24.217740535736084, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.217740535736084, "timesteps_since_restore": 0, "iterations_since_restore": 203, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17686265343877117, "mean_inference_ms": 0.7497885826029546, "mean_action_processing_ms": 0.04719827892565402, "mean_env_wait_ms": 0.29237124915629736, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12240, "timesteps_this_iter": 0, "agent_timesteps_total": 36720, "timers": {"sample_time_ms": 233.839, "sample_throughput": 256.587, "load_time_ms": 0.178, "load_throughput": 336306.615, "learn_time_ms": 12.351, "learn_throughput": 4858.061, "update_time_ms": 0.942}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5557538194652855e-62, "cur_lr": 0.0005, "total_loss": 2058171.8125, "policy_loss": 0.0004158881059588282, "vf_loss": 2058171.5625, "vf_explained_var": -2.205371856689453e-06, "kl": 8.07847284498564e-05, "entropy": 1.4230011701583862, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12240, "num_agent_steps_sampled": 36720, "num_steps_trained": 12240, "num_agent_steps_trained": 36720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 122, "training_iteration": 204, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 0.09658980369567871, "time_total_s": 24.314330339431763, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.314330339431763, "timesteps_since_restore": 0, "iterations_since_restore": 204, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17684464791565394, "mean_inference_ms": 0.7498165300853614, "mean_action_processing_ms": 0.0471939847188754, "mean_env_wait_ms": 0.29237875596353613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12300, "timesteps_this_iter": 0, "agent_timesteps_total": 36900, "timers": {"sample_time_ms": 234.243, "sample_throughput": 256.144, "load_time_ms": 0.179, "load_throughput": 335678.591, "learn_time_ms": 12.25, "learn_throughput": 4897.942, "update_time_ms": 0.984}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.778769097326428e-63, "cur_lr": 0.0005, "total_loss": 18767090.0, "policy_loss": -0.0008780532296643329, "vf_loss": 18767090.0, "vf_explained_var": 4.0531158447265625e-06, "kl": 6.028238471689207e-05, "entropy": 1.422760248184204, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12300, "num_agent_steps_sampled": 36900, "num_steps_trained": 12300, "num_agent_steps_trained": 36900, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 123, "training_iteration": 205, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 0.09441375732421875, "time_total_s": 24.40874409675598, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.40874409675598, "timesteps_since_restore": 0, "iterations_since_restore": 205, "perf": {"cpu_util_percent": 13.5, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17684464791565394, "mean_inference_ms": 0.7498165300853614, "mean_action_processing_ms": 0.0471939847188754, "mean_env_wait_ms": 0.29237875596353613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12360, "timesteps_this_iter": 0, "agent_timesteps_total": 37080, "timers": {"sample_time_ms": 234.144, "sample_throughput": 256.253, "load_time_ms": 0.186, "load_throughput": 322556.063, "learn_time_ms": 12.387, "learn_throughput": 4843.969, "update_time_ms": 0.953}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.889384548663214e-63, "cur_lr": 0.0005, "total_loss": 4454929.0, "policy_loss": -0.0007575124385752474, "vf_loss": 4454928.75, "vf_explained_var": 7.152557373046875e-06, "kl": 0.00013084413526920358, "entropy": 1.4345887899398804, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12360, "num_agent_steps_sampled": 37080, "num_steps_trained": 12360, "num_agent_steps_trained": 37080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 123, "training_iteration": 206, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 0.09413862228393555, "time_total_s": 24.502882719039917, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.502882719039917, "timesteps_since_restore": 0, "iterations_since_restore": 206, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1768301576015715, "mean_inference_ms": 0.7498509638796933, "mean_action_processing_ms": 0.04719025453161017, "mean_env_wait_ms": 0.29239059494925335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12420, "timesteps_this_iter": 0, "agent_timesteps_total": 37260, "timers": {"sample_time_ms": 234.109, "sample_throughput": 256.291, "load_time_ms": 0.191, "load_throughput": 314651.463, "learn_time_ms": 12.277, "learn_throughput": 4887.033, "update_time_ms": 1.038}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.944692274331607e-63, "cur_lr": 0.0005, "total_loss": 7828872.25, "policy_loss": -0.001949416967626405, "vf_loss": 7828872.25, "vf_explained_var": -2.86102294921875e-06, "kl": 0.00021007485387158908, "entropy": 1.4452160000801086, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12420, "num_agent_steps_sampled": 37260, "num_steps_trained": 12420, "num_agent_steps_trained": 37260, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 124, "training_iteration": 207, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 0.09438252449035645, "time_total_s": 24.597265243530273, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f31f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.597265243530273, "timesteps_since_restore": 0, "iterations_since_restore": 207, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1768301576015715, "mean_inference_ms": 0.7498509638796933, "mean_action_processing_ms": 0.04719025453161017, "mean_env_wait_ms": 0.29239059494925335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12480, "timesteps_this_iter": 0, "agent_timesteps_total": 37440, "timers": {"sample_time_ms": 233.689, "sample_throughput": 256.751, "load_time_ms": 0.187, "load_throughput": 320583.745, "learn_time_ms": 12.289, "learn_throughput": 4882.538, "update_time_ms": 1.025}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.723461371658034e-64, "cur_lr": 0.0005, "total_loss": 10458701.0, "policy_loss": 0.0006444891267971542, "vf_loss": 10458701.0, "vf_explained_var": -5.9604644775390625e-06, "kl": 0.0001440637030913905, "entropy": 1.448448896408081, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12480, "num_agent_steps_sampled": 37440, "num_steps_trained": 12480, "num_agent_steps_trained": 37440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 124, "training_iteration": 208, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-58", "timestamp": 1742303398, "time_this_iter_s": 0.09324455261230469, "time_total_s": 24.690509796142578, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771af70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.690509796142578, "timesteps_since_restore": 0, "iterations_since_restore": 208, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1768137249859761, "mean_inference_ms": 0.7498795573937193, "mean_action_processing_ms": 0.04718674851073706, "mean_env_wait_ms": 0.29239880895667425, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12540, "timesteps_this_iter": 0, "agent_timesteps_total": 37620, "timers": {"sample_time_ms": 233.417, "sample_throughput": 257.051, "load_time_ms": 0.175, "load_throughput": 342392.163, "learn_time_ms": 12.27, "learn_throughput": 4889.805, "update_time_ms": 1.029}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.861730685829017e-64, "cur_lr": 0.0005, "total_loss": 2056392.75, "policy_loss": -0.0003831221010628383, "vf_loss": 2056392.625, "vf_explained_var": -4.649162292480469e-06, "kl": 7.507244743187869e-05, "entropy": 1.4418204426765442, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12540, "num_agent_steps_sampled": 37620, "num_steps_trained": 12540, "num_agent_steps_trained": 37620, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 125, "training_iteration": 209, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.09430336952209473, "time_total_s": 24.784813165664673, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.784813165664673, "timesteps_since_restore": 0, "iterations_since_restore": 209, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17679211890271548, "mean_inference_ms": 0.7498749703991243, "mean_action_processing_ms": 0.04718184626886965, "mean_env_wait_ms": 0.2923899320086331, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12600, "timesteps_this_iter": 0, "agent_timesteps_total": 37800, "timers": {"sample_time_ms": 232.854, "sample_throughput": 257.672, "load_time_ms": 0.186, "load_throughput": 322845.722, "learn_time_ms": 12.249, "learn_throughput": 4898.295, "update_time_ms": 1.031}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.4308653429145086e-64, "cur_lr": 0.0005, "total_loss": 18757418.0, "policy_loss": -0.000647718350712978, "vf_loss": 18757420.0, "vf_explained_var": -3.5762786865234375e-07, "kl": 0.0001235307867011315, "entropy": 1.437741756439209, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12600, "num_agent_steps_sampled": 37800, "num_steps_trained": 12600, "num_agent_steps_trained": 37800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 126, "training_iteration": 210, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.09128594398498535, "time_total_s": 24.876099109649658, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f31f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.876099109649658, "timesteps_since_restore": 0, "iterations_since_restore": 210, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17679211890271548, "mean_inference_ms": 0.7498749703991243, "mean_action_processing_ms": 0.04718184626886965, "mean_env_wait_ms": 0.2923899320086331, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12660, "timesteps_this_iter": 0, "agent_timesteps_total": 37980, "timers": {"sample_time_ms": 107.269, "sample_throughput": 559.341, "load_time_ms": 0.182, "load_throughput": 329094.076, "learn_time_ms": 12.454, "learn_throughput": 4817.652, "update_time_ms": 0.983}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2154326714572543e-64, "cur_lr": 0.0005, "total_loss": 4453594.0, "policy_loss": -0.0033499492435815625, "vf_loss": 4453594.0, "vf_explained_var": -1.627206802368164e-05, "kl": 0.0004326202961031367, "entropy": 1.4280737042427063, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12660, "num_agent_steps_sampled": 37980, "num_steps_trained": 12660, "num_agent_steps_trained": 37980, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 126, "training_iteration": 211, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.09342765808105469, "time_total_s": 24.969526767730713, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.969526767730713, "timesteps_since_restore": 0, "iterations_since_restore": 211, "perf": {"cpu_util_percent": 13.4, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17677179491352923, "mean_inference_ms": 0.7498707600209351, "mean_action_processing_ms": 0.04717666670990244, "mean_env_wait_ms": 0.2923767903897753, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12720, "timesteps_this_iter": 0, "agent_timesteps_total": 38160, "timers": {"sample_time_ms": 106.963, "sample_throughput": 560.944, "load_time_ms": 0.184, "load_throughput": 326786.443, "learn_time_ms": 12.38, "learn_throughput": 4846.413, "update_time_ms": 0.981}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.0771633572862715e-65, "cur_lr": 0.0005, "total_loss": 7823795.25, "policy_loss": 0.0006803452774590824, "vf_loss": 7823795.25, "vf_explained_var": 5.036592483520508e-06, "kl": 0.00037165039176034753, "entropy": 1.3916577696800232, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12720, "num_agent_steps_sampled": 38160, "num_steps_trained": 12720, "num_agent_steps_trained": 38160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 127, "training_iteration": 212, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.0909566879272461, "time_total_s": 25.06048345565796, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.06048345565796, "timesteps_since_restore": 0, "iterations_since_restore": 212, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17677179491352923, "mean_inference_ms": 0.7498707600209351, "mean_action_processing_ms": 0.04717666670990244, "mean_env_wait_ms": 0.2923767903897753, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12780, "timesteps_this_iter": 0, "agent_timesteps_total": 38340, "timers": {"sample_time_ms": 107.12, "sample_throughput": 560.122, "load_time_ms": 0.183, "load_throughput": 327722.672, "learn_time_ms": 12.507, "learn_throughput": 4797.273, "update_time_ms": 0.981}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0385816786431358e-65, "cur_lr": 0.0005, "total_loss": 10456296.5, "policy_loss": 0.00018352700895363228, "vf_loss": 10456296.0, "vf_explained_var": 1.3709068298339844e-06, "kl": 8.981023918508413e-05, "entropy": 1.3805556297302246, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12780, "num_agent_steps_sampled": 38340, "num_steps_trained": 12780, "num_agent_steps_trained": 38340, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 127, "training_iteration": 213, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.0928351879119873, "time_total_s": 25.153318643569946, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.153318643569946, "timesteps_since_restore": 0, "iterations_since_restore": 213, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17675125020070412, "mean_inference_ms": 0.7498621544384307, "mean_action_processing_ms": 0.04717182511090501, "mean_env_wait_ms": 0.2923588163253643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12840, "timesteps_this_iter": 0, "agent_timesteps_total": 38520, "timers": {"sample_time_ms": 106.977, "sample_throughput": 560.866, "load_time_ms": 0.188, "load_throughput": 319484.88, "learn_time_ms": 12.393, "learn_throughput": 4841.593, "update_time_ms": 0.959}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5192908393215679e-65, "cur_lr": 0.0005, "total_loss": 2054576.875, "policy_loss": -0.0007597737583435737, "vf_loss": 2054577.0625, "vf_explained_var": 8.106231689453125e-06, "kl": 0.0001246657972036047, "entropy": 1.3905400037765503, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12840, "num_agent_steps_sampled": 38520, "num_steps_trained": 12840, "num_agent_steps_trained": 38520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 128, "training_iteration": 214, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.09245777130126953, "time_total_s": 25.245776414871216, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.245776414871216, "timesteps_since_restore": 0, "iterations_since_restore": 214, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17672801834018337, "mean_inference_ms": 0.7498521310736309, "mean_action_processing_ms": 0.04716698173819918, "mean_env_wait_ms": 0.2923367259875214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12900, "timesteps_this_iter": 0, "agent_timesteps_total": 38700, "timers": {"sample_time_ms": 106.661, "sample_throughput": 562.528, "load_time_ms": 0.195, "load_throughput": 307725.899, "learn_time_ms": 12.368, "learn_throughput": 4851.196, "update_time_ms": 0.936}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.596454196607839e-66, "cur_lr": 0.0005, "total_loss": 18747729.0, "policy_loss": 0.0005187491550007195, "vf_loss": 18747729.0, "vf_explained_var": -2.384185791015625e-06, "kl": 6.064647473680296e-05, "entropy": 1.413446068763733, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12900, "num_agent_steps_sampled": 38700, "num_steps_trained": 12900, "num_agent_steps_trained": 38700, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 129, "training_iteration": 215, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.09108424186706543, "time_total_s": 25.33686065673828, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.33686065673828, "timesteps_since_restore": 0, "iterations_since_restore": 215, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17672801834018337, "mean_inference_ms": 0.7498521310736309, "mean_action_processing_ms": 0.04716698173819918, "mean_env_wait_ms": 0.2923367259875214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12960, "timesteps_this_iter": 0, "agent_timesteps_total": 38880, "timers": {"sample_time_ms": 106.242, "sample_throughput": 564.75, "load_time_ms": 0.194, "load_throughput": 308669.496, "learn_time_ms": 12.315, "learn_throughput": 4872.018, "update_time_ms": 0.947}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.7982270983039197e-66, "cur_lr": 0.0005, "total_loss": 4452127.25, "policy_loss": -0.0021022465390458933, "vf_loss": 4452127.5, "vf_explained_var": -1.4185905456542969e-05, "kl": 0.00013436500011110297, "entropy": 1.412768304347992, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12960, "num_agent_steps_sampled": 38880, "num_steps_trained": 12960, "num_agent_steps_trained": 38880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 129, "training_iteration": 216, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.0895986557006836, "time_total_s": 25.426459312438965, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.426459312438965, "timesteps_since_restore": 0, "iterations_since_restore": 216, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1767043290306668, "mean_inference_ms": 0.749838962854364, "mean_action_processing_ms": 0.04716181134659172, "mean_env_wait_ms": 0.2923130766050415, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13020, "timesteps_this_iter": 0, "agent_timesteps_total": 39060, "timers": {"sample_time_ms": 106.18, "sample_throughput": 565.078, "load_time_ms": 0.191, "load_throughput": 313984.08, "learn_time_ms": 12.363, "learn_throughput": 4853.208, "update_time_ms": 0.865}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8991135491519599e-66, "cur_lr": 0.0005, "total_loss": 7818771.25, "policy_loss": -0.0011106901853867868, "vf_loss": 7818771.25, "vf_explained_var": 1.7881393432617188e-06, "kl": 0.00023107102305530702, "entropy": 1.4026786088943481, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13020, "num_agent_steps_sampled": 39060, "num_steps_trained": 13020, "num_agent_steps_trained": 39060, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 130, "training_iteration": 217, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-09-59", "timestamp": 1742303399, "time_this_iter_s": 0.09034490585327148, "time_total_s": 25.516804218292236, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.516804218292236, "timesteps_since_restore": 0, "iterations_since_restore": 217, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1767043290306668, "mean_inference_ms": 0.749838962854364, "mean_action_processing_ms": 0.04716181134659172, "mean_env_wait_ms": 0.2923130766050415, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13080, "timesteps_this_iter": 0, "agent_timesteps_total": 39240, "timers": {"sample_time_ms": 106.438, "sample_throughput": 563.707, "load_time_ms": 0.198, "load_throughput": 302364.82, "learn_time_ms": 12.413, "learn_throughput": 4833.697, "update_time_ms": 0.871}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.495567745759799e-67, "cur_lr": 0.0005, "total_loss": 10454204.0, "policy_loss": -0.0010811253269729093, "vf_loss": 10454204.0, "vf_explained_var": -8.940696716308594e-07, "kl": 0.0002510858894191337, "entropy": 1.3879266381263733, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13080, "num_agent_steps_sampled": 39240, "num_steps_trained": 13080, "num_agent_steps_trained": 39240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 130, "training_iteration": 218, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.09469866752624512, "time_total_s": 25.61150288581848, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.61150288581848, "timesteps_since_restore": 0, "iterations_since_restore": 218, "perf": {"cpu_util_percent": 13.5, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17668426895957576, "mean_inference_ms": 0.749831922165731, "mean_action_processing_ms": 0.047157056572864925, "mean_env_wait_ms": 0.29229148854420267, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13140, "timesteps_this_iter": 0, "agent_timesteps_total": 39420, "timers": {"sample_time_ms": 106.78, "sample_throughput": 561.904, "load_time_ms": 0.205, "load_throughput": 293068.872, "learn_time_ms": 12.42, "learn_throughput": 4830.812, "update_time_ms": 0.868}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.7477838728798996e-67, "cur_lr": 0.0005, "total_loss": 2052803.0625, "policy_loss": -0.0001731740074717436, "vf_loss": 2052803.0625, "vf_explained_var": -5.364418029785156e-06, "kl": 0.00021670224425029971, "entropy": 1.363563060760498, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13140, "num_agent_steps_sampled": 39420, "num_steps_trained": 13140, "num_agent_steps_trained": 39420, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 131, "training_iteration": 219, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.09460830688476562, "time_total_s": 25.706111192703247, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.706111192703247, "timesteps_since_restore": 0, "iterations_since_restore": 219, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17665998299680521, "mean_inference_ms": 0.7498154253421889, "mean_action_processing_ms": 0.04715194423749055, "mean_env_wait_ms": 0.29226827123126564, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13200, "timesteps_this_iter": 0, "agent_timesteps_total": 39600, "timers": {"sample_time_ms": 107.128, "sample_throughput": 560.075, "load_time_ms": 0.194, "load_throughput": 309276.441, "learn_time_ms": 12.443, "learn_throughput": 4821.991, "update_time_ms": 0.866}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.3738919364399498e-67, "cur_lr": 0.0005, "total_loss": 18737991.0, "policy_loss": -0.0011431074856460555, "vf_loss": 18737991.0, "vf_explained_var": 3.635883331298828e-06, "kl": 0.0001431072253863519, "entropy": 1.3447426557540894, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13200, "num_agent_steps_sampled": 39600, "num_steps_trained": 13200, "num_agent_steps_trained": 39600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 132, "training_iteration": 220, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.09256768226623535, "time_total_s": 25.798678874969482, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276744c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.798678874969482, "timesteps_since_restore": 0, "iterations_since_restore": 220, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17665998299680521, "mean_inference_ms": 0.7498154253421889, "mean_action_processing_ms": 0.04715194423749055, "mean_env_wait_ms": 0.29226827123126564, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13260, "timesteps_this_iter": 0, "agent_timesteps_total": 39780, "timers": {"sample_time_ms": 107.761, "sample_throughput": 556.787, "load_time_ms": 0.187, "load_throughput": 320379.682, "learn_time_ms": 12.251, "learn_throughput": 4897.666, "update_time_ms": 0.891}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1869459682199749e-67, "cur_lr": 0.0005, "total_loss": 4450706.5, "policy_loss": 0.0002172426986764009, "vf_loss": 4450706.25, "vf_explained_var": -1.8775463104248047e-05, "kl": 0.00011534385910749734, "entropy": 1.3562064170837402, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13260, "num_agent_steps_sampled": 39780, "num_steps_trained": 13260, "num_agent_steps_trained": 39780, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 132, "training_iteration": 221, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.09173274040222168, "time_total_s": 25.890411615371704, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.890411615371704, "timesteps_since_restore": 0, "iterations_since_restore": 221, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1766387515682626, "mean_inference_ms": 0.7498045469055991, "mean_action_processing_ms": 0.04714671936665447, "mean_env_wait_ms": 0.2922468229406322, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13320, "timesteps_this_iter": 0, "agent_timesteps_total": 39960, "timers": {"sample_time_ms": 107.803, "sample_throughput": 556.57, "load_time_ms": 0.192, "load_throughput": 312463.67, "learn_time_ms": 12.374, "learn_throughput": 4849.056, "update_time_ms": 0.897}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.9347298410998745e-68, "cur_lr": 0.0005, "total_loss": 7813754.0, "policy_loss": -0.0006864037558749203, "vf_loss": 7813754.5, "vf_explained_var": -5.7220458984375e-06, "kl": 0.0001742958717514398, "entropy": 1.331489622592926, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13320, "num_agent_steps_sampled": 39960, "num_steps_trained": 13320, "num_agent_steps_trained": 39960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 133, "training_iteration": 222, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.09407901763916016, "time_total_s": 25.984490633010864, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.984490633010864, "timesteps_since_restore": 0, "iterations_since_restore": 222, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1766387515682626, "mean_inference_ms": 0.7498045469055991, "mean_action_processing_ms": 0.04714671936665447, "mean_env_wait_ms": 0.2922468229406322, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13380, "timesteps_this_iter": 0, "agent_timesteps_total": 40140, "timers": {"sample_time_ms": 107.348, "sample_throughput": 558.929, "load_time_ms": 0.204, "load_throughput": 294681.78, "learn_time_ms": 12.363, "learn_throughput": 4853.245, "update_time_ms": 0.891}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9673649205499373e-68, "cur_lr": 0.0005, "total_loss": 10452056.0, "policy_loss": 0.00024267633820684864, "vf_loss": 10452056.5, "vf_explained_var": 8.225440979003906e-06, "kl": 0.0001239303597539987, "entropy": 1.2932208776474, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13380, "num_agent_steps_sampled": 40140, "num_steps_trained": 13380, "num_agent_steps_trained": 40140, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 133, "training_iteration": 223, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.08920454978942871, "time_total_s": 26.073695182800293, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.073695182800293, "timesteps_since_restore": 0, "iterations_since_restore": 223, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.176619192223059, "mean_inference_ms": 0.7497986359020898, "mean_action_processing_ms": 0.04714163064964601, "mean_env_wait_ms": 0.2922275001494996, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13440, "timesteps_this_iter": 0, "agent_timesteps_total": 40320, "timers": {"sample_time_ms": 107.461, "sample_throughput": 558.345, "load_time_ms": 0.204, "load_throughput": 293684.491, "learn_time_ms": 12.547, "learn_throughput": 4782.05, "update_time_ms": 0.905}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4836824602749686e-68, "cur_lr": 0.0005, "total_loss": 2050949.4375, "policy_loss": -0.0004077341931409961, "vf_loss": 2050949.5, "vf_explained_var": -3.5762786865234375e-07, "kl": 7.726994564949408e-05, "entropy": 1.2705636620521545, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13440, "num_agent_steps_sampled": 40320, "num_steps_trained": 13440, "num_agent_steps_trained": 40320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 134, "training_iteration": 224, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.0966031551361084, "time_total_s": 26.1702983379364, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.1702983379364, "timesteps_since_restore": 0, "iterations_since_restore": 224, "perf": {"cpu_util_percent": 14.0, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17659724276664968, "mean_inference_ms": 0.7497978076283178, "mean_action_processing_ms": 0.04713714254041684, "mean_env_wait_ms": 0.29221251907031154, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13500, "timesteps_this_iter": 0, "agent_timesteps_total": 40500, "timers": {"sample_time_ms": 107.581, "sample_throughput": 557.719, "load_time_ms": 0.208, "load_throughput": 288202.29, "learn_time_ms": 12.726, "learn_throughput": 4714.829, "update_time_ms": 0.895}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.418412301374843e-69, "cur_lr": 0.0005, "total_loss": 18728375.0, "policy_loss": -0.0029469307719005577, "vf_loss": 18728375.0, "vf_explained_var": -1.0848045349121094e-05, "kl": 0.00035858754912254653, "entropy": 1.241227149963379, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13500, "num_agent_steps_sampled": 40500, "num_steps_trained": 13500, "num_agent_steps_trained": 40500, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 135, "training_iteration": 225, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.09202194213867188, "time_total_s": 26.262320280075073, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.262320280075073, "timesteps_since_restore": 0, "iterations_since_restore": 225, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17659724276664968, "mean_inference_ms": 0.7497978076283178, "mean_action_processing_ms": 0.04713714254041684, "mean_env_wait_ms": 0.29221251907031154, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13560, "timesteps_this_iter": 0, "agent_timesteps_total": 40680, "timers": {"sample_time_ms": 107.866, "sample_throughput": 556.247, "load_time_ms": 0.207, "load_throughput": 290229.777, "learn_time_ms": 12.679, "learn_throughput": 4732.144, "update_time_ms": 0.895}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.7092061506874216e-69, "cur_lr": 0.0005, "total_loss": 4449216.0, "policy_loss": -0.002636802537985261, "vf_loss": 4449216.5, "vf_explained_var": -1.1324882507324219e-05, "kl": 0.0008526251922944539, "entropy": 1.1631507873535156, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13560, "num_agent_steps_sampled": 40680, "num_steps_trained": 13560, "num_agent_steps_trained": 40680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 135, "training_iteration": 226, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.09099841117858887, "time_total_s": 26.353318691253662, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.353318691253662, "timesteps_since_restore": 0, "iterations_since_restore": 226, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17657770862823596, "mean_inference_ms": 0.7497967671877716, "mean_action_processing_ms": 0.047132553216108326, "mean_env_wait_ms": 0.29219752892922246, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13620, "timesteps_this_iter": 0, "agent_timesteps_total": 40860, "timers": {"sample_time_ms": 107.898, "sample_throughput": 556.079, "load_time_ms": 0.216, "load_throughput": 278013.964, "learn_time_ms": 12.715, "learn_throughput": 4718.754, "update_time_ms": 0.893}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8546030753437108e-69, "cur_lr": 0.0005, "total_loss": 7808632.5, "policy_loss": -0.0012086914102020785, "vf_loss": 7808632.5, "vf_explained_var": 2.086162567138672e-07, "kl": 0.0008200849303333646, "entropy": 1.064023733139038, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13620, "num_agent_steps_sampled": 40860, "num_steps_trained": 13620, "num_agent_steps_trained": 40860, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 136, "training_iteration": 227, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-00", "timestamp": 1742303400, "time_this_iter_s": 0.09553337097167969, "time_total_s": 26.448852062225342, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771aca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.448852062225342, "timesteps_since_restore": 0, "iterations_since_restore": 227, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17657770862823596, "mean_inference_ms": 0.7497967671877716, "mean_action_processing_ms": 0.047132553216108326, "mean_env_wait_ms": 0.29219752892922246, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13680, "timesteps_this_iter": 0, "agent_timesteps_total": 41040, "timers": {"sample_time_ms": 107.878, "sample_throughput": 556.185, "load_time_ms": 0.213, "load_throughput": 282254.643, "learn_time_ms": 12.608, "learn_throughput": 4758.9, "update_time_ms": 0.904}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.273015376718554e-70, "cur_lr": 0.0005, "total_loss": 10449809.5, "policy_loss": -0.004062986849911354, "vf_loss": 10449809.5, "vf_explained_var": -1.2159347534179688e-05, "kl": 0.0009214842583560312, "entropy": 0.9595634639263153, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13680, "num_agent_steps_sampled": 41040, "num_steps_trained": 13680, "num_agent_steps_trained": 41040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 136, "training_iteration": 228, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.09293770790100098, "time_total_s": 26.541789770126343, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.541789770126343, "timesteps_since_restore": 0, "iterations_since_restore": 228, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17655808387708827, "mean_inference_ms": 0.7497990154612577, "mean_action_processing_ms": 0.04712860094538472, "mean_env_wait_ms": 0.29218350504297946, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13740, "timesteps_this_iter": 0, "agent_timesteps_total": 41220, "timers": {"sample_time_ms": 108.17, "sample_throughput": 554.682, "load_time_ms": 0.202, "load_throughput": 297257.548, "learn_time_ms": 12.642, "learn_throughput": 4745.994, "update_time_ms": 0.902}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.636507688359277e-70, "cur_lr": 0.0005, "total_loss": 2049192.375, "policy_loss": 0.00039802722813675473, "vf_loss": 2049192.5, "vf_explained_var": 3.2782554626464844e-06, "kl": 0.0007084546001821512, "entropy": 0.8360807597637177, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13740, "num_agent_steps_sampled": 41220, "num_steps_trained": 13740, "num_agent_steps_trained": 41220, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 137, "training_iteration": 229, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.10019803047180176, "time_total_s": 26.641987800598145, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.641987800598145, "timesteps_since_restore": 0, "iterations_since_restore": 229, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1765403020522867, "mean_inference_ms": 0.7498046311963789, "mean_action_processing_ms": 0.04712484767784437, "mean_env_wait_ms": 0.2921711054676073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13800, "timesteps_this_iter": 0, "agent_timesteps_total": 41400, "timers": {"sample_time_ms": 108.153, "sample_throughput": 554.772, "load_time_ms": 0.214, "load_throughput": 280586.732, "learn_time_ms": 12.628, "learn_throughput": 4751.308, "update_time_ms": 0.915}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.3182538441796385e-70, "cur_lr": 0.0005, "total_loss": 18718464.0, "policy_loss": -7.912549545885383e-05, "vf_loss": 18718464.0, "vf_explained_var": -3.814697265625e-06, "kl": 0.00033179548655537516, "entropy": 0.7457685470581055, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13800, "num_agent_steps_sampled": 41400, "num_steps_trained": 13800, "num_agent_steps_trained": 41400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 138, "training_iteration": 230, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.09403753280639648, "time_total_s": 26.73602533340454, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27779f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.73602533340454, "timesteps_since_restore": 0, "iterations_since_restore": 230, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1765403020522867, "mean_inference_ms": 0.7498046311963789, "mean_action_processing_ms": 0.04712484767784437, "mean_env_wait_ms": 0.2921711054676073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13860, "timesteps_this_iter": 0, "agent_timesteps_total": 41580, "timers": {"sample_time_ms": 107.553, "sample_throughput": 557.866, "load_time_ms": 0.221, "load_throughput": 271505.276, "learn_time_ms": 12.919, "learn_throughput": 4644.443, "update_time_ms": 0.906}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1591269220898192e-70, "cur_lr": 0.0005, "total_loss": 4447624.25, "policy_loss": 0.0005921982940186865, "vf_loss": 4447624.25, "vf_explained_var": 3.2782554626464844e-06, "kl": 0.00010929776325951934, "entropy": 0.6826170086860657, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13860, "num_agent_steps_sampled": 41580, "num_steps_trained": 13860, "num_agent_steps_trained": 41580, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 138, "training_iteration": 231, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.09381389617919922, "time_total_s": 26.82983922958374, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.82983922958374, "timesteps_since_restore": 0, "iterations_since_restore": 231, "perf": {"cpu_util_percent": 15.3, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17652124395249413, "mean_inference_ms": 0.7498092669942641, "mean_action_processing_ms": 0.047121231305248944, "mean_env_wait_ms": 0.2921580646328544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13920, "timesteps_this_iter": 0, "agent_timesteps_total": 41760, "timers": {"sample_time_ms": 108.319, "sample_throughput": 553.92, "load_time_ms": 0.219, "load_throughput": 273422.686, "learn_time_ms": 13.003, "learn_throughput": 4614.23, "update_time_ms": 0.899}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.795634610449096e-71, "cur_lr": 0.0005, "total_loss": 7803496.5, "policy_loss": -3.974437681364407e-05, "vf_loss": 7803497.0, "vf_explained_var": 2.652406692504883e-06, "kl": 1.4104044180340836e-05, "entropy": 0.6574853956699371, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13920, "num_agent_steps_sampled": 41760, "num_steps_trained": 13920, "num_agent_steps_trained": 41760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 139, "training_iteration": 232, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.09696006774902344, "time_total_s": 26.926799297332764, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.926799297332764, "timesteps_since_restore": 0, "iterations_since_restore": 232, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17652124395249413, "mean_inference_ms": 0.7498092669942641, "mean_action_processing_ms": 0.047121231305248944, "mean_env_wait_ms": 0.2921580646328544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13980, "timesteps_this_iter": 0, "agent_timesteps_total": 41940, "timers": {"sample_time_ms": 109.354, "sample_throughput": 548.676, "load_time_ms": 0.208, "load_throughput": 288963.417, "learn_time_ms": 13.059, "learn_throughput": 4594.66, "update_time_ms": 0.917}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.897817305224548e-71, "cur_lr": 0.0005, "total_loss": 10447260.0, "policy_loss": 7.708469848921595e-05, "vf_loss": 10447260.0, "vf_explained_var": 2.4437904357910156e-06, "kl": 1.7095663255695115e-05, "entropy": 0.6633910238742828, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 13980, "num_agent_steps_sampled": 41940, "num_steps_trained": 13980, "num_agent_steps_trained": 41940, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 139, "training_iteration": 233, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.0978248119354248, "time_total_s": 27.02462410926819, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.02462410926819, "timesteps_since_restore": 0, "iterations_since_restore": 233, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1765021437716567, "mean_inference_ms": 0.7498153465309757, "mean_action_processing_ms": 0.047118378220041855, "mean_env_wait_ms": 0.2921460748293956, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14040, "timesteps_this_iter": 0, "agent_timesteps_total": 42120, "timers": {"sample_time_ms": 109.412, "sample_throughput": 548.384, "load_time_ms": 0.197, "load_throughput": 304265.796, "learn_time_ms": 12.841, "learn_throughput": 4672.599, "update_time_ms": 0.906}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.448908652612274e-71, "cur_lr": 0.0005, "total_loss": 2047361.6875, "policy_loss": -0.0001130296137286102, "vf_loss": 2047361.6875, "vf_explained_var": 2.0265579223632812e-06, "kl": 1.5866128816099945e-05, "entropy": 0.6776693761348724, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14040, "num_agent_steps_sampled": 42120, "num_steps_trained": 14040, "num_agent_steps_trained": 42120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 140, "training_iteration": 234, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.09555840492248535, "time_total_s": 27.120182514190674, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.120182514190674, "timesteps_since_restore": 0, "iterations_since_restore": 234, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17648513955904874, "mean_inference_ms": 0.7498258113593789, "mean_action_processing_ms": 0.04711601386285982, "mean_env_wait_ms": 0.2921353807329461, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14100, "timesteps_this_iter": 0, "agent_timesteps_total": 42300, "timers": {"sample_time_ms": 109.274, "sample_throughput": 549.081, "load_time_ms": 0.186, "load_throughput": 322638.769, "learn_time_ms": 12.722, "learn_throughput": 4716.322, "update_time_ms": 0.912}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.24454326306137e-72, "cur_lr": 0.0005, "total_loss": 18708745.0, "policy_loss": -0.0005823526091646158, "vf_loss": 18708745.0, "vf_explained_var": -4.172325134277344e-06, "kl": 2.3398278187647392e-05, "entropy": 0.6898670494556427, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14100, "num_agent_steps_sampled": 42300, "num_steps_trained": 14100, "num_agent_steps_trained": 42300, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 141, "training_iteration": 235, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.09310317039489746, "time_total_s": 27.21328568458557, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ac10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.21328568458557, "timesteps_since_restore": 0, "iterations_since_restore": 235, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17648513955904874, "mean_inference_ms": 0.7498258113593789, "mean_action_processing_ms": 0.04711601386285982, "mean_env_wait_ms": 0.2921353807329461, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14160, "timesteps_this_iter": 0, "agent_timesteps_total": 42480, "timers": {"sample_time_ms": 109.271, "sample_throughput": 549.092, "load_time_ms": 0.18, "load_throughput": 332705.235, "learn_time_ms": 12.883, "learn_throughput": 4657.423, "update_time_ms": 0.903}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.622271631530685e-72, "cur_lr": 0.0005, "total_loss": 4446292.75, "policy_loss": -9.56601548942615e-05, "vf_loss": 4446292.75, "vf_explained_var": 8.940696716308594e-07, "kl": 3.3571698153211926e-05, "entropy": 0.6990494728088379, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14160, "num_agent_steps_sampled": 42480, "num_steps_trained": 14160, "num_agent_steps_trained": 42480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 141, "training_iteration": 236, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-01", "timestamp": 1742303401, "time_this_iter_s": 0.09201216697692871, "time_total_s": 27.3052978515625, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.3052978515625, "timesteps_since_restore": 0, "iterations_since_restore": 236, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17646910809416355, "mean_inference_ms": 0.7498343039133877, "mean_action_processing_ms": 0.047113816809312335, "mean_env_wait_ms": 0.29212604493074673, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14220, "timesteps_this_iter": 0, "agent_timesteps_total": 42660, "timers": {"sample_time_ms": 109.464, "sample_throughput": 548.128, "load_time_ms": 0.17, "load_throughput": 353006.368, "learn_time_ms": 12.86, "learn_throughput": 4665.53, "update_time_ms": 0.928}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8111358157653426e-72, "cur_lr": 0.0005, "total_loss": 7798475.75, "policy_loss": -0.0006630652700554407, "vf_loss": 7798475.75, "vf_explained_var": -2.8014183044433594e-06, "kl": 3.013212463232051e-05, "entropy": 0.7067981958389282, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14220, "num_agent_steps_sampled": 42660, "num_steps_trained": 14220, "num_agent_steps_trained": 42660, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 142, "training_iteration": 237, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.09525251388549805, "time_total_s": 27.400550365447998, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276741f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.400550365447998, "timesteps_since_restore": 0, "iterations_since_restore": 237, "perf": {"cpu_util_percent": 13.9, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17646910809416355, "mean_inference_ms": 0.7498343039133877, "mean_action_processing_ms": 0.047113816809312335, "mean_env_wait_ms": 0.29212604493074673, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14280, "timesteps_this_iter": 0, "agent_timesteps_total": 42840, "timers": {"sample_time_ms": 109.447, "sample_throughput": 548.213, "load_time_ms": 0.166, "load_throughput": 361681.863, "learn_time_ms": 12.908, "learn_throughput": 4648.158, "update_time_ms": 0.912}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.055679078826713e-73, "cur_lr": 0.0005, "total_loss": 10445269.0, "policy_loss": 0.00019025206436573683, "vf_loss": 10445269.0, "vf_explained_var": -9.5367431640625e-07, "kl": 2.4685159174753224e-05, "entropy": 0.7094846069812775, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14280, "num_agent_steps_sampled": 42840, "num_steps_trained": 14280, "num_agent_steps_trained": 42840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 142, "training_iteration": 238, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.094329833984375, "time_total_s": 27.494880199432373, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772aa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.494880199432373, "timesteps_since_restore": 0, "iterations_since_restore": 238, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1764549853923011, "mean_inference_ms": 0.7498451855304044, "mean_action_processing_ms": 0.047111771495726214, "mean_env_wait_ms": 0.2921197242674623, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14340, "timesteps_this_iter": 0, "agent_timesteps_total": 43020, "timers": {"sample_time_ms": 109.098, "sample_throughput": 549.966, "load_time_ms": 0.165, "load_throughput": 363352.931, "learn_time_ms": 12.918, "learn_throughput": 4644.581, "update_time_ms": 0.923}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5278395394133564e-73, "cur_lr": 0.0005, "total_loss": 2045520.1875, "policy_loss": -0.0004367470663666495, "vf_loss": 2045520.1875, "vf_explained_var": 1.0967254638671875e-05, "kl": 4.38256859318642e-05, "entropy": 0.7164683043956757, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14340, "num_agent_steps_sampled": 43020, "num_steps_trained": 14340, "num_agent_steps_trained": 43020, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 143, "training_iteration": 239, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.09543871879577637, "time_total_s": 27.59031891822815, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.59031891822815, "timesteps_since_restore": 0, "iterations_since_restore": 239, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17643957995609624, "mean_inference_ms": 0.7498558475199798, "mean_action_processing_ms": 0.04710982533853618, "mean_env_wait_ms": 0.2921093941762746, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14400, "timesteps_this_iter": 0, "agent_timesteps_total": 43200, "timers": {"sample_time_ms": 109.268, "sample_throughput": 549.11, "load_time_ms": 0.155, "load_throughput": 387942.408, "learn_time_ms": 12.83, "learn_throughput": 4676.654, "update_time_ms": 0.899}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2639197697066782e-73, "cur_lr": 0.0005, "total_loss": 18699004.0, "policy_loss": -0.0007719470330300737, "vf_loss": 18699004.0, "vf_explained_var": 1.9073486328125e-06, "kl": 0.00013095426804163313, "entropy": 0.7501407265663147, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14400, "num_agent_steps_sampled": 43200, "num_steps_trained": 14400, "num_agent_steps_trained": 43200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 144, "training_iteration": 240, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.09351229667663574, "time_total_s": 27.683831214904785, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.683831214904785, "timesteps_since_restore": 0, "iterations_since_restore": 240, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17643957995609624, "mean_inference_ms": 0.7498558475199798, "mean_action_processing_ms": 0.04710982533853618, "mean_env_wait_ms": 0.2921093941762746, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14460, "timesteps_this_iter": 0, "agent_timesteps_total": 43380, "timers": {"sample_time_ms": 109.979, "sample_throughput": 545.559, "load_time_ms": 0.147, "load_throughput": 407016.4, "learn_time_ms": 12.61, "learn_throughput": 4758.045, "update_time_ms": 0.881}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1319598848533391e-73, "cur_lr": 0.0005, "total_loss": 4444619.25, "policy_loss": -0.0007586700958199799, "vf_loss": 4444619.25, "vf_explained_var": -1.7881393432617188e-07, "kl": 0.00021232762128362004, "entropy": 0.7968156933784485, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14460, "num_agent_steps_sampled": 43380, "num_steps_trained": 14460, "num_agent_steps_trained": 43380, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 144, "training_iteration": 241, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.09233403205871582, "time_total_s": 27.7761652469635, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.7761652469635, "timesteps_since_restore": 0, "iterations_since_restore": 241, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17642394113789933, "mean_inference_ms": 0.7498587276860025, "mean_action_processing_ms": 0.04710739364490654, "mean_env_wait_ms": 0.29209464486990006, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14520, "timesteps_this_iter": 0, "agent_timesteps_total": 43560, "timers": {"sample_time_ms": 109.589, "sample_throughput": 547.499, "load_time_ms": 0.143, "load_throughput": 419640.22, "learn_time_ms": 12.429, "learn_throughput": 4827.281, "update_time_ms": 0.906}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.6597994242666955e-74, "cur_lr": 0.0005, "total_loss": 7793468.5, "policy_loss": 7.693369941108585e-05, "vf_loss": 7793468.75, "vf_explained_var": -5.0067901611328125e-06, "kl": 0.00017286849912068192, "entropy": 0.8468866944313049, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14520, "num_agent_steps_sampled": 43560, "num_steps_trained": 14520, "num_agent_steps_trained": 43560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 145, "training_iteration": 242, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.0961754322052002, "time_total_s": 27.8723406791687, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.8723406791687, "timesteps_since_restore": 0, "iterations_since_restore": 242, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17642394113789933, "mean_inference_ms": 0.7498587276860025, "mean_action_processing_ms": 0.04710739364490654, "mean_env_wait_ms": 0.29209464486990006, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14580, "timesteps_this_iter": 0, "agent_timesteps_total": 43740, "timers": {"sample_time_ms": 109.724, "sample_throughput": 546.826, "load_time_ms": 0.143, "load_throughput": 418871.904, "learn_time_ms": 12.458, "learn_throughput": 4816.14, "update_time_ms": 0.915}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.8298997121333478e-74, "cur_lr": 0.0005, "total_loss": 10442902.5, "policy_loss": 4.1557019400784156e-05, "vf_loss": 10442903.0, "vf_explained_var": -2.1457672119140625e-06, "kl": 8.395847622288954e-05, "entropy": 0.8720586895942688, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14580, "num_agent_steps_sampled": 43740, "num_steps_trained": 14580, "num_agent_steps_trained": 43740, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 145, "training_iteration": 243, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.10167789459228516, "time_total_s": 27.974018573760986, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.974018573760986, "timesteps_since_restore": 0, "iterations_since_restore": 243, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17640962634524804, "mean_inference_ms": 0.7498599064341689, "mean_action_processing_ms": 0.04710455875371797, "mean_env_wait_ms": 0.29207687835670487, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14640, "timesteps_this_iter": 0, "agent_timesteps_total": 43920, "timers": {"sample_time_ms": 110.608, "sample_throughput": 542.459, "load_time_ms": 0.15, "load_throughput": 399204.061, "learn_time_ms": 12.614, "learn_throughput": 4756.516, "update_time_ms": 0.932}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4149498560666739e-74, "cur_lr": 0.0005, "total_loss": 2043819.75, "policy_loss": -0.0003636366661847745, "vf_loss": 2043819.9375, "vf_explained_var": 1.0907649993896484e-05, "kl": 8.908086026160333e-05, "entropy": 0.8914686143398285, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14640, "num_agent_steps_sampled": 43920, "num_steps_trained": 14640, "num_agent_steps_trained": 43920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 146, "training_iteration": 244, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.10428190231323242, "time_total_s": 28.07830047607422, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.07830047607422, "timesteps_since_restore": 0, "iterations_since_restore": 244, "perf": {"cpu_util_percent": 15.7, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1763920555337757, "mean_inference_ms": 0.749836425965356, "mean_action_processing_ms": 0.047100422484021645, "mean_env_wait_ms": 0.2920501920620822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14700, "timesteps_this_iter": 0, "agent_timesteps_total": 44100, "timers": {"sample_time_ms": 111.078, "sample_throughput": 540.161, "load_time_ms": 0.159, "load_throughput": 378319.663, "learn_time_ms": 12.576, "learn_throughput": 4771.017, "update_time_ms": 0.913}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.074749280333369e-75, "cur_lr": 0.0005, "total_loss": 18689419.0, "policy_loss": -0.0015283451674292792, "vf_loss": 18689419.0, "vf_explained_var": 3.7550926208496094e-06, "kl": 0.0002468945382880783, "entropy": 0.9286384284496307, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14700, "num_agent_steps_sampled": 44100, "num_steps_trained": 14700, "num_agent_steps_trained": 44100, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 147, "training_iteration": 245, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-02", "timestamp": 1742303402, "time_this_iter_s": 0.09338927268981934, "time_total_s": 28.171689748764038, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771aa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.171689748764038, "timesteps_since_restore": 0, "iterations_since_restore": 245, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1763920555337757, "mean_inference_ms": 0.749836425965356, "mean_action_processing_ms": 0.047100422484021645, "mean_env_wait_ms": 0.2920501920620822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14760, "timesteps_this_iter": 0, "agent_timesteps_total": 44280, "timers": {"sample_time_ms": 111.486, "sample_throughput": 538.184, "load_time_ms": 0.166, "load_throughput": 361837.872, "learn_time_ms": 12.48, "learn_throughput": 4807.537, "update_time_ms": 0.926}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.5373746401666847e-75, "cur_lr": 0.0005, "total_loss": 4443389.0, "policy_loss": -0.0008167757109447393, "vf_loss": 4443389.0, "vf_explained_var": -1.609325408935547e-05, "kl": 0.00039968487834229904, "entropy": 0.9809725284576416, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14760, "num_agent_steps_sampled": 44280, "num_steps_trained": 14760, "num_agent_steps_trained": 44280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 147, "training_iteration": 246, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-03", "timestamp": 1742303403, "time_this_iter_s": 0.09559082984924316, "time_total_s": 28.26728057861328, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771aca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.26728057861328, "timesteps_since_restore": 0, "iterations_since_restore": 246, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17637460679186934, "mean_inference_ms": 0.749811795076262, "mean_action_processing_ms": 0.04709640885044829, "mean_env_wait_ms": 0.2920222833163175, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14820, "timesteps_this_iter": 0, "agent_timesteps_total": 44460, "timers": {"sample_time_ms": 111.475, "sample_throughput": 538.237, "load_time_ms": 0.167, "load_throughput": 359871.643, "learn_time_ms": 12.385, "learn_throughput": 4844.631, "update_time_ms": 0.975}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7686873200833424e-75, "cur_lr": 0.0005, "total_loss": 7788546.5, "policy_loss": 0.00042416984280002623, "vf_loss": 7788546.25, "vf_explained_var": -1.2040138244628906e-05, "kl": 0.00014762740336848879, "entropy": 1.0126832723617554, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14820, "num_agent_steps_sampled": 44460, "num_steps_trained": 14820, "num_agent_steps_trained": 44460, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 148, "training_iteration": 247, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-03", "timestamp": 1742303403, "time_this_iter_s": 0.09697151184082031, "time_total_s": 28.3642520904541, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.3642520904541, "timesteps_since_restore": 0, "iterations_since_restore": 247, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17637460679186934, "mean_inference_ms": 0.749811795076262, "mean_action_processing_ms": 0.04709640885044829, "mean_env_wait_ms": 0.2920222833163175, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14880, "timesteps_this_iter": 0, "agent_timesteps_total": 44640, "timers": {"sample_time_ms": 111.438, "sample_throughput": 538.418, "load_time_ms": 0.173, "load_throughput": 345921.979, "learn_time_ms": 12.368, "learn_throughput": 4851.206, "update_time_ms": 0.976}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.843436600416712e-76, "cur_lr": 0.0005, "total_loss": 10440933.5, "policy_loss": -0.0007236603324081159, "vf_loss": 10440933.5, "vf_explained_var": -3.933906555175781e-06, "kl": 0.00010396344655028145, "entropy": 0.9937956631183624, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14880, "num_agent_steps_sampled": 44640, "num_steps_trained": 14880, "num_agent_steps_trained": 44640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 148, "training_iteration": 248, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-03", "timestamp": 1742303403, "time_this_iter_s": 0.09429669380187988, "time_total_s": 28.45854878425598, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.45854878425598, "timesteps_since_restore": 0, "iterations_since_restore": 248, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1763552540485037, "mean_inference_ms": 0.749785287400017, "mean_action_processing_ms": 0.04709243753944173, "mean_env_wait_ms": 0.2919894568280945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14940, "timesteps_this_iter": 0, "agent_timesteps_total": 44820, "timers": {"sample_time_ms": 112.41, "sample_throughput": 533.761, "load_time_ms": 0.187, "load_throughput": 321156.508, "learn_time_ms": 12.442, "learn_throughput": 4822.508, "update_time_ms": 0.963}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.421718300208356e-76, "cur_lr": 0.0005, "total_loss": 2042100.25, "policy_loss": -0.0030764877175286642, "vf_loss": 2042100.4375, "vf_explained_var": -4.929304122924805e-05, "kl": 0.00026707668043490784, "entropy": 0.9591771066188812, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 14940, "num_agent_steps_sampled": 44820, "num_steps_trained": 14940, "num_agent_steps_trained": 44820, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 149, "training_iteration": 249, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-03", "timestamp": 1742303403, "time_this_iter_s": 0.10648441314697266, "time_total_s": 28.565033197402954, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.565033197402954, "timesteps_since_restore": 0, "iterations_since_restore": 249, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17633696104322613, "mean_inference_ms": 0.7497533740986205, "mean_action_processing_ms": 0.04708832325112629, "mean_env_wait_ms": 0.29195650355065333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15000, "timesteps_this_iter": 0, "agent_timesteps_total": 45000, "timers": {"sample_time_ms": 112.221, "sample_throughput": 534.659, "load_time_ms": 0.186, "load_throughput": 322680.138, "learn_time_ms": 12.455, "learn_throughput": 4817.421, "update_time_ms": 0.993}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.210859150104178e-76, "cur_lr": 0.0005, "total_loss": 18679810.0, "policy_loss": 0.0006874130624863195, "vf_loss": 18679810.0, "vf_explained_var": 4.9173831939697266e-06, "kl": 0.00042016280245604776, "entropy": 0.8841637074947357, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15000, "num_agent_steps_sampled": 45000, "num_steps_trained": 15000, "num_agent_steps_trained": 45000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14411423402270226, "mean_inference_ms": 0.7575907437378493, "mean_action_processing_ms": 0.04575591496385782, "mean_env_wait_ms": 0.28516115891506766, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 150, "training_iteration": 250, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-04", "timestamp": 1742303404, "time_this_iter_s": 1.3143854141235352, "time_total_s": 29.87941861152649, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771adc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 29.87941861152649, "timesteps_since_restore": 0, "iterations_since_restore": 250, "perf": {"cpu_util_percent": 14.6, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17633696104322613, "mean_inference_ms": 0.7497533740986205, "mean_action_processing_ms": 0.04708832325112629, "mean_env_wait_ms": 0.29195650355065333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15060, "timesteps_this_iter": 0, "agent_timesteps_total": 45180, "timers": {"sample_time_ms": 234.228, "sample_throughput": 256.161, "load_time_ms": 0.194, "load_throughput": 308821.009, "learn_time_ms": 12.496, "learn_throughput": 4801.639, "update_time_ms": 1.011}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.105429575052089e-76, "cur_lr": 0.0005, "total_loss": 4441856.5, "policy_loss": 0.0004913664668694806, "vf_loss": 4441856.5, "vf_explained_var": 1.0192394256591797e-05, "kl": 0.00015250217538920197, "entropy": 0.8284315168857574, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15060, "num_agent_steps_sampled": 45180, "num_steps_trained": 15060, "num_agent_steps_trained": 45180, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 150, "training_iteration": 251, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-04", "timestamp": 1742303404, "time_this_iter_s": 0.09285378456115723, "time_total_s": 29.972272396087646, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 29.972272396087646, "timesteps_since_restore": 0, "iterations_since_restore": 251, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17631900866243522, "mean_inference_ms": 0.749722218524128, "mean_action_processing_ms": 0.04708438082964869, "mean_env_wait_ms": 0.2919252221622843, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15120, "timesteps_this_iter": 0, "agent_timesteps_total": 45360, "timers": {"sample_time_ms": 234.037, "sample_throughput": 256.37, "load_time_ms": 0.197, "load_throughput": 304855.53, "learn_time_ms": 12.588, "learn_throughput": 4766.381, "update_time_ms": 0.989}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.527147875260445e-77, "cur_lr": 0.0005, "total_loss": 7783437.5, "policy_loss": -0.00039027202033992126, "vf_loss": 7783437.5, "vf_explained_var": -1.7881393432617188e-07, "kl": 8.66657551461536e-05, "entropy": 0.7941342294216156, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15120, "num_agent_steps_sampled": 45360, "num_steps_trained": 15120, "num_agent_steps_trained": 45360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 151, "training_iteration": 252, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-04", "timestamp": 1742303404, "time_this_iter_s": 0.0935213565826416, "time_total_s": 30.065793752670288, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.065793752670288, "timesteps_since_restore": 0, "iterations_since_restore": 252, "perf": {"cpu_util_percent": 12.3, "ram_util_percent": 20.7}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17631900866243522, "mean_inference_ms": 0.749722218524128, "mean_action_processing_ms": 0.04708438082964869, "mean_env_wait_ms": 0.2919252221622843, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15180, "timesteps_this_iter": 0, "agent_timesteps_total": 45540, "timers": {"sample_time_ms": 233.364, "sample_throughput": 257.109, "load_time_ms": 0.203, "load_throughput": 294992.662, "learn_time_ms": 12.492, "learn_throughput": 4803.252, "update_time_ms": 0.977}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.7635739376302224e-77, "cur_lr": 0.0005, "total_loss": 10438728.5, "policy_loss": -0.0009440210156341777, "vf_loss": 10438728.5, "vf_explained_var": -1.055002212524414e-05, "kl": 0.00015629113448079046, "entropy": 0.7609337866306305, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15180, "num_agent_steps_sampled": 45540, "num_steps_trained": 15180, "num_agent_steps_trained": 45540, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 151, "training_iteration": 253, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.09289813041687012, "time_total_s": 30.158691883087158, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771adc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.158691883087158, "timesteps_since_restore": 0, "iterations_since_restore": 253, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17630292008312257, "mean_inference_ms": 0.7496970386392218, "mean_action_processing_ms": 0.04708107812812599, "mean_env_wait_ms": 0.29189701933122897, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15240, "timesteps_this_iter": 0, "agent_timesteps_total": 45720, "timers": {"sample_time_ms": 232.13, "sample_throughput": 258.476, "load_time_ms": 0.2, "load_throughput": 299450.547, "learn_time_ms": 12.373, "learn_throughput": 4849.43, "update_time_ms": 0.966}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3817869688151112e-77, "cur_lr": 0.0005, "total_loss": 2040168.125, "policy_loss": 0.00017419589793354895, "vf_loss": 2040168.1875, "vf_explained_var": 8.940696716308594e-06, "kl": 0.0001299353103121348, "entropy": 0.714825451374054, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15240, "num_agent_steps_sampled": 45720, "num_steps_trained": 15240, "num_agent_steps_trained": 45720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 152, "training_iteration": 254, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.09296107292175293, "time_total_s": 30.25165295600891, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.25165295600891, "timesteps_since_restore": 0, "iterations_since_restore": 254, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17628461811252968, "mean_inference_ms": 0.7496718412942441, "mean_action_processing_ms": 0.047077772336889326, "mean_env_wait_ms": 0.2918687437797829, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15300, "timesteps_this_iter": 0, "agent_timesteps_total": 45900, "timers": {"sample_time_ms": 231.511, "sample_throughput": 259.167, "load_time_ms": 0.193, "load_throughput": 310535.834, "learn_time_ms": 12.383, "learn_throughput": 4845.489, "update_time_ms": 0.972}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.908934844075556e-78, "cur_lr": 0.0005, "total_loss": 18670008.0, "policy_loss": -0.0008770290542301495, "vf_loss": 18670008.0, "vf_explained_var": -6.616115570068359e-06, "kl": 0.00013457669478000867, "entropy": 0.6805738806724548, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15300, "num_agent_steps_sampled": 45900, "num_steps_trained": 15300, "num_agent_steps_trained": 45900, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 153, "training_iteration": 255, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.09084892272949219, "time_total_s": 30.342501878738403, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.342501878738403, "timesteps_since_restore": 0, "iterations_since_restore": 255, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17628461811252968, "mean_inference_ms": 0.7496718412942441, "mean_action_processing_ms": 0.047077772336889326, "mean_env_wait_ms": 0.2918687437797829, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15360, "timesteps_this_iter": 0, "agent_timesteps_total": 46080, "timers": {"sample_time_ms": 231.01, "sample_throughput": 259.729, "load_time_ms": 0.19, "load_throughput": 315400.727, "learn_time_ms": 12.703, "learn_throughput": 4723.129, "update_time_ms": 1.01}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.454467422037778e-78, "cur_lr": 0.0005, "total_loss": 4440393.25, "policy_loss": -0.0012245217571020817, "vf_loss": 4440393.0, "vf_explained_var": -1.1563301086425781e-05, "kl": 0.0002615861740422609, "entropy": 0.6328127384185791, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15360, "num_agent_steps_sampled": 46080, "num_steps_trained": 15360, "num_agent_steps_trained": 46080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 153, "training_iteration": 256, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.09594941139221191, "time_total_s": 30.438451290130615, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.438451290130615, "timesteps_since_restore": 0, "iterations_since_restore": 256, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17626774060861802, "mean_inference_ms": 0.7496452294147765, "mean_action_processing_ms": 0.04707442424880926, "mean_env_wait_ms": 0.2918376245974238, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15420, "timesteps_this_iter": 0, "agent_timesteps_total": 46260, "timers": {"sample_time_ms": 232.417, "sample_throughput": 258.157, "load_time_ms": 0.197, "load_throughput": 304707.882, "learn_time_ms": 12.898, "learn_throughput": 4651.938, "update_time_ms": 0.933}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.727233711018889e-78, "cur_lr": 0.0005, "total_loss": 7778376.75, "policy_loss": -0.0020490309120053674, "vf_loss": 7778376.5, "vf_explained_var": -5.9604644775390625e-06, "kl": 0.0003581551092337598, "entropy": 0.5734261870384216, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15420, "num_agent_steps_sampled": 46260, "num_steps_trained": 15420, "num_agent_steps_trained": 46260, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 154, "training_iteration": 257, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.09876728057861328, "time_total_s": 30.53721857070923, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.53721857070923, "timesteps_since_restore": 0, "iterations_since_restore": 257, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17626774060861802, "mean_inference_ms": 0.7496452294147765, "mean_action_processing_ms": 0.04707442424880926, "mean_env_wait_ms": 0.2918376245974238, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15480, "timesteps_this_iter": 0, "agent_timesteps_total": 46440, "timers": {"sample_time_ms": 233.378, "sample_throughput": 257.093, "load_time_ms": 0.19, "load_throughput": 315361.203, "learn_time_ms": 13.023, "learn_throughput": 4607.395, "update_time_ms": 0.925}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.636168555094445e-79, "cur_lr": 0.0005, "total_loss": 10436330.0, "policy_loss": -0.0009923547221761808, "vf_loss": 10436330.0, "vf_explained_var": -1.1920928955078125e-05, "kl": 0.00036362109100274154, "entropy": 0.5074111819267273, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15480, "num_agent_steps_sampled": 46440, "num_steps_trained": 15480, "num_agent_steps_trained": 46440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 154, "training_iteration": 258, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.10375690460205078, "time_total_s": 30.64097547531128, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.64097547531128, "timesteps_since_restore": 0, "iterations_since_restore": 258, "perf": {"cpu_util_percent": 16.0, "ram_util_percent": 20.8}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17625266046270538, "mean_inference_ms": 0.7496269211252286, "mean_action_processing_ms": 0.04707136460821256, "mean_env_wait_ms": 0.29180901424591843, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15540, "timesteps_this_iter": 0, "agent_timesteps_total": 46620, "timers": {"sample_time_ms": 232.818, "sample_throughput": 257.712, "load_time_ms": 0.177, "load_throughput": 339344.984, "learn_time_ms": 12.924, "learn_throughput": 4642.379, "update_time_ms": 0.935}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.3180842775472226e-79, "cur_lr": 0.0005, "total_loss": 2038434.75, "policy_loss": -0.00046029155879923067, "vf_loss": 2038434.8125, "vf_explained_var": -4.827976226806641e-06, "kl": 0.00028074590823198506, "entropy": 0.44171997904777527, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15540, "num_agent_steps_sampled": 46620, "num_steps_trained": 15540, "num_agent_steps_trained": 46620, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 155, "training_iteration": 259, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.0968778133392334, "time_total_s": 30.737853288650513, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772adc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.737853288650513, "timesteps_since_restore": 0, "iterations_since_restore": 259, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17623868675602886, "mean_inference_ms": 0.7496122880633943, "mean_action_processing_ms": 0.0470686418009669, "mean_env_wait_ms": 0.2917837468376096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15600, "timesteps_this_iter": 0, "agent_timesteps_total": 46800, "timers": {"sample_time_ms": 233.122, "sample_throughput": 257.376, "load_time_ms": 0.182, "load_throughput": 330000.315, "learn_time_ms": 12.909, "learn_throughput": 4648.012, "update_time_ms": 0.964}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.1590421387736113e-79, "cur_lr": 0.0005, "total_loss": 18660263.0, "policy_loss": -0.0009266416425814938, "vf_loss": 18660262.0, "vf_explained_var": -3.6954879760742188e-06, "kl": 0.00021851563005853558, "entropy": 0.3855929374694824, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15600, "num_agent_steps_sampled": 46800, "num_steps_trained": 15600, "num_agent_steps_trained": 46800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 156, "training_iteration": 260, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.0962672233581543, "time_total_s": 30.834120512008667, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27796160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.834120512008667, "timesteps_since_restore": 0, "iterations_since_restore": 260, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17623868675602886, "mean_inference_ms": 0.7496122880633943, "mean_action_processing_ms": 0.0470686418009669, "mean_env_wait_ms": 0.2917837468376096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15660, "timesteps_this_iter": 0, "agent_timesteps_total": 46980, "timers": {"sample_time_ms": 111.463, "sample_throughput": 538.293, "load_time_ms": 0.174, "load_throughput": 345115.524, "learn_time_ms": 12.789, "learn_throughput": 4691.423, "update_time_ms": 0.994}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0795210693868056e-79, "cur_lr": 0.0005, "total_loss": 4439055.5, "policy_loss": -7.479157745082787e-05, "vf_loss": 4439055.5, "vf_explained_var": -8.285045623779297e-06, "kl": 0.00014726267244025149, "entropy": 0.33619824051856995, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15660, "num_agent_steps_sampled": 46980, "num_steps_trained": 15660, "num_agent_steps_trained": 46980, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 156, "training_iteration": 261, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-05", "timestamp": 1742303405, "time_this_iter_s": 0.0966954231262207, "time_total_s": 30.930815935134888, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276740d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.930815935134888, "timesteps_since_restore": 0, "iterations_since_restore": 261, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17622592009207289, "mean_inference_ms": 0.7496003082095344, "mean_action_processing_ms": 0.04706611556976464, "mean_env_wait_ms": 0.2917589174217039, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15720, "timesteps_this_iter": 0, "agent_timesteps_total": 47160, "timers": {"sample_time_ms": 111.376, "sample_throughput": 538.718, "load_time_ms": 0.171, "load_throughput": 350303.786, "learn_time_ms": 12.786, "learn_throughput": 4692.464, "update_time_ms": 1.006}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.397605346934028e-80, "cur_lr": 0.0005, "total_loss": 7773278.75, "policy_loss": -0.00024078819098777293, "vf_loss": 7773278.75, "vf_explained_var": -3.7550926208496094e-06, "kl": 8.881837631147249e-05, "entropy": 0.2976644039154053, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15720, "num_agent_steps_sampled": 47160, "num_steps_trained": 15720, "num_agent_steps_trained": 47160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 157, "training_iteration": 262, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09375262260437012, "time_total_s": 31.024568557739258, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ac10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.024568557739258, "timesteps_since_restore": 0, "iterations_since_restore": 262, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17622592009207289, "mean_inference_ms": 0.7496003082095344, "mean_action_processing_ms": 0.04706611556976464, "mean_env_wait_ms": 0.2917589174217039, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15780, "timesteps_this_iter": 0, "agent_timesteps_total": 47340, "timers": {"sample_time_ms": 111.698, "sample_throughput": 537.163, "load_time_ms": 0.166, "load_throughput": 362254.556, "learn_time_ms": 12.74, "learn_throughput": 4709.685, "update_time_ms": 1.0}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.698802673467014e-80, "cur_lr": 0.0005, "total_loss": 10433965.5, "policy_loss": 0.00033557846909459954, "vf_loss": 10433965.5, "vf_explained_var": 4.708766937255859e-06, "kl": 3.855175731470872e-05, "entropy": 0.268439456820488, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15780, "num_agent_steps_sampled": 47340, "num_steps_trained": 15780, "num_agent_steps_trained": 47340, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 157, "training_iteration": 263, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09401702880859375, "time_total_s": 31.11858558654785, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f35e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.11858558654785, "timesteps_since_restore": 0, "iterations_since_restore": 263, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17621425102754554, "mean_inference_ms": 0.7495840146570899, "mean_action_processing_ms": 0.04706362703710454, "mean_env_wait_ms": 0.2917336061949804, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15840, "timesteps_this_iter": 0, "agent_timesteps_total": 47520, "timers": {"sample_time_ms": 112.577, "sample_throughput": 532.97, "load_time_ms": 0.159, "load_throughput": 378547.292, "learn_time_ms": 12.593, "learn_throughput": 4764.513, "update_time_ms": 1.02}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.349401336733507e-80, "cur_lr": 0.0005, "total_loss": 2036534.8125, "policy_loss": 7.642507585448044e-05, "vf_loss": 2036534.75, "vf_explained_var": 3.3080577850341797e-06, "kl": 9.63007713494779e-06, "entropy": 0.2527150511741638, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15840, "num_agent_steps_sampled": 47520, "num_steps_trained": 15840, "num_agent_steps_trained": 47520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 158, "training_iteration": 264, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09673380851745605, "time_total_s": 31.215319395065308, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.215319395065308, "timesteps_since_restore": 0, "iterations_since_restore": 264, "perf": {"cpu_util_percent": 15.7, "ram_util_percent": 20.9}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17620284641318001, "mean_inference_ms": 0.7495696314794097, "mean_action_processing_ms": 0.04706112785173497, "mean_env_wait_ms": 0.291711556036956, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15900, "timesteps_this_iter": 0, "agent_timesteps_total": 47700, "timers": {"sample_time_ms": 112.931, "sample_throughput": 531.299, "load_time_ms": 0.157, "load_throughput": 381994.9, "learn_time_ms": 12.686, "learn_throughput": 4729.742, "update_time_ms": 1.028}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.747006683667535e-81, "cur_lr": 0.0005, "total_loss": 18650492.0, "policy_loss": -1.4455782265443418e-05, "vf_loss": 18650493.0, "vf_explained_var": -2.384185791015625e-07, "kl": 3.320816801988258e-06, "entropy": 0.2448451966047287, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15900, "num_agent_steps_sampled": 47700, "num_steps_trained": 15900, "num_agent_steps_trained": 47700, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 159, "training_iteration": 265, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09308981895446777, "time_total_s": 31.308409214019775, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771aee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.308409214019775, "timesteps_since_restore": 0, "iterations_since_restore": 265, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17620284641318001, "mean_inference_ms": 0.7495696314794097, "mean_action_processing_ms": 0.04706112785173497, "mean_env_wait_ms": 0.291711556036956, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15960, "timesteps_this_iter": 0, "agent_timesteps_total": 47880, "timers": {"sample_time_ms": 113.437, "sample_throughput": 528.929, "load_time_ms": 0.153, "load_throughput": 392113.182, "learn_time_ms": 12.277, "learn_throughput": 4887.308, "update_time_ms": 1.004}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.3735033418337676e-81, "cur_lr": 0.0005, "total_loss": 4437591.0, "policy_loss": 1.7356541544444326e-05, "vf_loss": 4437590.5, "vf_explained_var": 3.2186508178710938e-06, "kl": 6.128447526121406e-07, "entropy": 0.23990745097398758, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15960, "num_agent_steps_sampled": 47880, "num_steps_trained": 15960, "num_agent_steps_trained": 47880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 159, "training_iteration": 266, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09498238563537598, "time_total_s": 31.40339159965515, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771aa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.40339159965515, "timesteps_since_restore": 0, "iterations_since_restore": 266, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761931755151678, "mean_inference_ms": 0.7495580759481121, "mean_action_processing_ms": 0.04705889959746846, "mean_env_wait_ms": 0.2916918147390243, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16020, "timesteps_this_iter": 0, "agent_timesteps_total": 48060, "timers": {"sample_time_ms": 112.163, "sample_throughput": 534.937, "load_time_ms": 0.169, "load_throughput": 354898.096, "learn_time_ms": 12.134, "learn_throughput": 4944.607, "update_time_ms": 1.002}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6867516709168838e-81, "cur_lr": 0.0005, "total_loss": 7768189.0, "policy_loss": -0.0002313382141068132, "vf_loss": 7768188.5, "vf_explained_var": 5.125999450683594e-06, "kl": 4.571191602471825e-06, "entropy": 0.2413468137383461, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16020, "num_agent_steps_sampled": 48060, "num_steps_trained": 16020, "num_agent_steps_trained": 48060, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 160, "training_iteration": 267, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09685111045837402, "time_total_s": 31.500242710113525, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276740d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.500242710113525, "timesteps_since_restore": 0, "iterations_since_restore": 267, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761931755151678, "mean_inference_ms": 0.7495580759481121, "mean_action_processing_ms": 0.04705889959746846, "mean_env_wait_ms": 0.2916918147390243, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16080, "timesteps_this_iter": 0, "agent_timesteps_total": 48240, "timers": {"sample_time_ms": 110.889, "sample_throughput": 541.083, "load_time_ms": 0.169, "load_throughput": 354798.026, "learn_time_ms": 11.931, "learn_throughput": 5028.77, "update_time_ms": 1.053}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.433758354584419e-82, "cur_lr": 0.0005, "total_loss": 10431748.5, "policy_loss": 2.189775255345694e-05, "vf_loss": 10431748.0, "vf_explained_var": -2.9802322387695312e-06, "kl": 1.2440922800606446e-05, "entropy": 0.2527420297265053, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16080, "num_agent_steps_sampled": 48240, "num_steps_trained": 16080, "num_agent_steps_trained": 48240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 160, "training_iteration": 268, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09162759780883789, "time_total_s": 31.591870307922363, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.591870307922363, "timesteps_since_restore": 0, "iterations_since_restore": 268, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761839022222353, "mean_inference_ms": 0.7495463884160308, "mean_action_processing_ms": 0.04705671889404711, "mean_env_wait_ms": 0.2916727694452854, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16140, "timesteps_this_iter": 0, "agent_timesteps_total": 48420, "timers": {"sample_time_ms": 110.012, "sample_throughput": 545.394, "load_time_ms": 0.169, "load_throughput": 354348.409, "learn_time_ms": 12.032, "learn_throughput": 4986.788, "update_time_ms": 1.048}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.2168791772922095e-82, "cur_lr": 0.0005, "total_loss": 2034816.5, "policy_loss": 3.044803989737943e-05, "vf_loss": 2034816.5625, "vf_explained_var": -1.2993812561035156e-05, "kl": 3.220958405769636e-06, "entropy": 0.261748269200325, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16140, "num_agent_steps_sampled": 48420, "num_steps_trained": 16140, "num_agent_steps_trained": 48420, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 161, "training_iteration": 269, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09267663955688477, "time_total_s": 31.684546947479248, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.684546947479248, "timesteps_since_restore": 0, "iterations_since_restore": 269, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761750925021018, "mean_inference_ms": 0.7495340918775858, "mean_action_processing_ms": 0.04705445172467375, "mean_env_wait_ms": 0.29165376241437424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16200, "timesteps_this_iter": 0, "agent_timesteps_total": 48600, "timers": {"sample_time_ms": 109.691, "sample_throughput": 546.989, "load_time_ms": 0.173, "load_throughput": 347162.698, "learn_time_ms": 12.044, "learn_throughput": 4981.694, "update_time_ms": 0.987}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.1084395886461048e-82, "cur_lr": 0.0005, "total_loss": 18640858.0, "policy_loss": -0.0007286906164765128, "vf_loss": 18640858.0, "vf_explained_var": 1.3172626495361328e-05, "kl": 1.167492362608158e-05, "entropy": 0.2656890004873276, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16200, "num_agent_steps_sampled": 48600, "num_steps_trained": 16200, "num_agent_steps_trained": 48600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 162, "training_iteration": 270, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-06", "timestamp": 1742303406, "time_this_iter_s": 0.09063076972961426, "time_total_s": 31.775177717208862, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.775177717208862, "timesteps_since_restore": 0, "iterations_since_restore": 270, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761750925021018, "mean_inference_ms": 0.7495340918775858, "mean_action_processing_ms": 0.04705445172467375, "mean_env_wait_ms": 0.29165376241437424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16260, "timesteps_this_iter": 0, "agent_timesteps_total": 48780, "timers": {"sample_time_ms": 108.99, "sample_throughput": 550.511, "load_time_ms": 0.173, "load_throughput": 347642.271, "learn_time_ms": 12.101, "learn_throughput": 4958.451, "update_time_ms": 0.94}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0542197943230524e-82, "cur_lr": 0.0005, "total_loss": 4436194.0, "policy_loss": 0.000141175258452364, "vf_loss": 4436194.0, "vf_explained_var": -5.781650543212891e-06, "kl": 3.696247104123529e-05, "entropy": 0.2859214246273041, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16260, "num_agent_steps_sampled": 48780, "num_steps_trained": 16260, "num_agent_steps_trained": 48780, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 162, "training_iteration": 271, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.09271883964538574, "time_total_s": 31.867896556854248, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a79d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.867896556854248, "timesteps_since_restore": 0, "iterations_since_restore": 271, "perf": {"cpu_util_percent": 13.6, "ram_util_percent": 20.9}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17616795791204914, "mean_inference_ms": 0.7495228581079405, "mean_action_processing_ms": 0.04705239648289728, "mean_env_wait_ms": 0.29163578536100837, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16320, "timesteps_this_iter": 0, "agent_timesteps_total": 48960, "timers": {"sample_time_ms": 108.877, "sample_throughput": 551.078, "load_time_ms": 0.174, "load_throughput": 345304.94, "learn_time_ms": 12.041, "learn_throughput": 4982.868, "update_time_ms": 0.924}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.271098971615262e-83, "cur_lr": 0.0005, "total_loss": 7763200.5, "policy_loss": 5.835228423478611e-05, "vf_loss": 7763200.5, "vf_explained_var": -5.960464477539062e-07, "kl": 2.4981916785460356e-05, "entropy": 0.3057188391685486, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16320, "num_agent_steps_sampled": 48960, "num_steps_trained": 16320, "num_agent_steps_trained": 48960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 163, "training_iteration": 272, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.0934300422668457, "time_total_s": 31.961326599121094, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.961326599121094, "timesteps_since_restore": 0, "iterations_since_restore": 272, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17616795791204914, "mean_inference_ms": 0.7495228581079405, "mean_action_processing_ms": 0.04705239648289728, "mean_env_wait_ms": 0.29163578536100837, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16380, "timesteps_this_iter": 0, "agent_timesteps_total": 49140, "timers": {"sample_time_ms": 108.566, "sample_throughput": 552.661, "load_time_ms": 0.178, "load_throughput": 337887.003, "learn_time_ms": 12.101, "learn_throughput": 4958.314, "update_time_ms": 0.935}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.635549485807631e-83, "cur_lr": 0.0005, "total_loss": 10429530.0, "policy_loss": -0.0011255104948446615, "vf_loss": 10429530.0, "vf_explained_var": 1.9311904907226562e-05, "kl": 5.352324856899848e-05, "entropy": 0.32514961063861847, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16380, "num_agent_steps_sampled": 49140, "num_steps_trained": 16380, "num_agent_steps_trained": 49140, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 163, "training_iteration": 273, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.09374547004699707, "time_total_s": 32.05507206916809, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f39d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.05507206916809, "timesteps_since_restore": 0, "iterations_since_restore": 273, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761609687045843, "mean_inference_ms": 0.7495150458408665, "mean_action_processing_ms": 0.04705041855892242, "mean_env_wait_ms": 0.29161967752484497, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16440, "timesteps_this_iter": 0, "agent_timesteps_total": 49320, "timers": {"sample_time_ms": 107.954, "sample_throughput": 555.794, "load_time_ms": 0.197, "load_throughput": 304045.234, "learn_time_ms": 12.183, "learn_throughput": 4924.8, "update_time_ms": 0.914}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3177747429038155e-83, "cur_lr": 0.0005, "total_loss": 2033043.75, "policy_loss": 0.00017273822805918826, "vf_loss": 2033043.5625, "vf_explained_var": -5.662441253662109e-06, "kl": 8.143240120261908e-05, "entropy": 0.36060841381549835, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16440, "num_agent_steps_sampled": 49320, "num_steps_trained": 16440, "num_agent_steps_trained": 49320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 164, "training_iteration": 274, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.09485816955566406, "time_total_s": 32.149930238723755, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a7ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.149930238723755, "timesteps_since_restore": 0, "iterations_since_restore": 274, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761523626813684, "mean_inference_ms": 0.749503773267966, "mean_action_processing_ms": 0.047048174223501646, "mean_env_wait_ms": 0.2916018205919104, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16500, "timesteps_this_iter": 0, "agent_timesteps_total": 49500, "timers": {"sample_time_ms": 107.91, "sample_throughput": 556.018, "load_time_ms": 0.2, "load_throughput": 299735.874, "learn_time_ms": 12.094, "learn_throughput": 4961.168, "update_time_ms": 0.912}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.588873714519077e-84, "cur_lr": 0.0005, "total_loss": 18631239.0, "policy_loss": 0.00011553598661606657, "vf_loss": 18631239.0, "vf_explained_var": -2.2649765014648438e-06, "kl": 4.8999653039505375e-05, "entropy": 0.3915689140558243, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16500, "num_agent_steps_sampled": 49500, "num_steps_trained": 16500, "num_agent_steps_trained": 49500, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 165, "training_iteration": 275, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.09294605255126953, "time_total_s": 32.242876291275024, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.242876291275024, "timesteps_since_restore": 0, "iterations_since_restore": 275, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761523626813684, "mean_inference_ms": 0.749503773267966, "mean_action_processing_ms": 0.047048174223501646, "mean_env_wait_ms": 0.2916018205919104, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16560, "timesteps_this_iter": 0, "agent_timesteps_total": 49680, "timers": {"sample_time_ms": 107.601, "sample_throughput": 557.618, "load_time_ms": 0.201, "load_throughput": 298917.021, "learn_time_ms": 12.194, "learn_throughput": 4920.572, "update_time_ms": 0.88}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.2944368572595387e-84, "cur_lr": 0.0005, "total_loss": 4434551.0, "policy_loss": -0.0008238093733474727, "vf_loss": 4434551.25, "vf_explained_var": 1.1146068572998047e-05, "kl": 7.831951900238998e-05, "entropy": 0.4189220666885376, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16560, "num_agent_steps_sampled": 49680, "num_steps_trained": 16560, "num_agent_steps_trained": 49680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 165, "training_iteration": 276, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.09345507621765137, "time_total_s": 32.336331367492676, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.336331367492676, "timesteps_since_restore": 0, "iterations_since_restore": 276, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761447131961372, "mean_inference_ms": 0.74949463946647, "mean_action_processing_ms": 0.04704627667163942, "mean_env_wait_ms": 0.2915856983620252, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16620, "timesteps_this_iter": 0, "agent_timesteps_total": 49860, "timers": {"sample_time_ms": 107.447, "sample_throughput": 558.414, "load_time_ms": 0.177, "load_throughput": 339116.346, "learn_time_ms": 12.234, "learn_throughput": 4904.223, "update_time_ms": 0.893}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6472184286297693e-84, "cur_lr": 0.0005, "total_loss": 7758214.0, "policy_loss": -0.0009880251509848392, "vf_loss": 7758213.75, "vf_explained_var": 9.506940841674805e-06, "kl": 0.0001794594491499879, "entropy": 0.461553618311882, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16620, "num_agent_steps_sampled": 49860, "num_steps_trained": 16620, "num_agent_steps_trained": 49860, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 166, "training_iteration": 277, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.09507298469543457, "time_total_s": 32.43140435218811, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277a79d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.43140435218811, "timesteps_since_restore": 0, "iterations_since_restore": 277, "perf": {"cpu_util_percent": 13.6, "ram_util_percent": 20.9}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1761447131961372, "mean_inference_ms": 0.74949463946647, "mean_action_processing_ms": 0.04704627667163942, "mean_env_wait_ms": 0.2915856983620252, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16680, "timesteps_this_iter": 0, "agent_timesteps_total": 50040, "timers": {"sample_time_ms": 107.851, "sample_throughput": 556.324, "load_time_ms": 0.189, "load_throughput": 317951.03, "learn_time_ms": 12.298, "learn_throughput": 4878.932, "update_time_ms": 0.846}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.236092143148847e-85, "cur_lr": 0.0005, "total_loss": 10427515.5, "policy_loss": 0.0011429909332139054, "vf_loss": 10427515.5, "vf_explained_var": -2.276897430419922e-05, "kl": 5.473525557830872e-05, "entropy": 0.5115501880645752, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16680, "num_agent_steps_sampled": 50040, "num_steps_trained": 16680, "num_agent_steps_trained": 50040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 166, "training_iteration": 278, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.0937509536743164, "time_total_s": 32.52515530586243, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2763ddc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.52515530586243, "timesteps_since_restore": 0, "iterations_since_restore": 278, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17613588866679555, "mean_inference_ms": 0.7494894644239284, "mean_action_processing_ms": 0.04704487196238759, "mean_env_wait_ms": 0.2915711265895283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16740, "timesteps_this_iter": 0, "agent_timesteps_total": 50220, "timers": {"sample_time_ms": 108.494, "sample_throughput": 553.026, "load_time_ms": 0.189, "load_throughput": 318152.01, "learn_time_ms": 12.337, "learn_throughput": 4863.243, "update_time_ms": 0.847}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.1180460715744234e-85, "cur_lr": 0.0005, "total_loss": 2031291.3125, "policy_loss": -0.000260704757723218, "vf_loss": 2031291.125, "vf_explained_var": -3.874301910400391e-06, "kl": 1.1272660060512862e-05, "entropy": 0.5196808576583862, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16740, "num_agent_steps_sampled": 50220, "num_steps_trained": 16740, "num_agent_steps_trained": 50220, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 167, "training_iteration": 279, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-07", "timestamp": 1742303407, "time_this_iter_s": 0.09969496726989746, "time_total_s": 32.624850273132324, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2763dd30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.624850273132324, "timesteps_since_restore": 0, "iterations_since_restore": 279, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17612616205141982, "mean_inference_ms": 0.7495226650351118, "mean_action_processing_ms": 0.04704361268031252, "mean_env_wait_ms": 0.2915566322093433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16800, "timesteps_this_iter": 0, "agent_timesteps_total": 50400, "timers": {"sample_time_ms": 114.715, "sample_throughput": 523.036, "load_time_ms": 0.182, "load_throughput": 329094.076, "learn_time_ms": 12.445, "learn_throughput": 4821.085, "update_time_ms": 0.848}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.0590230357872117e-85, "cur_lr": 0.0005, "total_loss": 18621692.0, "policy_loss": 7.5757503610329735e-06, "vf_loss": 18621692.0, "vf_explained_var": -3.3974647521972656e-06, "kl": 1.4879098725106843e-05, "entropy": 0.5159978568553925, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16800, "num_agent_steps_sampled": 50400, "num_steps_trained": 16800, "num_agent_steps_trained": 50400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 168, "training_iteration": 280, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.1551196575164795, "time_total_s": 32.779969930648804, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772aa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.779969930648804, "timesteps_since_restore": 0, "iterations_since_restore": 280, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17612616205141982, "mean_inference_ms": 0.7495226650351118, "mean_action_processing_ms": 0.04704361268031252, "mean_env_wait_ms": 0.2915566322093433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16860, "timesteps_this_iter": 0, "agent_timesteps_total": 50580, "timers": {"sample_time_ms": 114.834, "sample_throughput": 522.492, "load_time_ms": 0.182, "load_throughput": 329611.316, "learn_time_ms": 12.456, "learn_throughput": 4816.933, "update_time_ms": 0.856}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0295115178936058e-85, "cur_lr": 0.0005, "total_loss": 4433405.5, "policy_loss": -0.0007078799768365229, "vf_loss": 4433405.75, "vf_explained_var": -3.0040740966796875e-05, "kl": 4.389868551386844e-05, "entropy": 0.5052248984575272, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16860, "num_agent_steps_sampled": 50580, "num_steps_trained": 16860, "num_agent_steps_trained": 50580, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 168, "training_iteration": 281, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.09140563011169434, "time_total_s": 32.8713755607605, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f31f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.8713755607605, "timesteps_since_restore": 0, "iterations_since_restore": 281, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17611747301899022, "mean_inference_ms": 0.7495569600987672, "mean_action_processing_ms": 0.04704233221634655, "mean_env_wait_ms": 0.2915430385236851, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16920, "timesteps_this_iter": 0, "agent_timesteps_total": 50760, "timers": {"sample_time_ms": 114.882, "sample_throughput": 522.277, "load_time_ms": 0.202, "load_throughput": 296417.244, "learn_time_ms": 12.453, "learn_throughput": 4817.956, "update_time_ms": 0.862}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.147557589468029e-86, "cur_lr": 0.0005, "total_loss": 7753268.0, "policy_loss": 0.00038622155229361965, "vf_loss": 7753267.75, "vf_explained_var": 3.725290298461914e-06, "kl": 3.7201750066273576e-05, "entropy": 0.47709517180919647, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16920, "num_agent_steps_sampled": 50760, "num_steps_trained": 16920, "num_agent_steps_trained": 50760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 169, "training_iteration": 282, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.09244394302368164, "time_total_s": 32.96381950378418, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.96381950378418, "timesteps_since_restore": 0, "iterations_since_restore": 282, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17611747301899022, "mean_inference_ms": 0.7495569600987672, "mean_action_processing_ms": 0.04704233221634655, "mean_env_wait_ms": 0.2915430385236851, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16980, "timesteps_this_iter": 0, "agent_timesteps_total": 50940, "timers": {"sample_time_ms": 114.835, "sample_throughput": 522.489, "load_time_ms": 0.198, "load_throughput": 302510.206, "learn_time_ms": 12.496, "learn_throughput": 4801.649, "update_time_ms": 0.857}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.5737787947340146e-86, "cur_lr": 0.0005, "total_loss": 10425200.0, "policy_loss": -0.0003719733756355481, "vf_loss": 10425200.0, "vf_explained_var": -1.430511474609375e-06, "kl": 1.6431978915103836e-05, "entropy": 0.46203702688217163, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16980, "num_agent_steps_sampled": 50940, "num_steps_trained": 16980, "num_agent_steps_trained": 50940, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 169, "training_iteration": 283, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.09318876266479492, "time_total_s": 33.057008266448975, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276740d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.057008266448975, "timesteps_since_restore": 0, "iterations_since_restore": 283, "perf": {"cpu_util_percent": 14.0, "ram_util_percent": 20.9}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17610869855430397, "mean_inference_ms": 0.7495913682238874, "mean_action_processing_ms": 0.047041308103030845, "mean_env_wait_ms": 0.29153081892797, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17040, "timesteps_this_iter": 0, "agent_timesteps_total": 51120, "timers": {"sample_time_ms": 115.298, "sample_throughput": 520.391, "load_time_ms": 0.179, "load_throughput": 335097.523, "learn_time_ms": 12.451, "learn_throughput": 4818.704, "update_time_ms": 0.865}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2868893973670073e-86, "cur_lr": 0.0005, "total_loss": 2029447.75, "policy_loss": 5.698402900478072e-05, "vf_loss": 2029447.75, "vf_explained_var": 1.6689300537109375e-05, "kl": 3.622642727574288e-06, "entropy": 0.45187875628471375, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17040, "num_agent_steps_sampled": 51120, "num_steps_trained": 17040, "num_agent_steps_trained": 51120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 170, "training_iteration": 284, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.09759640693664551, "time_total_s": 33.15460467338562, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f31f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.15460467338562, "timesteps_since_restore": 0, "iterations_since_restore": 284, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1760998621232075, "mean_inference_ms": 0.749629370584065, "mean_action_processing_ms": 0.04704059240673019, "mean_env_wait_ms": 0.29151887747431965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17100, "timesteps_this_iter": 0, "agent_timesteps_total": 51300, "timers": {"sample_time_ms": 115.346, "sample_throughput": 520.174, "load_time_ms": 0.187, "load_throughput": 320951.715, "learn_time_ms": 12.559, "learn_throughput": 4777.619, "update_time_ms": 0.864}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.4344469868350365e-87, "cur_lr": 0.0005, "total_loss": 18612199.0, "policy_loss": -2.8301278952369557e-05, "vf_loss": 18612199.0, "vf_explained_var": -1.1086463928222656e-05, "kl": 1.47960588492424e-06, "entropy": 0.45796406269073486, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17100, "num_agent_steps_sampled": 51300, "num_steps_trained": 17100, "num_agent_steps_trained": 51300, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 171, "training_iteration": 285, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.09605145454406738, "time_total_s": 33.25065612792969, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.25065612792969, "timesteps_since_restore": 0, "iterations_since_restore": 285, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1760998621232075, "mean_inference_ms": 0.749629370584065, "mean_action_processing_ms": 0.04704059240673019, "mean_env_wait_ms": 0.29151887747431965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17160, "timesteps_this_iter": 0, "agent_timesteps_total": 51480, "timers": {"sample_time_ms": 115.612, "sample_throughput": 518.977, "load_time_ms": 0.19, "load_throughput": 316471.63, "learn_time_ms": 12.568, "learn_throughput": 4774.039, "update_time_ms": 0.918}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.2172234934175183e-87, "cur_lr": 0.0005, "total_loss": 4431987.25, "policy_loss": -0.0006594439205294123, "vf_loss": 4431987.0, "vf_explained_var": -5.841255187988281e-06, "kl": 1.0123583642052125e-05, "entropy": 0.4549597203731537, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17160, "num_agent_steps_sampled": 51480, "num_steps_trained": 17160, "num_agent_steps_trained": 51480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 171, "training_iteration": 286, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.09264802932739258, "time_total_s": 33.34330415725708, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771ac10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.34330415725708, "timesteps_since_restore": 0, "iterations_since_restore": 286, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17609246453374428, "mean_inference_ms": 0.7496673071190866, "mean_action_processing_ms": 0.04703999484537463, "mean_env_wait_ms": 0.29150701048392436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17220, "timesteps_this_iter": 0, "agent_timesteps_total": 51660, "timers": {"sample_time_ms": 115.629, "sample_throughput": 518.901, "load_time_ms": 0.19, "load_throughput": 316233.023, "learn_time_ms": 12.572, "learn_throughput": 4772.419, "update_time_ms": 0.908}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6086117467087591e-87, "cur_lr": 0.0005, "total_loss": 7748239.25, "policy_loss": -0.0001580668774998628, "vf_loss": 7748238.75, "vf_explained_var": -2.2649765014648438e-06, "kl": 2.043558789943667e-05, "entropy": 0.45377928018569946, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17220, "num_agent_steps_sampled": 51660, "num_steps_trained": 17220, "num_agent_steps_trained": 51660, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 172, "training_iteration": 287, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.09258317947387695, "time_total_s": 33.43588733673096, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.43588733673096, "timesteps_since_restore": 0, "iterations_since_restore": 287, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17609246453374428, "mean_inference_ms": 0.7496673071190866, "mean_action_processing_ms": 0.04703999484537463, "mean_env_wait_ms": 0.29150701048392436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17280, "timesteps_this_iter": 0, "agent_timesteps_total": 51840, "timers": {"sample_time_ms": 114.985, "sample_throughput": 521.806, "load_time_ms": 0.196, "load_throughput": 305521.719, "learn_time_ms": 12.542, "learn_throughput": 4783.886, "update_time_ms": 0.91}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.043058733543796e-88, "cur_lr": 0.0005, "total_loss": 10422464.0, "policy_loss": -0.00038287408015946767, "vf_loss": 10422464.0, "vf_explained_var": -5.841255187988281e-06, "kl": 1.7494860340860896e-05, "entropy": 0.45234134793281555, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17280, "num_agent_steps_sampled": 51840, "num_steps_trained": 17280, "num_agent_steps_trained": 51840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 172, "training_iteration": 288, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-08", "timestamp": 1742303408, "time_this_iter_s": 0.0896153450012207, "time_total_s": 33.52550268173218, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.52550268173218, "timesteps_since_restore": 0, "iterations_since_restore": 288, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.176085389416934, "mean_inference_ms": 0.7497005315953619, "mean_action_processing_ms": 0.047039218609654876, "mean_env_wait_ms": 0.29149280097508884, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17340, "timesteps_this_iter": 0, "agent_timesteps_total": 52020, "timers": {"sample_time_ms": 120.821, "sample_throughput": 496.603, "load_time_ms": 0.212, "load_throughput": 283207.562, "learn_time_ms": 12.411, "learn_throughput": 4834.394, "update_time_ms": 0.945}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.021529366771898e-88, "cur_lr": 0.0005, "total_loss": 2027629.625, "policy_loss": -3.0154651944336308e-05, "vf_loss": 2027629.625, "vf_explained_var": 1.6689300537109375e-05, "kl": 1.4828760154017573e-05, "entropy": 0.446759432554245, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17340, "num_agent_steps_sampled": 52020, "num_steps_trained": 17340, "num_agent_steps_trained": 52020, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 173, "training_iteration": 289, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-09", "timestamp": 1742303409, "time_this_iter_s": 0.09268379211425781, "time_total_s": 33.618186473846436, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.618186473846436, "timesteps_since_restore": 0, "iterations_since_restore": 289, "perf": {"cpu_util_percent": 14.1, "ram_util_percent": 21.0}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17607669119718292, "mean_inference_ms": 0.7497337735992395, "mean_action_processing_ms": 0.047038396782210154, "mean_env_wait_ms": 0.2914790860562146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17400, "timesteps_this_iter": 0, "agent_timesteps_total": 52200, "timers": {"sample_time_ms": 114.543, "sample_throughput": 523.82, "load_time_ms": 0.22, "load_throughput": 272652.481, "learn_time_ms": 12.384, "learn_throughput": 4845.004, "update_time_ms": 0.948}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.010764683385949e-88, "cur_lr": 0.0005, "total_loss": 18602498.0, "policy_loss": 6.172921631275585e-05, "vf_loss": 18602498.0, "vf_explained_var": -8.702278137207031e-06, "kl": 7.73674713006045e-06, "entropy": 0.45213067531585693, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17400, "num_agent_steps_sampled": 52200, "num_steps_trained": 17400, "num_agent_steps_trained": 52200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 174, "training_iteration": 290, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-09", "timestamp": 1742303409, "time_this_iter_s": 0.09265828132629395, "time_total_s": 33.71084475517273, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276741f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.71084475517273, "timesteps_since_restore": 0, "iterations_since_restore": 290, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17607669119718292, "mean_inference_ms": 0.7497337735992395, "mean_action_processing_ms": 0.047038396782210154, "mean_env_wait_ms": 0.2914790860562146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17460, "timesteps_this_iter": 0, "agent_timesteps_total": 52380, "timers": {"sample_time_ms": 114.354, "sample_throughput": 524.685, "load_time_ms": 0.221, "load_throughput": 271622.493, "learn_time_ms": 12.279, "learn_throughput": 4886.35, "update_time_ms": 0.938}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0053823416929745e-88, "cur_lr": 0.0005, "total_loss": 4430513.5, "policy_loss": -0.0003201137064010595, "vf_loss": 4430513.75, "vf_explained_var": 2.199411392211914e-05, "kl": 9.47054795119584e-06, "entropy": 0.4480508714914322, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17460, "num_agent_steps_sampled": 52380, "num_steps_trained": 17460, "num_agent_steps_trained": 52380, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 174, "training_iteration": 291, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-09", "timestamp": 1742303409, "time_this_iter_s": 0.09342646598815918, "time_total_s": 33.80427122116089, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2772aca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.80427122116089, "timesteps_since_restore": 0, "iterations_since_restore": 291, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17606881493291396, "mean_inference_ms": 0.7497671343121476, "mean_action_processing_ms": 0.047037544903828686, "mean_env_wait_ms": 0.2914633970286433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17520, "timesteps_this_iter": 0, "agent_timesteps_total": 52560, "timers": {"sample_time_ms": 114.879, "sample_throughput": 522.287, "load_time_ms": 0.214, "load_throughput": 281025.394, "learn_time_ms": 12.356, "learn_throughput": 4855.858, "update_time_ms": 0.941}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.026911708464872e-89, "cur_lr": 0.0005, "total_loss": 7743227.0, "policy_loss": -0.0016351706503578978, "vf_loss": 7743227.0, "vf_explained_var": 5.632638931274414e-06, "kl": 9.87161155457262e-05, "entropy": 0.4651763588190079, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17520, "num_agent_steps_sampled": 52560, "num_steps_trained": 17520, "num_agent_steps_trained": 52560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 175, "training_iteration": 292, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-09", "timestamp": 1742303409, "time_this_iter_s": 0.09914588928222656, "time_total_s": 33.903417110443115, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a2771a1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.903417110443115, "timesteps_since_restore": 0, "iterations_since_restore": 292, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17606881493291396, "mean_inference_ms": 0.7497671343121476, "mean_action_processing_ms": 0.047037544903828686, "mean_env_wait_ms": 0.2914633970286433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17580, "timesteps_this_iter": 0, "agent_timesteps_total": 52740, "timers": {"sample_time_ms": 114.901, "sample_throughput": 522.19, "load_time_ms": 0.213, "load_throughput": 281717.497, "learn_time_ms": 12.308, "learn_throughput": 4874.689, "update_time_ms": 0.969}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.513455854232436e-89, "cur_lr": 0.0005, "total_loss": 10420766.5, "policy_loss": -0.0011748370662747476, "vf_loss": 10420766.5, "vf_explained_var": 1.3709068298339844e-05, "kl": 0.00026923562331759854, "entropy": 0.5068315118551254, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17580, "num_agent_steps_sampled": 52740, "num_steps_trained": 17580, "num_agent_steps_trained": 52740, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 175, "training_iteration": 293, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-09", "timestamp": 1742303409, "time_this_iter_s": 0.09259462356567383, "time_total_s": 33.99601173400879, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.99601173400879, "timesteps_since_restore": 0, "iterations_since_restore": 293, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17606092528741094, "mean_inference_ms": 0.7498022316544255, "mean_action_processing_ms": 0.047036663927698875, "mean_env_wait_ms": 0.29144755544111567, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17640, "timesteps_this_iter": 0, "agent_timesteps_total": 52920, "timers": {"sample_time_ms": 114.544, "sample_throughput": 523.814, "load_time_ms": 0.212, "load_throughput": 282889.209, "learn_time_ms": 12.464, "learn_throughput": 4813.772, "update_time_ms": 0.96}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.256727927116218e-89, "cur_lr": 0.0005, "total_loss": 2025970.0625, "policy_loss": -0.0007948305845877357, "vf_loss": 2025970.1875, "vf_explained_var": 9.447336196899414e-06, "kl": 0.000396019504605466, "entropy": 0.5670921802520752, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17640, "num_agent_steps_sampled": 52920, "num_steps_trained": 17640, "num_agent_steps_trained": 52920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 176, "training_iteration": 294, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-09", "timestamp": 1742303409, "time_this_iter_s": 0.09572958946228027, "time_total_s": 34.09174132347107, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f39d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.09174132347107, "timesteps_since_restore": 0, "iterations_since_restore": 294, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17605201302936965, "mean_inference_ms": 0.7498324940257597, "mean_action_processing_ms": 0.047036068094768894, "mean_env_wait_ms": 0.2914317444014635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17700, "timesteps_this_iter": 0, "agent_timesteps_total": 53100, "timers": {"sample_time_ms": 114.804, "sample_throughput": 522.632, "load_time_ms": 0.202, "load_throughput": 297749.929, "learn_time_ms": 12.469, "learn_throughput": 4811.977, "update_time_ms": 0.95}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.28363963558109e-90, "cur_lr": 0.0005, "total_loss": 18593036.0, "policy_loss": -0.0022565590890337717, "vf_loss": 18593037.0, "vf_explained_var": 1.2606382369995117e-05, "kl": 0.0006122990366286274, "entropy": 0.6361372172832489, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17700, "num_agent_steps_sampled": 53100, "num_steps_trained": 17700, "num_agent_steps_trained": 53100, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 177, "training_iteration": 295, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-09", "timestamp": 1742303409, "time_this_iter_s": 0.09512114524841309, "time_total_s": 34.18686246871948, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a277519d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.18686246871948, "timesteps_since_restore": 0, "iterations_since_restore": 295, "perf": {"cpu_util_percent": 14.3, "ram_util_percent": 20.9}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17605201302936965, "mean_inference_ms": 0.7498324940257597, "mean_action_processing_ms": 0.047036068094768894, "mean_env_wait_ms": 0.2914317444014635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17760, "timesteps_this_iter": 0, "agent_timesteps_total": 53280, "timers": {"sample_time_ms": 114.363, "sample_throughput": 524.647, "load_time_ms": 0.198, "load_throughput": 302801.396, "learn_time_ms": 12.534, "learn_throughput": 4787.016, "update_time_ms": 0.906}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.141819817790545e-90, "cur_lr": 0.0005, "total_loss": 4429223.75, "policy_loss": -0.0009688851177784841, "vf_loss": 4429223.5, "vf_explained_var": 5.543231964111328e-06, "kl": 0.0008573215991987126, "entropy": 0.7216163277626038, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17760, "num_agent_steps_sampled": 53280, "num_steps_trained": 17760, "num_agent_steps_trained": 53280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 177, "training_iteration": 296, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-09", "timestamp": 1742303409, "time_this_iter_s": 0.09108972549438477, "time_total_s": 34.27795219421387, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.27795219421387, "timesteps_since_restore": 0, "iterations_since_restore": 296, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17604420592813944, "mean_inference_ms": 0.7498635133061713, "mean_action_processing_ms": 0.047035556002859656, "mean_env_wait_ms": 0.29141640661418516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17820, "timesteps_this_iter": 0, "agent_timesteps_total": 53460, "timers": {"sample_time_ms": 114.211, "sample_throughput": 525.344, "load_time_ms": 0.198, "load_throughput": 302655.731, "learn_time_ms": 12.534, "learn_throughput": 4787.016, "update_time_ms": 0.918}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5709099088952726e-90, "cur_lr": 0.0005, "total_loss": 7738529.0, "policy_loss": 0.0010276774073840755, "vf_loss": 7738528.5, "vf_explained_var": -7.033348083496094e-06, "kl": 0.0006491755436126567, "entropy": 0.7986764013767242, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17820, "num_agent_steps_sampled": 53460, "num_steps_trained": 17820, "num_agent_steps_trained": 53460, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 178, "training_iteration": 297, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-10", "timestamp": 1742303410, "time_this_iter_s": 0.09435868263244629, "time_total_s": 34.37231087684631, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27751310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.37231087684631, "timesteps_since_restore": 0, "iterations_since_restore": 297, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17604420592813944, "mean_inference_ms": 0.7498635133061713, "mean_action_processing_ms": 0.047035556002859656, "mean_env_wait_ms": 0.29141640661418516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17880, "timesteps_this_iter": 0, "agent_timesteps_total": 53640, "timers": {"sample_time_ms": 114.85, "sample_throughput": 522.423, "load_time_ms": 0.18, "load_throughput": 334251.879, "learn_time_ms": 12.619, "learn_throughput": 4754.584, "update_time_ms": 0.916}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.854549544476363e-91, "cur_lr": 0.0005, "total_loss": 10418927.0, "policy_loss": -0.0006313151563546171, "vf_loss": 10418927.0, "vf_explained_var": 5.0961971282958984e-06, "kl": 0.0004565076070841556, "entropy": 0.8493471741676331, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17880, "num_agent_steps_sampled": 53640, "num_steps_trained": 17880, "num_agent_steps_trained": 53640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 178, "training_iteration": 298, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-10", "timestamp": 1742303410, "time_this_iter_s": 0.09247684478759766, "time_total_s": 34.46478772163391, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a276f3af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.46478772163391, "timesteps_since_restore": 0, "iterations_since_restore": 298, "perf": {}}
{"episode_reward_max": -30300.0, "episode_reward_min": -30300.0, "episode_reward_mean": -30300.0, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -10100.0}, "policy_reward_max": {"shared_policy": -10100.0}, "policy_reward_mean": {"shared_policy": -10100.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0, -30300.0], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], "policy_shared_policy_reward": [-10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0, -10100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.176035844483146, "mean_inference_ms": 0.749891256928156, "mean_action_processing_ms": 0.047035080544268144, "mean_env_wait_ms": 0.29140102958043235, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17940, "timesteps_this_iter": 0, "agent_timesteps_total": 53820, "timers": {"sample_time_ms": 108.69, "sample_throughput": 552.027, "load_time_ms": 0.166, "load_throughput": 361370.247, "learn_time_ms": 12.637, "learn_throughput": 4748.0, "update_time_ms": 0.886}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.9272747722381815e-91, "cur_lr": 0.0005, "total_loss": 2024289.8125, "policy_loss": 0.00036650166730467504, "vf_loss": 2024289.9375, "vf_explained_var": -9.655952453613281e-06, "kl": 0.00031311156575242194, "entropy": 0.8898780941963196, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 17940, "num_agent_steps_sampled": 53820, "num_steps_trained": 17940, "num_agent_steps_trained": 53820, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 179, "training_iteration": 299, "trial_id": "3846d_00000", "experiment_id": "d0aee79d70614861a347f140e0ec0ed1", "date": "2025-03-18_14-10-10", "timestamp": 1742303410, "time_this_iter_s": 0.0940706729888916, "time_total_s": 34.5588583946228, "pid": 34935, "hostname": "LC1633", "node_ip": "172.20.4.161", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 60, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 60, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "wmt", "env_args": {"grid_size": [10, 10], "agents_number": 3, "view_size": 3, "max_cycles": 100, "map_name": "warehouse_management"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0], [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14], (49,), int64))", "space_act": "Discrete(7)", "num_agents": 3, "episode_limit": 30, "policy_mapping_info": {"warehouse_management": {"description": "Warehouse Management", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "wmt_warehouse_management", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x740a27674040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 60, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.5588583946228, "timesteps_since_restore": 0, "iterations_since_restore": 299, "perf": {}}
